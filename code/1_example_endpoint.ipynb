{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook to demonstrate the main workflow of the manuscript for one example endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the supporting information to the manuscript entitled \"Assessing the Calibration in Toxicological in Vitro Models with Conformal Prediction\". The notebook was developed by Andrea Morger in the \n",
    "In Silico Toxicology and Structural Biology Group of Prof. Dr. Andrea Volkamer at the Charité Universitätsmedizin \n",
    "Berlin, in collaboration with Fredrik Svensson, Staffan Arvidsson McShane, Niharika Gauraha, Ulf Norinder and Ola Spjuth. It was last updated in January 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "This notebooks demonstrates the main workflow to obtain the results for the manuscript on \"Assessing the Calibration in Toxicological in Vitro Models with Conformal Prediction\" for an example endpoint.\n",
    "It can be used to train aggregated conformal predictors on the Tox21Train datasets. The predictions of Tox21Score can be compared in different experiments with and without updated calibration sets as well as with updating the complete training set. The notebook may be adapted to use the code for different datasets if a different endpoint is selected in `input cell 6`.\n",
    "\n",
    "For a general introduction on conformal prediction (CP) and calibration plots we refer to the manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "1. [Preparation](#preparation) <br>\n",
    "    1.1. [Import libraries and modules](#import-libraries-and-modules)<br>\n",
    "    1.2. [Define paths and parameters](#define-paths-parameters)<br>\n",
    "2. [Conformal prediction experiments](#cp-experiments)<br>\n",
    "    2.1. [Load datasets](#load-data)<br>\n",
    "    2.2. [Using different calibration sets](#different-cal-sets)<br>\n",
    "    2.3. [Using updated training set](#updated-train-set)<br>\n",
    "3. [Evaluate conformal predictions](#evaluate-cp)<br>\n",
    "    3.1. [Calibration and efficiency plots](#cal-plots)<br>\n",
    "    3.2. [Root-mean-square deviations from the diagonal (rmsd)](#rmsd)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation <a id='preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Import libraries and modules <a id='import-libraries-and-modules'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from nonconformist.nc import NcFactory, MarginErrFunc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cptox21 import (\n",
    "    define_path, load_signatures_files, StratifiedRatioSampler,CrossValidationSampler,\n",
    "    KnownIndicesSampler, InductiveConformalPredictor,\n",
    "    AggregatedConformalPredictor, CPTox21AggregatedConformalPredictor, \n",
    "    CPTox21CrossValidator, CPTox21TrainUpdateCrossValidator, \n",
    "    calculate_rmsd_from_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define paths and parameters <a id='define-paths-parameters'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_signatures_path = DATA / \"data_signatures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"NR_ER\"  # Example endpoint \"estrogen receptor\" (a nuclear receptor). \n",
    "# The `endpoint` parameter may be changed to any of the other Tox21 endpoints \n",
    "# (i.e. 'SR_ATAD5', 'NR_ER', 'NR_AR', 'SR_HSE', 'SR_MMP', 'SR_p53', 'NR_Aromatase',\n",
    "# 'SR_ARE', 'NR_AR_LBD', 'NR_AhR', 'NR_ER_LBD', 'NR_PPAR_gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of loops used in ACP\n",
    "n_folds_acp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_state = 42  # Set the random seed for deterministic results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conformal prediction experiments <a id='cp-experiments'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for programmatic reasons, the conformal prediction experiments are calculated in a different order, not following the story in the manuscript. However, in [Section 3. Evaluate conformal predictions](#evaluate-cp), the order from the manuscript is preserved to explain the results.\n",
    "\n",
    "To perform the conformal prediction experiments, we need an `AggregatedConformalPredictor` object, which consolidates all the information needed to train an aggregated conformal prediction with a given number of loops (`n_folds_acp`) and a `CrossValidator` objects to handle the splits and folds of a crossvalidation. The two classes are adapted for the different parts (update calibration set and update training set) as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load datasets <a id='load-data'></a>\n",
    "Per endpoint, three datasets are loaded (Tox21Train, Tox21Test, Tox21Score, see manuscript for more explanation) which consist of the precalculated signature descriptors and the activity labels for the corresponding endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"train\", \"test\", \"score\"]  # Tox21 dataset_names\n",
    "train_path = os.path.join(\n",
    "        data_signatures_path, f\"data_signatures_{endpoint}_{dataset_names[0]}.csr\"\n",
    "    )\n",
    "test_path = os.path.join(\n",
    "        data_signatures_path, f\"data_signatures_{endpoint}_{dataset_names[1]}.csr\"\n",
    "    )\n",
    "score_path = os.path.join(\n",
    "        data_signatures_path, f\"data_signatures_{endpoint}_{dataset_names[2]}.csr\"\n",
    "    )\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_score, y_score = load_signatures_files(train_path, test_path, score_path)\n",
    "\n",
    "# Comment below code for final run (Uncomment to shorten calculation time for test runs)\n",
    "# X_train = X_train[:500]\n",
    "# y_train = y_train[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare size of datasets\n",
    "To interpret and assess the results, it might be useful to know, how many data points we actually have per dataset, and how balanced they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>actives</th>\n",
       "      <th>inactives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>901</td>\n",
       "      <td>6290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>27</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>score</td>\n",
       "      <td>49</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  actives  inactives\n",
       "0  train      901       6290\n",
       "1   test       27        231\n",
       "2  score       49        441"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_size_dict = {\"name\": dataset_names, \"actives\": [], \"inactives\": []}\n",
    "\n",
    "for dataset, labels in zip(dataset_names, [y_train, y_test, y_score]):\n",
    "    datasets_size_dict[\"actives\"].append(len(labels[labels==1]))\n",
    "    datasets_size_dict[\"inactives\"].append(len(labels[labels==0]))\n",
    "\n",
    "pd.DataFrame.from_dict(datasets_size_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Using different calibration sets <a id='different-cal-sets'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `CPTox21AggregatedConformalPredictor` class, an aggregated conformal predictor can be trained and calibrated with three different calibration sets: The original calibration set split from Tox21train, the more recent update set Tox21test, and the random stratified split (implying the same distribution as the prediction set) from Tox21score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Inductive Conformal Prediction classifier (ICP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(\n",
    "    kernel='rbf', C=50, gamma=0.002, probability=True, random_state=set_random_state\n",
    ")  # ML classifier\n",
    "error_function = MarginErrFunc()  # Error function\n",
    "normaliser_model = None  # Normaliser model\n",
    "nc = NcFactory.create_nc(clf, err_func=error_function)  # Nonconformity scorer\n",
    "icp = InductiveConformalPredictor(\n",
    "    nc_function=nc, condition=(lambda instance: instance[1])\n",
    ")  # Mondrian as (default) condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Aggregated Conformal Predictor (ACP) for main framework (using different calibration sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp = CPTox21AggregatedConformalPredictor(\n",
    "    predictor=icp, sampler=StratifiedRatioSampler(n_folds=n_folds_acp, random_state=set_random_state), aggregation_func=np.median\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define crossvalidator, with which a crossvalidation can be performed for all acp experiments except for train_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = CPTox21CrossValidator(\n",
    "    acp, cv_splitter=CrossValidationSampler(random_state=set_random_state), score_splitter=StratifiedRatioSampler(test_ratio=0.5, random_state=set_random_state)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossvalidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_dfs = cross_validator.cross_validate(\n",
    "    steps=10,  # Number of steps (significance level) for evaluating conformal predictions\n",
    "    endpoint=endpoint,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_update=X_test,\n",
    "    y_update=y_test,\n",
    "    X_score=X_score,\n",
    "    y_score=y_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Using updated training set <a id='updated-train-set'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the updated training set, new machine learning models are trained. This is can be done with the `train_update_acp` class. The crossvalidation splits from the [2.2. Using different calibration sets](#different-cal-sets) part were saved and can be accessed and used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get splits from crossvalidator, so that exactly the same splits can be used for train_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, test_index = cross_validator.train_indices, cross_validator.test_indices\n",
    "\n",
    "known_indices_sampler = KnownIndicesSampler(known_train=train_index, known_test=test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define ACP for train_update\n",
    "Difference to CPTox21AggregatedConformalPredictor: As we do not further update the calibration set for this experiment, we use the `train_update_acp` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_update_acp = AggregatedConformalPredictor(\n",
    "    predictor=icp, sampler=StratifiedRatioSampler(n_folds=n_folds_acp, random_state=set_random_state), aggregation_func=np.median\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define train_update crossvalidator using same splits as before and crossvalidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_update_cross_validator = CPTox21TrainUpdateCrossValidator(\n",
    "    train_update_acp, cv_splitter=known_indices_sampler\n",
    ")\n",
    "\n",
    "train_update_cross_validation_dfs = train_update_cross_validator.cross_validate(\n",
    "    steps=10,  # Number of steps (significance level) for evaluating conformal predictions\n",
    "    endpoint=endpoint,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_update=X_test,\n",
    "    y_update=y_test,\n",
    "    X_score=X_score,\n",
    "    y_score=y_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate conformal predictions <a id='evaluate-cp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Calibration and efficiency plots <a id='cal-plots'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a calibration plot, the observed error rate for a batch of predictions is plotted against the expected error rate (diagonal line). For complementary tracing of the informational efficiency, we also plot the efficiency, defined as the ratio of single class predictions. The plots are, thus, called `calibration and efficiency plots` (CEPs). The firm lines in the plot are the mean values of a five-fold cross-validation, the shaded areas represent the standard deviation.\n",
    "\n",
    "Calibration plots are useful to assess the calibration of conformal prediction models and to analyse the impact of improvement strategies on the calibration (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-validation\n",
    "As proof-of-concept, let's look at the CEP of the cross-validation. Given the random stratified splitting and sufficient data, the expected error rate should follow the diagonal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[\"cv\"] = cross_validator.calibration_plot( \n",
    "    averaged_evaluation_df=cross_validator.averaged_evaluation_df_cv,\n",
    "    endpoint=endpoint,\n",
    "    title_name=\"cross-validation with original calibration set\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict score and test set using the aggregated conformal predictor with the 'original' calibration set\n",
    "If the training set and the predicted data originate from the same distribution, and if they are available in sufficient amount, the error rates should follow the diagonal line. Any deviations suggest deviations from the CP exchangeability assumption (or a too small data size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[\"pred_score\"] = cross_validator.calibration_plot(\n",
    "    averaged_evaluation_df=cross_validator.averaged_evaluation_df_pred_score,\n",
    "    endpoint=endpoint, \n",
    "    title_name=\"predict score set (original calibration set)\"\n",
    ")\n",
    "\n",
    "plots[\"pred_test\"] = cross_validator.calibration_plot(\n",
    "    averaged_evaluation_df=cross_validator.averaged_evaluation_df_pred_test,\n",
    "    endpoint=endpoint, \n",
    "    title_name=\"predict test set (original calibration set)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Update (increase) the training set with more recent data\n",
    "Probably the most intuitive way to improve the validity of the predictions will be to update the training set with more recent data. If \"old and new\" data are available, they can be combined to train a more up-to-date model. The following plots show the cross-validation of this model as well as the prediction of score data. \n",
    "\n",
    "For the prediction of the score data, we, usually (for most endpoints), do not see a big difference to the above CEP, since the number of recent compounds is almost negligible compared to the number of original training compounds. On the other hand, the more recent data would not be enough for training a model on them alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[\"train_update_cv\"] = train_update_cross_validator.calibration_plot(\n",
    "    averaged_evaluation_df=train_update_cross_validator.averaged_evaluation_df_cv,\n",
    "    endpoint=endpoint, \n",
    "    title_name=\"cross-validation with updated training set\"\n",
    ")\n",
    "\n",
    "plots[\"train_update_pred_score\"] = train_update_cross_validator.calibration_plot(\n",
    "    averaged_evaluation_df=train_update_cross_validator.averaged_evaluation_df_pred_score,\n",
    "    endpoint=endpoint, \n",
    "    title_name=\"predict score set (updated training set)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Update (exchange) the calibration set with a more recent dataset\n",
    "If exchangeability between the datasets cannot be assumed, a proposed strategy to improve the applicability of the model, is to update the calibration set with more recent data.\n",
    "Based on the chronogical release of the Tox21 datasets, we assume that Tox21test is more similar to Tox21 score than Tox21 train. Thus Tox21test is used to update the calibration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[\"cal_update\"] = cross_validator.calibration_plot(\n",
    "    averaged_evaluation_df=cross_validator.averaged_evaluation_df_cal_update,\n",
    "    endpoint=endpoint, \n",
    "    title_name=\"predict score set (updated calibration set)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Update (exchange) the calibration set with data, which are inherently exchangeable\n",
    "With the above updating experiment, we made an assumption about the similarity of the datasets. This assumption was not true for all datasets. Thus, a more suitable experiment would be to update the calibration set with one part (50%) of the score set and to predict the other part of the score set. This gives us the certainty that the calibration and the prediction set stem from the same distribution. Note, that this might be more suitable as a proof of concept, on the other hand it does not represent a real-life scenario. Furthermore, we might see a larger standard deviation in the error rate, as we predict fewer data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[\"cal_update2\"] = cross_validator.calibration_plot(\n",
    "    averaged_evaluation_df=cross_validator.averaged_evaluation_df_cal_update2,\n",
    "    endpoint=endpoint, \n",
    "    title_name=\"predict part of score set (updated calibration set \\n with (other) part of score set)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.  Root-mean-square deviations from the diagonal (rmsd) <a id='rmsd'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a value to compare the calibration plots (validity) over all experiments, we calculate the rmsd of the observed error rate to the expected error rate (for 10 significance levels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect data (evaluation dfs) from the cross-validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dfs = {}\n",
    "\n",
    "for strategy in [\"cv\", \"pred_score\", \"cal_update\", \"cal_update2\"]:\n",
    "    evaluation_dfs[strategy] = getattr(\n",
    "        cross_validator, f\"averaged_evaluation_df_{strategy}\"\n",
    "    )\n",
    "for strategy in [\"cv\", \"pred_score\"]:\n",
    "    evaluation_dfs[f\"{strategy}_train_update\"] = getattr(\n",
    "        train_update_cross_validator, f\"averaged_evaluation_df_{strategy}\"\n",
    "    )                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate rmsd's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsds = {}\n",
    "for k, v in evaluation_dfs.items():\n",
    "\n",
    "    rmsd = calculate_rmsd_from_df(v)\n",
    "    rmsds[k] = rmsd\n",
    "    \n",
    "rmsds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot\n",
    "To visualise the rmsds over all strategies, a scatter plot can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmsds(rmsds, strategies, endpoint=endpoint):\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    \n",
    "    plt.scatter(strategies, [rmsds[s] for s in strategies], marker='_', s=500)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.title(f\"rmsds for different CP set-ups - {endpoint} endpoint\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = rmsds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmsds(rmsds, strategies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
