{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPTox21: Conformal prediction and exchangeability in in vitro toxicological datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, it is shown how the experiments for the CPTox21 manuscript (train model and make predictions with Tox21 data, update the training and/or calibration set) are run for multiple endpoints. Furthermore the evaluation over all enpoints in the form of boxplots is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from nonconformist.nc import NcFactory, MarginErrFunc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cptox21 import (\n",
    "    define_path, load_signatures_files, InductiveConformalPredictor,\n",
    "    CPTox21AggregatedConformalPredictor, AggregatedConformalPredictor, \n",
    "    StratifiedRatioSampler, CrossValidationSampler, KnownIndicesSampler,\n",
    "    CPTox21CrossValidator, CPTox21TrainUpdateCrossValidator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    filename='test_logger.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO)\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.ERROR)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_signatures_path = \"../data/data_signatures/\"\n",
    "data_statistics_path = \"../data/data_statistics/\"\n",
    "data_statistics_path = \"../../../KT-ER/cptox21_pipeline/data/data_curta_200909/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define if model fitting and predictions are required (set to True) or if data are already\n",
    "# available (set to False)\n",
    "run_experiment = False #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_folds_acp = 3# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = [\n",
    "    'SR_ATAD5', 'NR_ER', 'NR_AR', 'SR_HSE', 'SR_MMP', 'SR_p53', 'NR_Aromatase',\n",
    "    'SR_ARE', 'NR_AR_LBD', 'NR_AhR', 'NR_ER_LBD', 'NR_PPAR_gamma'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(endpoint):\n",
    "    \"\"\"\n",
    "    Load signature datasets per endpoint\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    endpoint : endpoint for which the data should be loaded\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train : (signature) descriptors for Tox21train set\n",
    "    y_train : labels for Tox21train set\n",
    "    X_test : (signature) descriptors for Tox21test set\n",
    "    y_test : labels for Tox21test set\n",
    "    X_score : (signature) descriptors for Tox21score set\n",
    "    y_score : labels for Tox21score set\n",
    "    \n",
    "    \"\"\"\n",
    "    datasets = [\"train\", \"test\", \"score\"]\n",
    "    train_path = define_path(endpoint=endpoint, data=datasets[0], signatures_path=data_signatures_path)\n",
    "    test_path = define_path(endpoint=endpoint, data=datasets[1], signatures_path=data_signatures_path)\n",
    "    score_path = define_path(endpoint=endpoint, data=datasets[2], signatures_path=data_signatures_path)\n",
    "\n",
    "    X_train, y_train, X_test, y_test, X_score, y_score = load_signatures_files(train_path, test_path, score_path)\n",
    "    X_train = X_train[:500]\n",
    "    y_train = y_train[:500]\n",
    "    return X_train, y_train, X_test, y_test, X_score, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_compare_calibration_sets(\n",
    "    endpoint, X_train, y_train, X_test, y_test, X_score, y_score\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform a crossvalidation, including the following settings:\n",
    "    * use original training and calibration set (Tox21train): predict internal test set (Tox21train)\n",
    "    * use original training and calibration set: predict score set (Tox21score)\n",
    "    * use original training and calibration set: predict test set (Tox21test)\n",
    "    * update calibration set with Tox21test: predict score set\n",
    "    * update calibration set with part of Tox21score: predict (other) part of Tox21score\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    endpoint : endpoint for which the data should be loaded\n",
    "    \n",
    "    X_train : (signature) descriptors for Tox21train set\n",
    "    y_train : labels for Tox21train set\n",
    "    X_test : (signature) descriptors for Tox21test set\n",
    "    y_test : labels for Tox21test set\n",
    "    X_score : (signature) descriptors for Tox21score set\n",
    "    y_score : labels for Tox21score set\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cross_validator : cross_validator class with fitted and calibrated models and evaluation dfs\n",
    "    \"\"\"\n",
    "    cross_validator = CPTox21CrossValidator(\n",
    "            acp, cv_splitter=CrossValidationSampler(),\n",
    "            score_splitter=StratifiedRatioSampler(test_ratio=0.5)\n",
    "        )\n",
    "    cross_validation_dfs = cross_validator.cross_validate(\n",
    "            steps=10,\n",
    "            endpoint=endpoint,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_update=X_test,\n",
    "            y_update=y_test,\n",
    "            X_score=X_score,\n",
    "            y_score=y_score,\n",
    "        )\n",
    "    return cross_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_with_updated_training_set(\n",
    "    endpoint, X_train, y_train, X_test, y_test, X_score, y_score, known_indices_sampler\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform a crossvalidation, including the following settings:\n",
    "    * update original training set (Tox21train) with Tox21test: predict internal test set (Tox21train & Tox21test)\n",
    "    * update original training set (Tox21train) with Tox21test: predict score set (Tox21score)\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    endpoint : endpoint for which the data should be loaded\n",
    "    \n",
    "    X_train : (signature) descriptors for Tox21train set\n",
    "    y_train : labels for Tox21train set\n",
    "    X_test : (signature) descriptors for Tox21test set\n",
    "    y_test : labels for Tox21test set\n",
    "    X_score : (signature) descriptors for Tox21score set\n",
    "    y_score : labels for Tox21score set\n",
    "    \n",
    "    known_indices_sampler: Sampler to split X_train and y_train in the same train and test sets\n",
    "    as used (known) for the previous experiments\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cross_validator : cross_validator class with fitted and calibrated models and evaluation dfs\n",
    "    \"\"\"\n",
    "    train_update_cross_validator = CPTox21TrainUpdateCrossValidator(\n",
    "    train_update_acp, cv_splitter=known_indices_sampler\n",
    ")\n",
    "\n",
    "    train_update_cross_validation_dfs = train_update_cross_validator.cross_validate(steps=10,\n",
    "                                           endpoint=endpoint,\n",
    "                                           X_train=X_train,\n",
    "                                           y_train=y_train,\n",
    "                                           X_update=X_test,\n",
    "                                           y_update=y_test,\n",
    "                                           X_score=X_score,\n",
    "                                           y_score=y_score,\n",
    "                                           class_wise_evaluation=False)\n",
    "    return train_update_cross_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo: import from cptox21.py!!!!!!\n",
    "\n",
    "def calculate_deviation_square(error, sl):\n",
    "    \"\"\"\n",
    "    Calculate the square deviation between a given error value and a significance level\n",
    "    Parameters\n",
    "    ----------\n",
    "    error : error\n",
    "    sl : significance level\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    square deviation\n",
    "    \n",
    "    \"\"\"\n",
    "    return (error-sl)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmsd_from_df(eval_df, cl=None):\n",
    "    \"\"\"\n",
    "    Calculate the rmsd (root mean square deviation) for all error-significance level pairs\n",
    "    in a dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_df : dataframe for which the rmsd should be calculated\n",
    "    cl : class of compounds for which the rmsd should be calculated, i.e. 0 or 1\n",
    "    if cl is None, the overall rmsd for all compounds will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe with an additional 'rmsd' column\n",
    "    \n",
    "    \"\"\"\n",
    "    if cl:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_deviation_square(\n",
    "            row[f\"error_rate_{cl} mean\"],   row[\"significance_level\"]), axis=1)\n",
    "    else:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_deviation_square(\n",
    "            row[\"error_rate mean\"], row[\"significance_level\"]), axis=1)\n",
    "    rmsd = np.round(math.sqrt(np.mean(eval_df[\"square\"])), 3)\n",
    "    \n",
    "    return rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_deviation_square(error, sl):\n",
    "    \"\"\"\n",
    "    Calculate the square deviation between a given error value and a significance level\n",
    "    if the deviation is positive (>0)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    error : error\n",
    "    sl : significance level\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    square deviation or 0\n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "    if error > sl:\n",
    "        return (error-sl)**2\n",
    "    else:\n",
    "\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmsd_pos_from_df(eval_df, cl=None):\n",
    "    # fixme: exchange 'rmsd_pos' with a more appropriate term\n",
    "    \"\"\"\n",
    "    Calculate the rmsd (root mean square deviation) for all error-significance level pairs\n",
    "    in a dataframe if the deviation (error - significance level) is larger than 0\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_df : dataframe for which the rmsd_pos should be calculated\n",
    "    cl : class of compounds for which the rmsd_pos should be calculated, i.e. 0 or 1\n",
    "        if cl is None, the overall rmsd_pos for all compounds will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe with an additional 'rmsd_pos' column\n",
    "    \n",
    "    \"\"\"\n",
    "    if cl:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_pos_deviation_square(\n",
    "            row[f\"error_rate_{cl} mean\"],   row[\"significance_level\"]), axis=1)\n",
    "    else:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_pos_deviation_square(\n",
    "            row[\"error_rate mean\"], row[\"significance_level\"]), axis=1)\n",
    "    rmsd_pos = np.round(math.sqrt(np.mean(eval_df[\"square\"])), 3)\n",
    "    \n",
    "    return rmsd_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_rmsd(rmsds, rmsd_title, strategies=None):\n",
    "    if strategies is None:\n",
    "        strategies = [\"cv_original\", \"pred_score_original\", \"pred_score_trainupdate\",\n",
    "              \"pred_score_calupdate\", \"pred_score_calupdate2\"]\n",
    "    \"\"\"\n",
    "    Generate a boxplot with the rmsd values over multiple endpoints.\n",
    "    This function can be used to plot both rmsd or rmsd_pos values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    strategies : strategies or set-ups used when making the predictions (e.g. \"original_cv\")\n",
    "    rmsds : a dictionary with the strategies as keys and a list of rmsd values for all the\n",
    "        endpoints as values\n",
    "    rmsd_title : the naming for 'rmsd' which should be used in the plot title, e.g. \"rmsd\", \"rmsd_pos\"\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    plt.boxplot([rmsds[k] for k in strategies], labels=strategies)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.title(f\"{rmsd_title} over all endpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build conformal predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ICP\n",
    "clf = SVC(kernel='rbf', C=50, gamma=0.002, probability=True)\n",
    "error_function = MarginErrFunc()\n",
    "normaliser_model = None\n",
    "nc = NcFactory.create_nc(clf, err_func=error_function)\n",
    "icp = InductiveConformalPredictor(\n",
    "    nc_function=nc, condition=(lambda instance: instance[1])\n",
    ")  # Mondrian as (default) condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ACP (uses original and updated calibration sets)\n",
    "acp = CPTox21AggregatedConformalPredictor(\n",
    "        predictor=icp, sampler=StratifiedRatioSampler(n_folds=n_folds_acp),\n",
    "        aggregation_func=np.median\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ACP (accepts only one calibration set, used with updated training set)\n",
    "train_update_acp = AggregatedConformalPredictor(\n",
    "        predictor=icp, sampler=StratifiedRatioSampler(n_folds=n_folds_acp),\n",
    "        aggregation_func=np.median\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR_ATAD5\n",
      "NR_ER\n",
      "NR_AR\n",
      "SR_HSE\n",
      "SR_MMP\n",
      "SR_p53\n",
      "NR_Aromatase\n",
      "SR_ARE\n",
      "NR_AR_LBD\n",
      "NR_AhR\n",
      "NR_ER_LBD\n",
      "NR_PPAR_gamma\n"
     ]
    }
   ],
   "source": [
    "# fixme: alternatively, if models/predictions already fitted/made, we could load datasets \n",
    "# (instead of fitting/predicting everything again)\n",
    "\n",
    "evaluation_dfs = {\"cv_original\": [], \"pred_score_original\": [], \"pred_test_original\": [],\n",
    "                  \"pred_score_scp\": [],\n",
    "                 \"pred_score_calupdate\": [], \"pred_score_calupdate2\": [],\n",
    "                  \"cv_trainupdate\": [], \"pred_score_trainupdate\": []}\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint)\n",
    "    if run_experiment: # If we want to make calculations for all set-ups\n",
    "        \n",
    "        X_train, y_train, X_test, y_test, X_score, y_score = load_data(endpoint)\n",
    "        cptox21_cross_validator = cross_validate_compare_calibration_sets(\n",
    "            endpoint, X_train, y_train, X_test, y_test, X_score, y_score\n",
    "        )\n",
    "\n",
    "        evaluation_dfs[\"cv_original\"].append(cptox21_cross_validator.averaged_evaluation_df_cv)\n",
    "        evaluation_dfs[\"pred_score_original\"].append(\n",
    "            cptox21_cross_validator.averaged_evaluation_df_pred_score\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_calupdate\"].append(\n",
    "            cptox21_cross_validator.averaged_evaluation_df_pred_cal_update\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_calupdate2\"].append(\n",
    "            cptox21_cross_validator.averaged_evaluation_df_pred_cal_update2\n",
    "        )\n",
    "        \n",
    "        cptox21_cross_validator.averaged_evaluation_df_cv.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_cv_original.csv\"\n",
    "        )\n",
    "        cptox21_cross_validator.averaged_evaluation_df_pred_score.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_score_original.csv\"\n",
    "        )\n",
    "        cptox21_cross_validator.averaged_evaluation_df_pred_test.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_test_original.csv\"\n",
    "        )\n",
    "        cptox21_cross_validator.averaged_evaluation_df_pred_cal_update.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_score_calupdate.csv\"\n",
    "        )\n",
    "        cptox21_cross_validator.averaged_evaluation_df_pred_cal_update2.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_score_calupdate2.csv\"\n",
    "        )\n",
    "        \n",
    "        train_index, test_index = cptox21_cross_validator.train_indices, cptox21_cross_validator.test_indices\n",
    "        known_indices_sampler = KnownIndicesSampler(\n",
    "            known_train=train_index, known_test=test_index\n",
    "        )\n",
    "\n",
    "        train_update_cross_validator = cross_validate_with_updated_training_set(\n",
    "            endpoint, X_train, y_train, X_test, y_test, X_score, y_score, known_indices_sampler\n",
    "        )\n",
    "\n",
    "        evaluation_dfs[\"cv_trainupdate\"].append(train_update_cross_validator.averaged_evaluation_df_cv)\n",
    "        evaluation_dfs[\"pred_score_trainupdate\"].append(train_update_cross_validator.averaged_evaluation_df_pred_score)\n",
    "    \n",
    "        train_update_cross_validator.averaged_evaluation_df_cv.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_cv_trainupdate.csv\"\n",
    "        )\n",
    "        train_update_cross_validator.averaged_evaluation_df_pred_score.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_score_trainupdate.csv\"\n",
    "        )\n",
    "#     else: # If results are already available and dataframes can be loaded directly\n",
    "#         cv_original_df = pd.read_csv(f\"{data_statistics_path}{endpoint}_cv_original.csv\")\n",
    "#         evaluation_dfs[\"cv_original\"].append(cv_original_df)\n",
    "#         pred_score_original_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_pred_score_original.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"pred_score_original\"].append(pred_score_original_df)\n",
    "#         pred_test_original_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_pred_test_original.csv\"\n",
    "#         )\n",
    "#         pred_score_calupdate_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_pred_score_calupdate.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"pred_score_calupdate\"].append(pred_score_calupdate_df)\n",
    "#         pred_score_calupdate2_df = pd.read_csv(\n",
    "#              f\"{data_statistics_path}{endpoint}_pred_score_calupdate2.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"pred_score_calupdate2\"].append(pred_score_calupdate2_df)\n",
    "#         cv_trainupdate_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_cv_trainupdate.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"cv_trainupdate\"].append(cv_trainupdate_df)\n",
    "#         pred_score_trainupdate_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_pred_score_trainupdate.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"pred_score_trainupdate\"].append(pred_score_trainupdate_df)\n",
    "        \n",
    "    else: # If results are already available and dataframes can be loaded directly\n",
    "        cv_original_df = pd.read_csv(f\"{data_statistics_path}{endpoint}_averaged_eval_df_cv.csv\")\n",
    "        evaluation_dfs[\"cv_original\"].append(cv_original_df)\n",
    "        pred_score_original_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_pred_score.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_original\"].append(pred_score_original_df)\n",
    "        pred_test_original_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_pred_test.csv\"\n",
    "        )\n",
    "        pred_score_scp_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_pred_score_scp.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_scp\"].append(pred_score_scp_df)\n",
    "        pred_score_calupdate_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_cal_update.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_calupdate\"].append(pred_score_calupdate_df)\n",
    "        pred_score_calupdate2_df = pd.read_csv(\n",
    "             f\"{data_statistics_path}{endpoint}_averaged_eval_df_cal_update2.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_calupdate2\"].append(pred_score_calupdate2_df)\n",
    "        cv_trainupdate_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_cv_train_update.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"cv_trainupdate\"].append(cv_trainupdate_df)\n",
    "        pred_score_trainupdate_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_pred_score_train_update.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_trainupdate\"].append(pred_score_trainupdate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_original': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9140      0.009772           0.9142   \n",
       "  2                  0.2         0.8116      0.008355           0.8106   \n",
       "  3                  0.3         0.7084      0.009889           0.7076   \n",
       "  4                  0.4         0.6056      0.007092           0.6034   \n",
       "  5                  0.5         0.4966      0.012361           0.4950   \n",
       "  6                  0.6         0.3892      0.021052           0.3868   \n",
       "  7                  0.7         0.2810      0.020298           0.2784   \n",
       "  8                  0.8         0.1798      0.013755           0.1796   \n",
       "  9                  0.9         0.0840      0.013748           0.0850   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.011345           0.9068        0.029269           0.0860   \n",
       "  2         0.008820           0.8352        0.045444           0.1884   \n",
       "  3         0.011082           0.7356        0.058338           0.2916   \n",
       "  4         0.009607           0.6580        0.068132           0.3944   \n",
       "  5         0.014300           0.5432        0.063492           0.5034   \n",
       "  6         0.023124           0.4466        0.110484           0.6108   \n",
       "  7         0.022711           0.3440        0.096713           0.7190   \n",
       "  8         0.015630           0.1832        0.065937           0.8202   \n",
       "  9         0.013874           0.0558        0.023510           0.9160   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.009772             0.0858  ...        0.017170           0.8866   \n",
       "  2         0.008355             0.1894  ...        0.009381           0.8306   \n",
       "  3         0.009889             0.2924  ...        0.018426           0.8420   \n",
       "  4         0.007092             0.3966  ...        0.012194           0.8574   \n",
       "  5         0.012361             0.5050  ...        0.009039           0.8790   \n",
       "  6         0.021052             0.6132  ...        0.009044           0.8724   \n",
       "  7         0.020298             0.7216  ...        0.002168           0.8958   \n",
       "  8         0.013755             0.8204  ...        0.005404           0.8958   \n",
       "  9         0.013748             0.9150  ...        0.006686           0.9000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              322.0   \n",
       "  1         0.036363                   0.1              322.0   \n",
       "  2         0.045512                   0.2              322.0   \n",
       "  3         0.033548                   0.3              322.0   \n",
       "  4         0.032516                   0.4              322.0   \n",
       "  5         0.035637                   0.5              322.0   \n",
       "  6         0.043489                   0.6              322.0   \n",
       "  7         0.040413                   0.7              322.0   \n",
       "  8         0.091311                   0.8              322.0   \n",
       "  9         0.148978                   0.9              322.0   \n",
       "  10        0.000000                   1.0              322.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8179.0                25.0                 240.0   \n",
       "  1                8179.0                25.0                 240.0   \n",
       "  2                8179.0                25.0                 240.0   \n",
       "  3                8179.0                25.0                 240.0   \n",
       "  4                8179.0                25.0                 240.0   \n",
       "  5                8179.0                25.0                 240.0   \n",
       "  6                8179.0                25.0                 240.0   \n",
       "  7                8179.0                25.0                 240.0   \n",
       "  8                8179.0                25.0                 240.0   \n",
       "  9                8179.0                25.0                 240.0   \n",
       "  10               8179.0                25.0                 240.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                554.0  \n",
       "  1                36.0                554.0  \n",
       "  2                36.0                554.0  \n",
       "  3                36.0                554.0  \n",
       "  4                36.0                554.0  \n",
       "  5                36.0                554.0  \n",
       "  6                36.0                554.0  \n",
       "  7                36.0                554.0  \n",
       "  8                36.0                554.0  \n",
       "  9                36.0                554.0  \n",
       "  10               36.0                554.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9164      0.007127           0.9144   \n",
       "  2                  0.2         0.8228      0.011345           0.8232   \n",
       "  3                  0.3         0.7294      0.015339           0.7332   \n",
       "  4                  0.4         0.5996      0.018569           0.5990   \n",
       "  5                  0.5         0.4906      0.013353           0.4896   \n",
       "  6                  0.6         0.3796      0.019450           0.3750   \n",
       "  7                  0.7         0.2676      0.017615           0.2602   \n",
       "  8                  0.8         0.1624      0.019655           0.1604   \n",
       "  9                  0.9         0.0716      0.012260           0.0676   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005030           0.9290        0.023822           0.0836   \n",
       "  2         0.008468           0.8192        0.039556           0.1772   \n",
       "  3         0.010780           0.7050        0.062470           0.2706   \n",
       "  4         0.018802           0.6050        0.047524           0.4004   \n",
       "  5         0.015110           0.4996        0.060855           0.5094   \n",
       "  6         0.019170           0.4108        0.056654           0.6204   \n",
       "  7         0.016604           0.3208        0.061885           0.7324   \n",
       "  8         0.017487           0.1788        0.058255           0.8376   \n",
       "  9         0.011524           0.0998        0.043894           0.9284   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007127             0.0856  ...        0.020993           0.8842   \n",
       "  2         0.011345             0.1768  ...        0.010710           0.7750   \n",
       "  3         0.015339             0.2668  ...        0.009434           0.7016   \n",
       "  4         0.018569             0.4010  ...        0.012578           0.7168   \n",
       "  5         0.013353             0.5104  ...        0.021131           0.7268   \n",
       "  6         0.019450             0.6250  ...        0.018330           0.7424   \n",
       "  7         0.017615             0.7398  ...        0.013667           0.7704   \n",
       "  8         0.019655             0.8396  ...        0.010502           0.7436   \n",
       "  9         0.012260             0.9324  ...        0.007036           0.7378   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              901.0   \n",
       "  1         0.035647                   0.1              901.0   \n",
       "  2         0.046266                   0.2              901.0   \n",
       "  3         0.059785                   0.3              901.0   \n",
       "  4         0.050514                   0.4              901.0   \n",
       "  5         0.053420                   0.5              901.0   \n",
       "  6         0.053896                   0.6              901.0   \n",
       "  7         0.048727                   0.7              901.0   \n",
       "  8         0.094166                   0.8              901.0   \n",
       "  9         0.137210                   0.9              901.0   \n",
       "  10        0.000000                   1.0              901.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6290.0                27.0                 231.0   \n",
       "  1                6290.0                27.0                 231.0   \n",
       "  2                6290.0                27.0                 231.0   \n",
       "  3                6290.0                27.0                 231.0   \n",
       "  4                6290.0                27.0                 231.0   \n",
       "  5                6290.0                27.0                 231.0   \n",
       "  6                6290.0                27.0                 231.0   \n",
       "  7                6290.0                27.0                 231.0   \n",
       "  8                6290.0                27.0                 231.0   \n",
       "  9                6290.0                27.0                 231.0   \n",
       "  10               6290.0                27.0                 231.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                49.0                441.0  \n",
       "  1                49.0                441.0  \n",
       "  2                49.0                441.0  \n",
       "  3                49.0                441.0  \n",
       "  4                49.0                441.0  \n",
       "  5                49.0                441.0  \n",
       "  6                49.0                441.0  \n",
       "  7                49.0                441.0  \n",
       "  8                49.0                441.0  \n",
       "  9                49.0                441.0  \n",
       "  10               49.0                441.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9238      0.010498           0.9240   \n",
       "  2                  0.2         0.8242      0.017370           0.8238   \n",
       "  3                  0.3         0.7168      0.013217           0.7176   \n",
       "  4                  0.4         0.6008      0.013664           0.6008   \n",
       "  5                  0.5         0.4788      0.016514           0.4762   \n",
       "  6                  0.6         0.3604      0.016273           0.3572   \n",
       "  7                  0.7         0.2492      0.011032           0.2476   \n",
       "  8                  0.8         0.1498      0.005167           0.1472   \n",
       "  9                  0.9         0.0622      0.009550           0.0614   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010677           0.9198        0.070680           0.0762   \n",
       "  2         0.017167           0.8342        0.082144           0.1758   \n",
       "  3         0.012033           0.6920        0.080430           0.2832   \n",
       "  4         0.013442           0.6004        0.039100           0.3992   \n",
       "  5         0.017108           0.5338        0.020608           0.5212   \n",
       "  6         0.016377           0.4290        0.033354           0.6396   \n",
       "  7         0.009290           0.2872        0.080107           0.7508   \n",
       "  8         0.006140           0.2092        0.065171           0.8502   \n",
       "  9         0.010334           0.0802        0.041051           0.9378   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.010498             0.0760  ...        0.058415           0.8910   \n",
       "  2         0.017370             0.1762  ...        0.047069           0.8022   \n",
       "  3         0.013217             0.2824  ...        0.041487           0.7054   \n",
       "  4         0.013664             0.3992  ...        0.034056           0.7164   \n",
       "  5         0.016514             0.5238  ...        0.002387           0.7368   \n",
       "  6         0.016273             0.6428  ...        0.002236           0.7416   \n",
       "  7         0.011032             0.7524  ...        0.003082           0.7234   \n",
       "  8         0.005167             0.8528  ...        0.001789           0.7772   \n",
       "  9         0.009550             0.9386  ...        0.000000           0.7818   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              373.0   \n",
       "  1         0.093672                   0.1              373.0   \n",
       "  2         0.091606                   0.2              373.0   \n",
       "  3         0.054684                   0.3              373.0   \n",
       "  4         0.054510                   0.4              373.0   \n",
       "  5         0.054843                   0.5              373.0   \n",
       "  6         0.093302                   0.6              373.0   \n",
       "  7         0.133281                   0.7              373.0   \n",
       "  8         0.101802                   0.8              373.0   \n",
       "  9         0.149455                   0.9              373.0   \n",
       "  10        0.000000                   1.0              373.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8370.0                 3.0                 282.0   \n",
       "  1                8370.0                 3.0                 282.0   \n",
       "  2                8370.0                 3.0                 282.0   \n",
       "  3                8370.0                 3.0                 282.0   \n",
       "  4                8370.0                 3.0                 282.0   \n",
       "  5                8370.0                 3.0                 282.0   \n",
       "  6                8370.0                 3.0                 282.0   \n",
       "  7                8370.0                 3.0                 282.0   \n",
       "  8                8370.0                 3.0                 282.0   \n",
       "  9                8370.0                 3.0                 282.0   \n",
       "  10               8370.0                 3.0                 282.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                11.0                549.0  \n",
       "  1                11.0                549.0  \n",
       "  2                11.0                549.0  \n",
       "  3                11.0                549.0  \n",
       "  4                11.0                549.0  \n",
       "  5                11.0                549.0  \n",
       "  6                11.0                549.0  \n",
       "  7                11.0                549.0  \n",
       "  8                11.0                549.0  \n",
       "  9                11.0                549.0  \n",
       "  10               11.0                549.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9178      0.007190           0.9188   \n",
       "  2                  0.2         0.8342      0.013773           0.8356   \n",
       "  3                  0.3         0.7142      0.016407           0.7134   \n",
       "  4                  0.4         0.6086      0.015805           0.6092   \n",
       "  5                  0.5         0.4988      0.021064           0.4990   \n",
       "  6                  0.6         0.3836      0.012837           0.3820   \n",
       "  7                  0.7         0.2732      0.014704           0.2700   \n",
       "  8                  0.8         0.1750      0.013134           0.1716   \n",
       "  9                  0.9         0.0768      0.007463           0.0776   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006221           0.9044        0.059643           0.0822   \n",
       "  2         0.010807           0.8058        0.102346           0.1658   \n",
       "  3         0.011546           0.7256        0.121964           0.2858   \n",
       "  4         0.013682           0.6062        0.094919           0.3914   \n",
       "  5         0.019326           0.4950        0.080477           0.5012   \n",
       "  6         0.011705           0.4178        0.089542           0.6164   \n",
       "  7         0.013509           0.3348        0.084206           0.7268   \n",
       "  8         0.014011           0.2388        0.049022           0.8250   \n",
       "  9         0.008473           0.0624        0.028183           0.9232   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007190             0.0812  ...        0.020413           0.8604   \n",
       "  2         0.013773             0.1644  ...        0.017044           0.7822   \n",
       "  3         0.016407             0.2866  ...        0.032439           0.7544   \n",
       "  4         0.015805             0.3908  ...        0.017132           0.7620   \n",
       "  5         0.021064             0.5010  ...        0.014509           0.7648   \n",
       "  6         0.012837             0.6180  ...        0.008325           0.7788   \n",
       "  7         0.014704             0.7300  ...        0.004336           0.7842   \n",
       "  8         0.013134             0.8284  ...        0.004416           0.8484   \n",
       "  9         0.007463             0.9224  ...        0.009813           0.8150   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              386.0   \n",
       "  1         0.086228                   0.1              386.0   \n",
       "  2         0.111502                   0.2              386.0   \n",
       "  3         0.100987                   0.3              386.0   \n",
       "  4         0.103976                   0.4              386.0   \n",
       "  5         0.121874                   0.5              386.0   \n",
       "  6         0.144394                   0.6              386.0   \n",
       "  7         0.149500                   0.7              386.0   \n",
       "  8         0.127473                   0.8              386.0   \n",
       "  9         0.247235                   0.9              386.0   \n",
       "  10        0.000000                   1.0              386.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7233.0                10.0                 250.0   \n",
       "  1                7233.0                10.0                 250.0   \n",
       "  2                7233.0                10.0                 250.0   \n",
       "  3                7233.0                10.0                 250.0   \n",
       "  4                7233.0                10.0                 250.0   \n",
       "  5                7233.0                10.0                 250.0   \n",
       "  6                7233.0                10.0                 250.0   \n",
       "  7                7233.0                10.0                 250.0   \n",
       "  8                7233.0                10.0                 250.0   \n",
       "  9                7233.0                10.0                 250.0   \n",
       "  10               7233.0                10.0                 250.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                19.0                558.0  \n",
       "  1                19.0                558.0  \n",
       "  2                19.0                558.0  \n",
       "  3                19.0                558.0  \n",
       "  4                19.0                558.0  \n",
       "  5                19.0                558.0  \n",
       "  6                19.0                558.0  \n",
       "  7                19.0                558.0  \n",
       "  8                19.0                558.0  \n",
       "  9                19.0                558.0  \n",
       "  10               19.0                558.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9112      0.008983           0.9114   \n",
       "  2                  0.2         0.8182      0.006058           0.8166   \n",
       "  3                  0.3         0.7028      0.015123           0.6982   \n",
       "  4                  0.4         0.5960      0.014457           0.5870   \n",
       "  5                  0.5         0.5014      0.015947           0.4938   \n",
       "  6                  0.6         0.3932      0.014114           0.3828   \n",
       "  7                  0.7         0.2790      0.014265           0.2806   \n",
       "  8                  0.8         0.1864      0.013465           0.1844   \n",
       "  9                  0.9         0.0882      0.011077           0.0886   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009099           0.9094        0.017038           0.0888   \n",
       "  2         0.008905           0.8254        0.009813           0.1818   \n",
       "  3         0.016131           0.7276        0.015339           0.2972   \n",
       "  4         0.012942           0.6436        0.030072           0.4040   \n",
       "  5         0.014481           0.5390        0.032962           0.4986   \n",
       "  6         0.013480           0.4470        0.030741           0.6068   \n",
       "  7         0.015582           0.2716        0.021279           0.7210   \n",
       "  8         0.012681           0.1966        0.028059           0.8136   \n",
       "  9         0.010114           0.0870        0.025622           0.9118   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.008983             0.0886  ...        0.009257           0.9030   \n",
       "  2         0.006058             0.1834  ...        0.009670           0.8922   \n",
       "  3         0.015123             0.3018  ...        0.005215           0.9194   \n",
       "  4         0.014457             0.4130  ...        0.003271           0.9450   \n",
       "  5         0.015947             0.5062  ...        0.005273           0.9534   \n",
       "  6         0.014114             0.6172  ...        0.008019           0.9614   \n",
       "  7         0.014265             0.7194  ...        0.007918           0.9634   \n",
       "  8         0.013465             0.8156  ...        0.010761           0.9746   \n",
       "  9         0.011077             0.9114  ...        0.016583           0.9630   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1094.0   \n",
       "  1         0.016016                   0.1             1094.0   \n",
       "  2         0.007596                   0.2             1094.0   \n",
       "  3         0.020513                   0.3             1094.0   \n",
       "  4         0.017132                   0.4             1094.0   \n",
       "  5         0.020330                   0.5             1094.0   \n",
       "  6         0.019360                   0.6             1094.0   \n",
       "  7         0.028728                   0.7             1094.0   \n",
       "  8         0.020912                   0.8             1094.0   \n",
       "  9         0.036304                   0.9             1094.0   \n",
       "  10        0.000000                   1.0             1094.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5719.0                38.0                 195.0   \n",
       "  1                5719.0                38.0                 195.0   \n",
       "  2                5719.0                38.0                 195.0   \n",
       "  3                5719.0                38.0                 195.0   \n",
       "  4                5719.0                38.0                 195.0   \n",
       "  5                5719.0                38.0                 195.0   \n",
       "  6                5719.0                38.0                 195.0   \n",
       "  7                5719.0                38.0                 195.0   \n",
       "  8                5719.0                38.0                 195.0   \n",
       "  9                5719.0                38.0                 195.0   \n",
       "  10               5719.0                38.0                 195.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                56.0                457.0  \n",
       "  1                56.0                457.0  \n",
       "  2                56.0                457.0  \n",
       "  3                56.0                457.0  \n",
       "  4                56.0                457.0  \n",
       "  5                56.0                457.0  \n",
       "  6                56.0                457.0  \n",
       "  7                56.0                457.0  \n",
       "  8                56.0                457.0  \n",
       "  9                56.0                457.0  \n",
       "  10               56.0                457.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9198      0.012931           0.9192   \n",
       "  2                  0.2         0.8212      0.015320           0.8210   \n",
       "  3                  0.3         0.7038      0.009039           0.7022   \n",
       "  4                  0.4         0.6006      0.016577           0.5970   \n",
       "  5                  0.5         0.4930      0.022439           0.4888   \n",
       "  6                  0.6         0.3986      0.018528           0.3950   \n",
       "  7                  0.7         0.2882      0.013517           0.2830   \n",
       "  8                  0.8         0.1856      0.015805           0.1834   \n",
       "  9                  0.9         0.0840      0.009274           0.0854   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.014255           0.9280        0.047723           0.0802   \n",
       "  2         0.017479           0.8252        0.056238           0.1788   \n",
       "  3         0.014653           0.7264        0.088540           0.2962   \n",
       "  4         0.020037           0.6546        0.064248           0.3994   \n",
       "  5         0.025762           0.5514        0.073122           0.5070   \n",
       "  6         0.022316           0.4562        0.072905           0.6014   \n",
       "  7         0.015859           0.3670        0.050922           0.7118   \n",
       "  8         0.019178           0.2214        0.054811           0.8144   \n",
       "  9         0.009423           0.0584        0.015339           0.9160   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.012931             0.0808  ...        0.026954           0.9118   \n",
       "  2         0.015320             0.1790  ...        0.031591           0.8302   \n",
       "  3         0.009039             0.2978  ...        0.018289           0.8476   \n",
       "  4         0.016577             0.4030  ...        0.016025           0.8934   \n",
       "  5         0.022439             0.5112  ...        0.012853           0.9350   \n",
       "  6         0.018528             0.6050  ...        0.006580           0.9560   \n",
       "  7         0.013517             0.7170  ...        0.003114           0.9606   \n",
       "  8         0.015805             0.8166  ...        0.006723           0.9700   \n",
       "  9         0.009274             0.9146  ...        0.006042           0.9666   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              515.0   \n",
       "  1         0.059713                   0.1              515.0   \n",
       "  2         0.049651                   0.2              515.0   \n",
       "  3         0.059660                   0.3              515.0   \n",
       "  4         0.040581                   0.4              515.0   \n",
       "  5         0.053977                   0.5              515.0   \n",
       "  6         0.028766                   0.6              515.0   \n",
       "  7         0.025334                   0.7              515.0   \n",
       "  8         0.027991                   0.8              515.0   \n",
       "  9         0.074685                   0.9              515.0   \n",
       "  10        0.000000                   1.0              515.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7542.0                28.0                 234.0   \n",
       "  1                7542.0                28.0                 234.0   \n",
       "  2                7542.0                28.0                 234.0   \n",
       "  3                7542.0                28.0                 234.0   \n",
       "  4                7542.0                28.0                 234.0   \n",
       "  5                7542.0                28.0                 234.0   \n",
       "  6                7542.0                28.0                 234.0   \n",
       "  7                7542.0                28.0                 234.0   \n",
       "  8                7542.0                28.0                 234.0   \n",
       "  9                7542.0                28.0                 234.0   \n",
       "  10               7542.0                28.0                 234.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                40.0                543.0  \n",
       "  1                40.0                543.0  \n",
       "  2                40.0                543.0  \n",
       "  3                40.0                543.0  \n",
       "  4                40.0                543.0  \n",
       "  5                40.0                543.0  \n",
       "  6                40.0                543.0  \n",
       "  7                40.0                543.0  \n",
       "  8                40.0                543.0  \n",
       "  9                40.0                543.0  \n",
       "  10               40.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9154      0.011803           0.9156   \n",
       "  2                  0.2         0.8062      0.015222           0.8064   \n",
       "  3                  0.3         0.7046      0.013069           0.7056   \n",
       "  4                  0.4         0.5978      0.011122           0.5974   \n",
       "  5                  0.5         0.4866      0.011803           0.4858   \n",
       "  6                  0.6         0.3822      0.014237           0.3802   \n",
       "  7                  0.7         0.2810      0.020100           0.2780   \n",
       "  8                  0.8         0.1778      0.011122           0.1748   \n",
       "  9                  0.9         0.0846      0.005079           0.0862   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010854           0.9170        0.038549           0.0846   \n",
       "  2         0.013704           0.8044        0.046533           0.1938   \n",
       "  3         0.013315           0.6896        0.033665           0.2954   \n",
       "  4         0.008905           0.6036        0.057374           0.4022   \n",
       "  5         0.010663           0.5000        0.061814           0.5134   \n",
       "  6         0.012677           0.4172        0.045538           0.6178   \n",
       "  7         0.017649           0.3370        0.072646           0.7190   \n",
       "  8         0.008899           0.2336        0.081168           0.8222   \n",
       "  9         0.004550           0.0504        0.036875           0.9154   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.011803             0.0844  ...        0.012865           0.8908   \n",
       "  2         0.015222             0.1936  ...        0.012775           0.7976   \n",
       "  3         0.013069             0.2944  ...        0.009864           0.8040   \n",
       "  4         0.011122             0.4026  ...        0.003564           0.8560   \n",
       "  5         0.011803             0.5142  ...        0.005263           0.8892   \n",
       "  6         0.014237             0.6198  ...        0.005167           0.9154   \n",
       "  7         0.020100             0.7220  ...        0.002881           0.9342   \n",
       "  8         0.011122             0.8252  ...        0.004930           0.9360   \n",
       "  9         0.005079             0.9138  ...        0.008050           0.9750   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              338.0   \n",
       "  1         0.048623                   0.1              338.0   \n",
       "  2         0.044439                   0.2              338.0   \n",
       "  3         0.044441                   0.3              338.0   \n",
       "  4         0.042732                   0.4              338.0   \n",
       "  5         0.057399                   0.5              338.0   \n",
       "  6         0.056047                   0.6              338.0   \n",
       "  7         0.061467                   0.7              338.0   \n",
       "  8         0.060782                   0.8              338.0   \n",
       "  9         0.055902                   0.9              338.0   \n",
       "  10        0.000000                   1.0              338.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6362.0                18.0                 192.0   \n",
       "  1                6362.0                18.0                 192.0   \n",
       "  2                6362.0                18.0                 192.0   \n",
       "  3                6362.0                18.0                 192.0   \n",
       "  4                6362.0                18.0                 192.0   \n",
       "  5                6362.0                18.0                 192.0   \n",
       "  6                6362.0                18.0                 192.0   \n",
       "  7                6362.0                18.0                 192.0   \n",
       "  8                6362.0                18.0                 192.0   \n",
       "  9                6362.0                18.0                 192.0   \n",
       "  10               6362.0                18.0                 192.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                466.0  \n",
       "  1                36.0                466.0  \n",
       "  2                36.0                466.0  \n",
       "  3                36.0                466.0  \n",
       "  4                36.0                466.0  \n",
       "  5                36.0                466.0  \n",
       "  6                36.0                466.0  \n",
       "  7                36.0                466.0  \n",
       "  8                36.0                466.0  \n",
       "  9                36.0                466.0  \n",
       "  10               36.0                466.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9144      0.005128           0.9138   \n",
       "  2                  0.2         0.8178      0.010849           0.8182   \n",
       "  3                  0.3         0.7210      0.008093           0.7208   \n",
       "  4                  0.4         0.5976      0.011059           0.5946   \n",
       "  5                  0.5         0.4970      0.012450           0.4960   \n",
       "  6                  0.6         0.3828      0.012617           0.3804   \n",
       "  7                  0.7         0.2820      0.011662           0.2762   \n",
       "  8                  0.8         0.1778      0.013953           0.1754   \n",
       "  9                  0.9         0.0752      0.007014           0.0752   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005848           0.9176        0.024966           0.0856   \n",
       "  2         0.009418           0.8156        0.041168           0.1822   \n",
       "  3         0.007050           0.7200        0.034605           0.2790   \n",
       "  4         0.013164           0.6142        0.037459           0.4024   \n",
       "  5         0.019144           0.5030        0.029095           0.5030   \n",
       "  6         0.018555           0.3952        0.023900           0.6172   \n",
       "  7         0.015189           0.3140        0.022439           0.7180   \n",
       "  8         0.014153           0.1890        0.037276           0.8222   \n",
       "  9         0.009524           0.0744        0.030270           0.9248   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.005128             0.0862  ...        0.016208           0.8886   \n",
       "  2         0.010849             0.1818  ...        0.009757           0.8112   \n",
       "  3         0.008093             0.2792  ...        0.014890           0.8200   \n",
       "  4         0.011059             0.4054  ...        0.008426           0.8386   \n",
       "  5         0.012450             0.5040  ...        0.012174           0.8470   \n",
       "  6         0.012617             0.6196  ...        0.015222           0.8734   \n",
       "  7         0.011662             0.7238  ...        0.013795           0.8952   \n",
       "  8         0.013953             0.8246  ...        0.015166           0.8974   \n",
       "  9         0.007014             0.9248  ...        0.008031           0.9156   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1032.0   \n",
       "  1         0.033193                   0.1             1032.0   \n",
       "  2         0.040727                   0.2             1032.0   \n",
       "  3         0.031040                   0.3             1032.0   \n",
       "  4         0.032822                   0.4             1032.0   \n",
       "  5         0.020248                   0.5             1032.0   \n",
       "  6         0.032470                   0.6             1032.0   \n",
       "  7         0.024150                   0.7             1032.0   \n",
       "  8         0.059374                   0.8             1032.0   \n",
       "  9         0.080606                   0.9             1032.0   \n",
       "  10        0.000000                   1.0             1032.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5653.0                47.0                 181.0   \n",
       "  1                5653.0                47.0                 181.0   \n",
       "  2                5653.0                47.0                 181.0   \n",
       "  3                5653.0                47.0                 181.0   \n",
       "  4                5653.0                47.0                 181.0   \n",
       "  5                5653.0                47.0                 181.0   \n",
       "  6                5653.0                47.0                 181.0   \n",
       "  7                5653.0                47.0                 181.0   \n",
       "  8                5653.0                47.0                 181.0   \n",
       "  9                5653.0                47.0                 181.0   \n",
       "  10               5653.0                47.0                 181.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                89.0                433.0  \n",
       "  1                89.0                433.0  \n",
       "  2                89.0                433.0  \n",
       "  3                89.0                433.0  \n",
       "  4                89.0                433.0  \n",
       "  5                89.0                433.0  \n",
       "  6                89.0                433.0  \n",
       "  7                89.0                433.0  \n",
       "  8                89.0                433.0  \n",
       "  9                89.0                433.0  \n",
       "  10               89.0                433.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9224      0.010407           0.9226   \n",
       "  2                  0.2         0.8154      0.016471           0.8148   \n",
       "  3                  0.3         0.7096      0.020256           0.7088   \n",
       "  4                  0.4         0.5994      0.029501           0.5980   \n",
       "  5                  0.5         0.4924      0.023755           0.4908   \n",
       "  6                  0.6         0.3788      0.016724           0.3790   \n",
       "  7                  0.7         0.2712      0.013590           0.2706   \n",
       "  8                  0.8         0.1674      0.014188           0.1666   \n",
       "  9                  0.9         0.0772      0.011862           0.0770   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010877           0.9218        0.025782           0.0776   \n",
       "  2         0.017370           0.8338        0.046687           0.1846   \n",
       "  3         0.021324           0.7358        0.055868           0.2904   \n",
       "  4         0.027776           0.6340        0.089994           0.4006   \n",
       "  5         0.023317           0.5286        0.085778           0.5076   \n",
       "  6         0.015572           0.3696        0.101574           0.6212   \n",
       "  7         0.013012           0.2880        0.070093           0.7288   \n",
       "  8         0.014724           0.1896        0.032416           0.8326   \n",
       "  9         0.012247           0.0816        0.027934           0.9228   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.010407             0.0774  ...        0.024197           0.9100   \n",
       "  2         0.016471             0.1852  ...        0.032199           0.8506   \n",
       "  3         0.020256             0.2912  ...        0.005320           0.8508   \n",
       "  4         0.029501             0.4020  ...        0.001304           0.8470   \n",
       "  5         0.023755             0.5092  ...        0.000837           0.8780   \n",
       "  6         0.016724             0.6210  ...        0.001095           0.8554   \n",
       "  7         0.013590             0.7294  ...        0.001095           0.8662   \n",
       "  8         0.014188             0.8334  ...        0.000000           0.8884   \n",
       "  9         0.011862             0.9230  ...        0.000000           0.9500   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              295.0   \n",
       "  1         0.030684                   0.1              295.0   \n",
       "  2         0.031580                   0.2              295.0   \n",
       "  3         0.025665                   0.3              295.0   \n",
       "  4         0.042509                   0.4              295.0   \n",
       "  5         0.042638                   0.5              295.0   \n",
       "  6         0.060194                   0.6              295.0   \n",
       "  7         0.035124                   0.7              295.0   \n",
       "  8         0.067814                   0.8              295.0   \n",
       "  9         0.111803                   0.9              295.0   \n",
       "  10        0.000000                   1.0              295.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7742.0                 4.0                 242.0   \n",
       "  1                7742.0                 4.0                 242.0   \n",
       "  2                7742.0                 4.0                 242.0   \n",
       "  3                7742.0                 4.0                 242.0   \n",
       "  4                7742.0                 4.0                 242.0   \n",
       "  5                7742.0                 4.0                 242.0   \n",
       "  6                7742.0                 4.0                 242.0   \n",
       "  7                7742.0                 4.0                 242.0   \n",
       "  8                7742.0                 4.0                 242.0   \n",
       "  9                7742.0                 4.0                 242.0   \n",
       "  10               7742.0                 4.0                 242.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                 8.0                543.0  \n",
       "  1                 8.0                543.0  \n",
       "  2                 8.0                543.0  \n",
       "  3                 8.0                543.0  \n",
       "  4                 8.0                543.0  \n",
       "  5                 8.0                543.0  \n",
       "  6                 8.0                543.0  \n",
       "  7                 8.0                543.0  \n",
       "  8                 8.0                543.0  \n",
       "  9                 8.0                543.0  \n",
       "  10                8.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9140      0.004848           0.9146   \n",
       "  2                  0.2         0.8268      0.008899           0.8276   \n",
       "  3                  0.3         0.7128      0.016254           0.7100   \n",
       "  4                  0.4         0.6124      0.014046           0.6108   \n",
       "  5                  0.5         0.5130      0.010124           0.5076   \n",
       "  6                  0.6         0.3926      0.011194           0.3856   \n",
       "  7                  0.7         0.2844      0.009397           0.2808   \n",
       "  8                  0.8         0.1732      0.005357           0.1748   \n",
       "  9                  0.9         0.0850      0.011554           0.0836   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007603           0.9078        0.032430           0.0860   \n",
       "  2         0.012442           0.8210        0.039045           0.1732   \n",
       "  3         0.020579           0.7310        0.031591           0.2872   \n",
       "  4         0.018780           0.6246        0.050387           0.3876   \n",
       "  5         0.014011           0.5508        0.056069           0.4870   \n",
       "  6         0.012095           0.4438        0.028995           0.6074   \n",
       "  7         0.007981           0.3106        0.025890           0.7156   \n",
       "  8         0.007014           0.1620        0.025990           0.8268   \n",
       "  9         0.013126           0.0944        0.023266           0.9150   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004848             0.0854  ...        0.010164           0.8976   \n",
       "  2         0.008899             0.1724  ...        0.011459           0.8566   \n",
       "  3         0.016254             0.2900  ...        0.011992           0.8898   \n",
       "  4         0.014046             0.3892  ...        0.011327           0.8936   \n",
       "  5         0.010124             0.4924  ...        0.008877           0.9142   \n",
       "  6         0.011194             0.6144  ...        0.005595           0.9354   \n",
       "  7         0.009397             0.7192  ...        0.005273           0.9416   \n",
       "  8         0.005357             0.8252  ...        0.006099           0.9230   \n",
       "  9         0.011554             0.9164  ...        0.011415           0.9500   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              933.0   \n",
       "  1         0.035458                   0.1              933.0   \n",
       "  2         0.034253                   0.2              933.0   \n",
       "  3         0.037858                   0.3              933.0   \n",
       "  4         0.033679                   0.4              933.0   \n",
       "  5         0.016664                   0.5              933.0   \n",
       "  6         0.022854                   0.6              933.0   \n",
       "  7         0.018119                   0.7              933.0   \n",
       "  8         0.062097                   0.8              933.0   \n",
       "  9         0.055177                   0.9              933.0   \n",
       "  10        0.000000                   1.0              933.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6687.0                29.0                 236.0   \n",
       "  1                6687.0                29.0                 236.0   \n",
       "  2                6687.0                29.0                 236.0   \n",
       "  3                6687.0                29.0                 236.0   \n",
       "  4                6687.0                29.0                 236.0   \n",
       "  5                6687.0                29.0                 236.0   \n",
       "  6                6687.0                29.0                 236.0   \n",
       "  7                6687.0                29.0                 236.0   \n",
       "  8                6687.0                29.0                 236.0   \n",
       "  9                6687.0                29.0                 236.0   \n",
       "  10               6687.0                29.0                 236.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                71.0                506.0  \n",
       "  1                71.0                506.0  \n",
       "  2                71.0                506.0  \n",
       "  3                71.0                506.0  \n",
       "  4                71.0                506.0  \n",
       "  5                71.0                506.0  \n",
       "  6                71.0                506.0  \n",
       "  7                71.0                506.0  \n",
       "  8                71.0                506.0  \n",
       "  9                71.0                506.0  \n",
       "  10               71.0                506.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9210      0.006164           0.9208   \n",
       "  2                  0.2         0.8110      0.009899           0.8102   \n",
       "  3                  0.3         0.7082      0.006535           0.7078   \n",
       "  4                  0.4         0.5946      0.013164           0.5924   \n",
       "  5                  0.5         0.4846      0.020671           0.4818   \n",
       "  6                  0.6         0.3804      0.017344           0.3760   \n",
       "  7                  0.7         0.2718      0.013142           0.2714   \n",
       "  8                  0.8         0.1738      0.016193           0.1734   \n",
       "  9                  0.9         0.0734      0.006465           0.0728   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006140           0.9214        0.022854           0.0790   \n",
       "  2         0.011476           0.8232        0.035513           0.1890   \n",
       "  3         0.008012           0.7162        0.045921           0.2918   \n",
       "  4         0.013278           0.6322        0.038868           0.4054   \n",
       "  5         0.021371           0.5368        0.039833           0.5154   \n",
       "  6         0.018262           0.4604        0.015646           0.6196   \n",
       "  7         0.015805           0.2744        0.042099           0.7282   \n",
       "  8         0.017401           0.1884        0.031358           0.8262   \n",
       "  9         0.006535           0.0856        0.013107           0.9266   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.006164             0.0792  ...        0.025016           0.8992   \n",
       "  2         0.009899             0.1898  ...        0.018171           0.8104   \n",
       "  3         0.006535             0.2922  ...        0.017541           0.7876   \n",
       "  4         0.013164             0.4076  ...        0.008142           0.8058   \n",
       "  5         0.020671             0.5182  ...        0.002121           0.8076   \n",
       "  6         0.017344             0.6240  ...        0.003082           0.8196   \n",
       "  7         0.013142             0.7286  ...        0.003362           0.7760   \n",
       "  8         0.016193             0.8266  ...        0.002490           0.7964   \n",
       "  9         0.006465             0.9272  ...        0.000000           0.7960   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              419.0   \n",
       "  1         0.025704                   0.1              419.0   \n",
       "  2         0.037481                   0.2              419.0   \n",
       "  3         0.028378                   0.3              419.0   \n",
       "  4         0.010616                   0.4              419.0   \n",
       "  5         0.026121                   0.5              419.0   \n",
       "  6         0.032532                   0.6              419.0   \n",
       "  7         0.036249                   0.7              419.0   \n",
       "  8         0.073272                   0.8              419.0   \n",
       "  9         0.073188                   0.9              419.0   \n",
       "  10        0.000000                   1.0              419.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7763.0                10.0                 270.0   \n",
       "  1                7763.0                10.0                 270.0   \n",
       "  2                7763.0                10.0                 270.0   \n",
       "  3                7763.0                10.0                 270.0   \n",
       "  4                7763.0                10.0                 270.0   \n",
       "  5                7763.0                10.0                 270.0   \n",
       "  6                7763.0                10.0                 270.0   \n",
       "  7                7763.0                10.0                 270.0   \n",
       "  8                7763.0                10.0                 270.0   \n",
       "  9                7763.0                10.0                 270.0   \n",
       "  10               7763.0                10.0                 270.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                20.0                548.0  \n",
       "  1                20.0                548.0  \n",
       "  2                20.0                548.0  \n",
       "  3                20.0                548.0  \n",
       "  4                20.0                548.0  \n",
       "  5                20.0                548.0  \n",
       "  6                20.0                548.0  \n",
       "  7                20.0                548.0  \n",
       "  8                20.0                548.0  \n",
       "  9                20.0                548.0  \n",
       "  10               20.0                548.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9182      0.009257           0.9174   \n",
       "  2                  0.2         0.8116      0.011014           0.8110   \n",
       "  3                  0.3         0.7074      0.010262           0.7062   \n",
       "  4                  0.4         0.6002      0.006261           0.6000   \n",
       "  5                  0.5         0.4906      0.013390           0.4908   \n",
       "  6                  0.6         0.3854      0.014673           0.3850   \n",
       "  7                  0.7         0.2782      0.015881           0.2776   \n",
       "  8                  0.8         0.1766      0.009711           0.1754   \n",
       "  9                  0.9         0.0778      0.007362           0.0786   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010040           0.9312        0.037393           0.0818   \n",
       "  2         0.010794           0.8380        0.048265           0.1884   \n",
       "  3         0.010521           0.7350        0.053940           0.2926   \n",
       "  4         0.006519           0.5980        0.113093           0.3998   \n",
       "  5         0.013719           0.4760        0.080100           0.5094   \n",
       "  6         0.014160           0.3968        0.079704           0.6146   \n",
       "  7         0.015453           0.2890        0.073072           0.7218   \n",
       "  8         0.010383           0.2304        0.040290           0.8234   \n",
       "  9         0.007301           0.0486        0.048875           0.9222   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.009257             0.0826  ...        0.020474           0.9018   \n",
       "  2         0.011014             0.1890  ...        0.014433           0.8244   \n",
       "  3         0.010262             0.2938  ...        0.028865           0.7980   \n",
       "  4         0.006261             0.4000  ...        0.026957           0.7972   \n",
       "  5         0.013390             0.5092  ...        0.014567           0.8244   \n",
       "  6         0.014673             0.6150  ...        0.013993           0.8352   \n",
       "  7         0.015881             0.7224  ...        0.009529           0.8674   \n",
       "  8         0.009711             0.8246  ...        0.006403           0.9184   \n",
       "  9         0.007362             0.9214  ...        0.004382           0.7428   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              204.0   \n",
       "  1         0.048267                   0.1              204.0   \n",
       "  2         0.048645                   0.2              204.0   \n",
       "  3         0.028662                   0.3              204.0   \n",
       "  4         0.031571                   0.4              204.0   \n",
       "  5         0.073548                   0.5              204.0   \n",
       "  6         0.069568                   0.6              204.0   \n",
       "  7         0.058539                   0.7              204.0   \n",
       "  8         0.077684                   0.8              204.0   \n",
       "  9         0.433312                   0.9              204.0   \n",
       "  10        0.000000                   1.0              204.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7414.0                15.0                 245.0   \n",
       "  1                7414.0                15.0                 245.0   \n",
       "  2                7414.0                15.0                 245.0   \n",
       "  3                7414.0                15.0                 245.0   \n",
       "  4                7414.0                15.0                 245.0   \n",
       "  5                7414.0                15.0                 245.0   \n",
       "  6                7414.0                15.0                 245.0   \n",
       "  7                7414.0                15.0                 245.0   \n",
       "  8                7414.0                15.0                 245.0   \n",
       "  9                7414.0                15.0                 245.0   \n",
       "  10               7414.0                15.0                 245.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                31.0                543.0  \n",
       "  1                31.0                543.0  \n",
       "  2                31.0                543.0  \n",
       "  3                31.0                543.0  \n",
       "  4                31.0                543.0  \n",
       "  5                31.0                543.0  \n",
       "  6                31.0                543.0  \n",
       "  7                31.0                543.0  \n",
       "  8                31.0                543.0  \n",
       "  9                31.0                543.0  \n",
       "  10               31.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns]],\n",
       " 'pred_score_original': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8448      0.014220           0.8466   \n",
       "  2                  0.2         0.7588      0.013572           0.7696   \n",
       "  3                  0.3         0.6502      0.011946           0.6606   \n",
       "  4                  0.4         0.5248      0.016468           0.5364   \n",
       "  5                  0.5         0.4212      0.012677           0.4352   \n",
       "  6                  0.6         0.3140      0.012166           0.3296   \n",
       "  7                  0.7         0.2130      0.006285           0.2266   \n",
       "  8                  0.8         0.1332      0.008556           0.1416   \n",
       "  9                  0.9         0.0636      0.002510           0.0678   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.013631           0.8166        0.050342           0.1552   \n",
       "  2         0.014082           0.5890        0.045492           0.2412   \n",
       "  3         0.013372           0.4888        0.031925           0.3498   \n",
       "  4         0.018555           0.3446        0.046436           0.4752   \n",
       "  5         0.014856           0.2054        0.031620           0.5788   \n",
       "  6         0.013975           0.0722        0.046376           0.6860   \n",
       "  7         0.006804           0.0056        0.012522           0.7870   \n",
       "  8         0.009370           0.0000        0.000000           0.8668   \n",
       "  9         0.002588           0.0000        0.000000           0.9364   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.014220             0.1534  ...        0.014983           0.7304   \n",
       "  2         0.013572             0.2304  ...        0.014474           0.5700   \n",
       "  3         0.011946             0.3394  ...        0.018754           0.5752   \n",
       "  4         0.016468             0.4636  ...        0.018267           0.5868   \n",
       "  5         0.012677             0.5648  ...        0.015694           0.5810   \n",
       "  6         0.012166             0.6704  ...        0.013722           0.4192   \n",
       "  7         0.006285             0.7734  ...        0.003578           0.0500   \n",
       "  8         0.008556             0.8584  ...        0.006856           0.0000   \n",
       "  9         0.002510             0.9322  ...        0.012075           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              322.0   \n",
       "  1         0.050895                   0.1              322.0   \n",
       "  2         0.041467                   0.2              322.0   \n",
       "  3         0.034738                   0.3              322.0   \n",
       "  4         0.068346                   0.4              322.0   \n",
       "  5         0.092671                   0.5              322.0   \n",
       "  6         0.250143                   0.6              322.0   \n",
       "  7         0.111803                   0.7              322.0   \n",
       "  8         0.000000                   0.8              322.0   \n",
       "  9         0.000000                   0.9              322.0   \n",
       "  10        0.000000                   1.0              322.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8179.0                25.0                 240.0   \n",
       "  1                8179.0                25.0                 240.0   \n",
       "  2                8179.0                25.0                 240.0   \n",
       "  3                8179.0                25.0                 240.0   \n",
       "  4                8179.0                25.0                 240.0   \n",
       "  5                8179.0                25.0                 240.0   \n",
       "  6                8179.0                25.0                 240.0   \n",
       "  7                8179.0                25.0                 240.0   \n",
       "  8                8179.0                25.0                 240.0   \n",
       "  9                8179.0                25.0                 240.0   \n",
       "  10               8179.0                25.0                 240.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                554.0  \n",
       "  1                36.0                554.0  \n",
       "  2                36.0                554.0  \n",
       "  3                36.0                554.0  \n",
       "  4                36.0                554.0  \n",
       "  5                36.0                554.0  \n",
       "  6                36.0                554.0  \n",
       "  7                36.0                554.0  \n",
       "  8                36.0                554.0  \n",
       "  9                36.0                554.0  \n",
       "  10               36.0                554.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8840      0.005831           0.8742   \n",
       "  2                  0.2         0.7668      0.012578           0.7596   \n",
       "  3                  0.3         0.6396      0.024183           0.6308   \n",
       "  4                  0.4         0.5740      0.024587           0.5744   \n",
       "  5                  0.5         0.4634      0.021478           0.4662   \n",
       "  6                  0.6         0.3488      0.022410           0.3590   \n",
       "  7                  0.7         0.2290      0.016109           0.2436   \n",
       "  8                  0.8         0.1178      0.011367           0.1224   \n",
       "  9                  0.9         0.0442      0.004604           0.0432   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007362           0.9674        0.011502           0.1160   \n",
       "  2         0.015241           0.8328        0.022320           0.2332   \n",
       "  3         0.029107           0.7182        0.022320           0.3604   \n",
       "  4         0.028953           0.5674        0.036253           0.4260   \n",
       "  5         0.025203           0.4368        0.055093           0.5366   \n",
       "  6         0.029215           0.2570        0.059008           0.6512   \n",
       "  7         0.017615           0.0980        0.016733           0.7710   \n",
       "  8         0.012992           0.0778        0.009391           0.8822   \n",
       "  9         0.006301           0.0532        0.018281           0.9558   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.005831             0.1258  ...        0.048340           0.9376   \n",
       "  2         0.012578             0.2404  ...        0.035557           0.7820   \n",
       "  3         0.024183             0.3692  ...        0.033444           0.7192   \n",
       "  4         0.024587             0.4256  ...        0.035189           0.6952   \n",
       "  5         0.021478             0.5338  ...        0.035043           0.7130   \n",
       "  6         0.022410             0.6410  ...        0.024183           0.7068   \n",
       "  7         0.016109             0.7564  ...        0.011300           0.5976   \n",
       "  8         0.011367             0.8776  ...        0.009391           0.7468   \n",
       "  9         0.004604             0.9568  ...        0.000000           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              901.0   \n",
       "  1         0.021314                   0.1              901.0   \n",
       "  2         0.029026                   0.2              901.0   \n",
       "  3         0.019045                   0.3              901.0   \n",
       "  4         0.029406                   0.4              901.0   \n",
       "  5         0.040119                   0.5              901.0   \n",
       "  6         0.067614                   0.6              901.0   \n",
       "  7         0.064326                   0.7              901.0   \n",
       "  8         0.159081                   0.8              901.0   \n",
       "  9         0.000000                   0.9              901.0   \n",
       "  10        0.000000                   1.0              901.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6290.0                27.0                 231.0   \n",
       "  1                6290.0                27.0                 231.0   \n",
       "  2                6290.0                27.0                 231.0   \n",
       "  3                6290.0                27.0                 231.0   \n",
       "  4                6290.0                27.0                 231.0   \n",
       "  5                6290.0                27.0                 231.0   \n",
       "  6                6290.0                27.0                 231.0   \n",
       "  7                6290.0                27.0                 231.0   \n",
       "  8                6290.0                27.0                 231.0   \n",
       "  9                6290.0                27.0                 231.0   \n",
       "  10               6290.0                27.0                 231.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                49.0                441.0  \n",
       "  1                49.0                441.0  \n",
       "  2                49.0                441.0  \n",
       "  3                49.0                441.0  \n",
       "  4                49.0                441.0  \n",
       "  5                49.0                441.0  \n",
       "  6                49.0                441.0  \n",
       "  7                49.0                441.0  \n",
       "  8                49.0                441.0  \n",
       "  9                49.0                441.0  \n",
       "  10               49.0                441.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8852      0.012112           0.8836   \n",
       "  2                  0.2         0.8084      0.009737           0.8078   \n",
       "  3                  0.3         0.6948      0.018767           0.6948   \n",
       "  4                  0.4         0.5786      0.012661           0.5828   \n",
       "  5                  0.5         0.4570      0.012042           0.4660   \n",
       "  6                  0.6         0.3390      0.011640           0.3456   \n",
       "  7                  0.7         0.2296      0.013390           0.2344   \n",
       "  8                  0.8         0.1314      0.009370           0.1334   \n",
       "  9                  0.9         0.0514      0.004930           0.0524   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.013502           0.9636        0.049843           0.1148   \n",
       "  2         0.009257           0.8362        0.076136           0.1916   \n",
       "  3         0.017456           0.7090        0.149102           0.3052   \n",
       "  4         0.010521           0.3638        0.143568           0.4214   \n",
       "  5         0.012550           0.0000        0.000000           0.5430   \n",
       "  6         0.011971           0.0000        0.000000           0.6610   \n",
       "  7         0.013240           0.0000        0.000000           0.7704   \n",
       "  8         0.009370           0.0000        0.000000           0.8686   \n",
       "  9         0.004930           0.0000        0.000000           0.9486   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.012112             0.1164  ...        0.044354           0.9492   \n",
       "  2         0.009737             0.1922  ...        0.038897           0.7950   \n",
       "  3         0.018767             0.3052  ...        0.038798           0.7180   \n",
       "  4         0.012661             0.4172  ...        0.033231           0.6262   \n",
       "  5         0.012042             0.5340  ...        0.001789           0.0000   \n",
       "  6         0.011640             0.6544  ...        0.000000           0.0000   \n",
       "  7         0.013390             0.7656  ...        0.000000           0.0000   \n",
       "  8         0.009370             0.8666  ...        0.000000           0.0000   \n",
       "  9         0.004930             0.9476  ...        0.000000           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              373.0   \n",
       "  1         0.070475                   0.1              373.0   \n",
       "  2         0.102164                   0.2              373.0   \n",
       "  3         0.130083                   0.3              373.0   \n",
       "  4         0.138341                   0.4              373.0   \n",
       "  5         0.000000                   0.5              373.0   \n",
       "  6         0.000000                   0.6              373.0   \n",
       "  7         0.000000                   0.7              373.0   \n",
       "  8         0.000000                   0.8              373.0   \n",
       "  9         0.000000                   0.9              373.0   \n",
       "  10        0.000000                   1.0              373.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8370.0                 3.0                 282.0   \n",
       "  1                8370.0                 3.0                 282.0   \n",
       "  2                8370.0                 3.0                 282.0   \n",
       "  3                8370.0                 3.0                 282.0   \n",
       "  4                8370.0                 3.0                 282.0   \n",
       "  5                8370.0                 3.0                 282.0   \n",
       "  6                8370.0                 3.0                 282.0   \n",
       "  7                8370.0                 3.0                 282.0   \n",
       "  8                8370.0                 3.0                 282.0   \n",
       "  9                8370.0                 3.0                 282.0   \n",
       "  10               8370.0                 3.0                 282.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                11.0                549.0  \n",
       "  1                11.0                549.0  \n",
       "  2                11.0                549.0  \n",
       "  3                11.0                549.0  \n",
       "  4                11.0                549.0  \n",
       "  5                11.0                549.0  \n",
       "  6                11.0                549.0  \n",
       "  7                11.0                549.0  \n",
       "  8                11.0                549.0  \n",
       "  9                11.0                549.0  \n",
       "  10               11.0                549.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8452      0.011670           0.8418   \n",
       "  2                  0.2         0.7278      0.011122           0.7244   \n",
       "  3                  0.3         0.6656      0.011589           0.6622   \n",
       "  4                  0.4         0.5642      0.016784           0.5622   \n",
       "  5                  0.5         0.4530      0.004637           0.4528   \n",
       "  6                  0.6         0.3380      0.017306           0.3380   \n",
       "  7                  0.7         0.2388      0.011756           0.2382   \n",
       "  8                  0.8         0.1558      0.009524           0.1588   \n",
       "  9                  0.9         0.0820      0.003808           0.0836   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.012112           0.9366        0.023255           0.1548   \n",
       "  2         0.012621           0.8208        0.047405           0.2722   \n",
       "  3         0.011692           0.7576        0.046902           0.3344   \n",
       "  4         0.015515           0.6316        0.098353           0.4358   \n",
       "  5         0.004087           0.4632        0.057786           0.5470   \n",
       "  6         0.015937           0.3368        0.079851           0.6620   \n",
       "  7         0.012215           0.2526        0.023255           0.7612   \n",
       "  8         0.009960           0.0634        0.023255           0.8442   \n",
       "  9         0.004393           0.0424        0.023702           0.9180   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.011670             0.1582  ...        0.010060           0.9048   \n",
       "  2         0.011122             0.2756  ...        0.021312           0.8052   \n",
       "  3         0.011589             0.3378  ...        0.022532           0.7652   \n",
       "  4         0.016784             0.4378  ...        0.015738           0.7896   \n",
       "  5         0.004637             0.5472  ...        0.025466           0.7698   \n",
       "  6         0.017306             0.6620  ...        0.021265           0.7656   \n",
       "  7         0.011756             0.7618  ...        0.016149           0.7788   \n",
       "  8         0.009524             0.8412  ...        0.008860           0.5000   \n",
       "  9         0.003808             0.9164  ...        0.009839           0.4000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              386.0   \n",
       "  1         0.033425                   0.1              386.0   \n",
       "  2         0.046268                   0.2              386.0   \n",
       "  3         0.033018                   0.3              386.0   \n",
       "  4         0.064733                   0.4              386.0   \n",
       "  5         0.075744                   0.5              386.0   \n",
       "  6         0.127602                   0.6              386.0   \n",
       "  7         0.060669                   0.7              386.0   \n",
       "  8         0.000000                   0.8              386.0   \n",
       "  9         0.223607                   0.9              386.0   \n",
       "  10        0.000000                   1.0              386.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7233.0                10.0                 250.0   \n",
       "  1                7233.0                10.0                 250.0   \n",
       "  2                7233.0                10.0                 250.0   \n",
       "  3                7233.0                10.0                 250.0   \n",
       "  4                7233.0                10.0                 250.0   \n",
       "  5                7233.0                10.0                 250.0   \n",
       "  6                7233.0                10.0                 250.0   \n",
       "  7                7233.0                10.0                 250.0   \n",
       "  8                7233.0                10.0                 250.0   \n",
       "  9                7233.0                10.0                 250.0   \n",
       "  10               7233.0                10.0                 250.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                19.0                558.0  \n",
       "  1                19.0                558.0  \n",
       "  2                19.0                558.0  \n",
       "  3                19.0                558.0  \n",
       "  4                19.0                558.0  \n",
       "  5                19.0                558.0  \n",
       "  6                19.0                558.0  \n",
       "  7                19.0                558.0  \n",
       "  8                19.0                558.0  \n",
       "  9                19.0                558.0  \n",
       "  10               19.0                558.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8642      0.004324           0.8540   \n",
       "  2                  0.2         0.7156      0.008764           0.7120   \n",
       "  3                  0.3         0.6558      0.012215           0.6656   \n",
       "  4                  0.4         0.5620      0.016897           0.5782   \n",
       "  5                  0.5         0.4764      0.021055           0.4946   \n",
       "  6                  0.6         0.3836      0.021524           0.4026   \n",
       "  7                  0.7         0.2818      0.009985           0.2960   \n",
       "  8                  0.8         0.1950      0.012884           0.2026   \n",
       "  9                  0.9         0.0922      0.006723           0.0964   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005612           0.9498        0.014704           0.1358   \n",
       "  2         0.007280           0.7464        0.032199           0.2844   \n",
       "  3         0.012681           0.5748        0.014704           0.3442   \n",
       "  4         0.015865           0.4286        0.033276           0.4380   \n",
       "  5         0.023028           0.3286        0.041028           0.5236   \n",
       "  6         0.023671           0.2284        0.023469           0.6164   \n",
       "  7         0.009274           0.1678        0.046440           0.7182   \n",
       "  8         0.013012           0.1320        0.041049           0.8050   \n",
       "  9         0.005941           0.0572        0.026262           0.9078   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004324             0.1460  ...        0.005404           0.9400   \n",
       "  2         0.008764             0.2880  ...        0.010173           0.9334   \n",
       "  3         0.012215             0.3344  ...        0.005595           0.9422   \n",
       "  4         0.016897             0.4218  ...        0.004669           0.9516   \n",
       "  5         0.021055             0.5054  ...        0.005683           0.9614   \n",
       "  6         0.021524             0.5974  ...        0.001924           1.0000   \n",
       "  7         0.009985             0.7040  ...        0.006140           1.0000   \n",
       "  8         0.012884             0.7974  ...        0.007436           1.0000   \n",
       "  9         0.006723             0.9036  ...        0.019829           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1094.0   \n",
       "  1         0.016462                   0.1             1094.0   \n",
       "  2         0.020611                   0.2             1094.0   \n",
       "  3         0.028066                   0.3             1094.0   \n",
       "  4         0.021617                   0.4             1094.0   \n",
       "  5         0.041531                   0.5             1094.0   \n",
       "  6         0.000000                   0.6             1094.0   \n",
       "  7         0.000000                   0.7             1094.0   \n",
       "  8         0.000000                   0.8             1094.0   \n",
       "  9         0.000000                   0.9             1094.0   \n",
       "  10        0.000000                   1.0             1094.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5719.0                38.0                 195.0   \n",
       "  1                5719.0                38.0                 195.0   \n",
       "  2                5719.0                38.0                 195.0   \n",
       "  3                5719.0                38.0                 195.0   \n",
       "  4                5719.0                38.0                 195.0   \n",
       "  5                5719.0                38.0                 195.0   \n",
       "  6                5719.0                38.0                 195.0   \n",
       "  7                5719.0                38.0                 195.0   \n",
       "  8                5719.0                38.0                 195.0   \n",
       "  9                5719.0                38.0                 195.0   \n",
       "  10               5719.0                38.0                 195.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                56.0                457.0  \n",
       "  1                56.0                457.0  \n",
       "  2                56.0                457.0  \n",
       "  3                56.0                457.0  \n",
       "  4                56.0                457.0  \n",
       "  5                56.0                457.0  \n",
       "  6                56.0                457.0  \n",
       "  7                56.0                457.0  \n",
       "  8                56.0                457.0  \n",
       "  9                56.0                457.0  \n",
       "  10               56.0                457.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8222      0.009066           0.8226   \n",
       "  2                  0.2         0.7032      0.010060           0.7106   \n",
       "  3                  0.3         0.6244      0.010597           0.6390   \n",
       "  4                  0.4         0.5176      0.015241           0.5350   \n",
       "  5                  0.5         0.4298      0.006686           0.4482   \n",
       "  6                  0.6         0.3280      0.007036           0.3458   \n",
       "  7                  0.7         0.2174      0.008933           0.2304   \n",
       "  8                  0.8         0.1296      0.005727           0.1372   \n",
       "  9                  0.9         0.0476      0.004159           0.0508   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.012341            0.815        0.037914           0.1778   \n",
       "  2         0.009889            0.600        0.030619           0.2968   \n",
       "  3         0.011446            0.425        0.039528           0.3756   \n",
       "  4         0.016294            0.280        0.027386           0.4824   \n",
       "  5         0.008497            0.180        0.020917           0.5702   \n",
       "  6         0.009149            0.090        0.028504           0.6720   \n",
       "  7         0.009940            0.040        0.022361           0.7826   \n",
       "  8         0.006686            0.025        0.025000           0.8704   \n",
       "  9         0.004207            0.005        0.011180           0.9524   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.009066             0.1774  ...        0.029913           0.7172   \n",
       "  2         0.010060             0.2894  ...        0.023446           0.6102   \n",
       "  3         0.010597             0.3610  ...        0.024317           0.5712   \n",
       "  4         0.015241             0.4650  ...        0.021159           0.5830   \n",
       "  5         0.006686             0.5518  ...        0.011895           0.5394   \n",
       "  6         0.007036             0.6542  ...        0.008556           0.5238   \n",
       "  7         0.008933             0.7696  ...        0.011189           0.5800   \n",
       "  8         0.005727             0.8628  ...        0.007155           0.5000   \n",
       "  9         0.004159             0.9492  ...        0.018676           0.2000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              515.0   \n",
       "  1         0.043626                   0.1              515.0   \n",
       "  2         0.032882                   0.2              515.0   \n",
       "  3         0.028173                   0.3              515.0   \n",
       "  4         0.031281                   0.4              515.0   \n",
       "  5         0.079330                   0.5              515.0   \n",
       "  6         0.202444                   0.6              515.0   \n",
       "  7         0.426615                   0.7              515.0   \n",
       "  8         0.500000                   0.8              515.0   \n",
       "  9         0.447214                   0.9              515.0   \n",
       "  10        0.000000                   1.0              515.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7542.0                28.0                 234.0   \n",
       "  1                7542.0                28.0                 234.0   \n",
       "  2                7542.0                28.0                 234.0   \n",
       "  3                7542.0                28.0                 234.0   \n",
       "  4                7542.0                28.0                 234.0   \n",
       "  5                7542.0                28.0                 234.0   \n",
       "  6                7542.0                28.0                 234.0   \n",
       "  7                7542.0                28.0                 234.0   \n",
       "  8                7542.0                28.0                 234.0   \n",
       "  9                7542.0                28.0                 234.0   \n",
       "  10               7542.0                28.0                 234.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                40.0                543.0  \n",
       "  1                40.0                543.0  \n",
       "  2                40.0                543.0  \n",
       "  3                40.0                543.0  \n",
       "  4                40.0                543.0  \n",
       "  5                40.0                543.0  \n",
       "  6                40.0                543.0  \n",
       "  7                40.0                543.0  \n",
       "  8                40.0                543.0  \n",
       "  9                40.0                543.0  \n",
       "  10               40.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8704      0.007335           0.8700   \n",
       "  2                  0.2         0.7678      0.007950           0.7712   \n",
       "  3                  0.3         0.6722      0.011278           0.6812   \n",
       "  4                  0.4         0.5696      0.005367           0.5852   \n",
       "  5                  0.5         0.4608      0.010640           0.4806   \n",
       "  6                  0.6         0.3566      0.013957           0.3750   \n",
       "  7                  0.7         0.2642      0.009859           0.2812   \n",
       "  8                  0.8         0.1702      0.002683           0.1806   \n",
       "  9                  0.9         0.0856      0.006229           0.0900   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006000           0.8724        0.042069           0.1296   \n",
       "  2         0.006221           0.7222        0.043957           0.2322   \n",
       "  3         0.009960           0.5612        0.041094           0.3278   \n",
       "  4         0.007050           0.3664        0.045583           0.4304   \n",
       "  5         0.008620           0.2056        0.042004           0.5392   \n",
       "  6         0.013928           0.1110        0.019799           0.6434   \n",
       "  7         0.009884           0.0448        0.015336           0.7358   \n",
       "  8         0.003715           0.0392        0.015336           0.8298   \n",
       "  9         0.006819           0.0224        0.012522           0.9144   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007335             0.1300  ...        0.003493           0.8028   \n",
       "  2         0.007950             0.2288  ...        0.005857           0.7068   \n",
       "  3         0.011278             0.3188  ...        0.005177           0.7014   \n",
       "  4         0.005367             0.4148  ...        0.009497           0.6680   \n",
       "  5         0.010640             0.5194  ...        0.006797           0.6502   \n",
       "  6         0.013957             0.6250  ...        0.007085           0.5526   \n",
       "  7         0.009859             0.7188  ...        0.003391           0.4500   \n",
       "  8         0.002683             0.8194  ...        0.006573           0.7334   \n",
       "  9         0.006229             0.9100  ...        0.000000           0.7000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              338.0   \n",
       "  1         0.057317                   0.1              338.0   \n",
       "  2         0.037332                   0.2              338.0   \n",
       "  3         0.023405                   0.3              338.0   \n",
       "  4         0.057806                   0.4              338.0   \n",
       "  5         0.084878                   0.5              338.0   \n",
       "  6         0.105737                   0.6              338.0   \n",
       "  7         0.162618                   0.7              338.0   \n",
       "  8         0.252741                   0.8              338.0   \n",
       "  9         0.447214                   0.9              338.0   \n",
       "  10        0.000000                   1.0              338.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6362.0                18.0                 192.0   \n",
       "  1                6362.0                18.0                 192.0   \n",
       "  2                6362.0                18.0                 192.0   \n",
       "  3                6362.0                18.0                 192.0   \n",
       "  4                6362.0                18.0                 192.0   \n",
       "  5                6362.0                18.0                 192.0   \n",
       "  6                6362.0                18.0                 192.0   \n",
       "  7                6362.0                18.0                 192.0   \n",
       "  8                6362.0                18.0                 192.0   \n",
       "  9                6362.0                18.0                 192.0   \n",
       "  10               6362.0                18.0                 192.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                466.0  \n",
       "  1                36.0                466.0  \n",
       "  2                36.0                466.0  \n",
       "  3                36.0                466.0  \n",
       "  4                36.0                466.0  \n",
       "  5                36.0                466.0  \n",
       "  6                36.0                466.0  \n",
       "  7                36.0                466.0  \n",
       "  8                36.0                466.0  \n",
       "  9                36.0                466.0  \n",
       "  10               36.0                466.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8448      0.012235           0.8256   \n",
       "  2                  0.2         0.6940      0.006083           0.6688   \n",
       "  3                  0.3         0.5744      0.010286           0.5542   \n",
       "  4                  0.4         0.4942      0.011432           0.4872   \n",
       "  5                  0.5         0.4172      0.005070           0.4278   \n",
       "  6                  0.6         0.3212      0.015222           0.3348   \n",
       "  7                  0.7         0.2184      0.017743           0.2330   \n",
       "  8                  0.8         0.1242      0.014061           0.1328   \n",
       "  9                  0.9         0.0580      0.010368           0.0546   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.014293           0.9394        0.012896           0.1552   \n",
       "  2         0.009311           0.8180        0.016688           0.3060   \n",
       "  3         0.015515           0.6740        0.027559           0.4256   \n",
       "  4         0.013755           0.5282        0.026224           0.5058   \n",
       "  5         0.011345           0.3662        0.028128           0.5828   \n",
       "  6         0.014360           0.2540        0.038646           0.6788   \n",
       "  7         0.018000           0.1462        0.019486           0.7816   \n",
       "  8         0.014464           0.0810        0.029908           0.8758   \n",
       "  9         0.012137           0.0742        0.025782           0.9420   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.012235             0.1744  ...        0.015023           0.9040   \n",
       "  2         0.006083             0.3312  ...        0.011336           0.8102   \n",
       "  3         0.010286             0.4458  ...        0.018472           0.8286   \n",
       "  4         0.011432             0.5128  ...        0.014673           0.8274   \n",
       "  5         0.005070             0.5722  ...        0.013088           0.8358   \n",
       "  6         0.015222             0.6652  ...        0.028813           0.8564   \n",
       "  7         0.017743             0.7670  ...        0.020057           0.8934   \n",
       "  8         0.014061             0.8672  ...        0.018254           0.8950   \n",
       "  9         0.010368             0.9454  ...        0.044178           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1032.0   \n",
       "  1         0.022327                   0.1             1032.0   \n",
       "  2         0.016769                   0.2             1032.0   \n",
       "  3         0.016832                   0.3             1032.0   \n",
       "  4         0.012260                   0.4             1032.0   \n",
       "  5         0.034215                   0.5             1032.0   \n",
       "  6         0.067073                   0.6             1032.0   \n",
       "  7         0.075672                   0.7             1032.0   \n",
       "  8         0.173566                   0.8             1032.0   \n",
       "  9         0.000000                   0.9             1032.0   \n",
       "  10        0.000000                   1.0             1032.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5653.0                47.0                 181.0   \n",
       "  1                5653.0                47.0                 181.0   \n",
       "  2                5653.0                47.0                 181.0   \n",
       "  3                5653.0                47.0                 181.0   \n",
       "  4                5653.0                47.0                 181.0   \n",
       "  5                5653.0                47.0                 181.0   \n",
       "  6                5653.0                47.0                 181.0   \n",
       "  7                5653.0                47.0                 181.0   \n",
       "  8                5653.0                47.0                 181.0   \n",
       "  9                5653.0                47.0                 181.0   \n",
       "  10               5653.0                47.0                 181.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                89.0                433.0  \n",
       "  1                89.0                433.0  \n",
       "  2                89.0                433.0  \n",
       "  3                89.0                433.0  \n",
       "  4                89.0                433.0  \n",
       "  5                89.0                433.0  \n",
       "  6                89.0                433.0  \n",
       "  7                89.0                433.0  \n",
       "  8                89.0                433.0  \n",
       "  9                89.0                433.0  \n",
       "  10               89.0                433.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8850      0.017479           0.8884   \n",
       "  2                  0.2         0.7952      0.019512           0.8018   \n",
       "  3                  0.3         0.6830      0.015017           0.6928   \n",
       "  4                  0.4         0.5642      0.013535           0.5726   \n",
       "  5                  0.5         0.4412      0.018953           0.4474   \n",
       "  6                  0.6         0.3408      0.020462           0.3458   \n",
       "  7                  0.7         0.2368      0.013255           0.2402   \n",
       "  8                  0.8         0.1446      0.005857           0.1468   \n",
       "  9                  0.9         0.0692      0.008556           0.0704   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.017883             0.65        0.136931           0.1150   \n",
       "  2         0.020315             0.35        0.055902           0.2048   \n",
       "  3         0.015205             0.00        0.000000           0.3170   \n",
       "  4         0.013975             0.00        0.000000           0.4358   \n",
       "  5         0.019243             0.00        0.000000           0.5588   \n",
       "  6         0.020462             0.00        0.000000           0.6592   \n",
       "  7         0.013609             0.00        0.000000           0.7632   \n",
       "  8         0.006181             0.00        0.000000           0.8554   \n",
       "  9         0.008706             0.00        0.000000           0.9308   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.017479             0.1116  ...        0.029346           0.4466   \n",
       "  2         0.019512             0.1982  ...        0.032654           0.3774   \n",
       "  3         0.015017             0.3072  ...        0.007463           0.0000   \n",
       "  4         0.013535             0.4274  ...        0.001643           0.0000   \n",
       "  5         0.018953             0.5526  ...        0.001789           0.0000   \n",
       "  6         0.020462             0.6542  ...        0.003033           0.0000   \n",
       "  7         0.013255             0.7598  ...        0.003578           0.0000   \n",
       "  8         0.005857             0.8532  ...        0.000000           0.0000   \n",
       "  9         0.008556             0.9296  ...        0.000000           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              295.0   \n",
       "  1         0.076862                   0.1              295.0   \n",
       "  2         0.034100                   0.2              295.0   \n",
       "  3         0.000000                   0.3              295.0   \n",
       "  4         0.000000                   0.4              295.0   \n",
       "  5         0.000000                   0.5              295.0   \n",
       "  6         0.000000                   0.6              295.0   \n",
       "  7         0.000000                   0.7              295.0   \n",
       "  8         0.000000                   0.8              295.0   \n",
       "  9         0.000000                   0.9              295.0   \n",
       "  10        0.000000                   1.0              295.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7742.0                 4.0                 242.0   \n",
       "  1                7742.0                 4.0                 242.0   \n",
       "  2                7742.0                 4.0                 242.0   \n",
       "  3                7742.0                 4.0                 242.0   \n",
       "  4                7742.0                 4.0                 242.0   \n",
       "  5                7742.0                 4.0                 242.0   \n",
       "  6                7742.0                 4.0                 242.0   \n",
       "  7                7742.0                 4.0                 242.0   \n",
       "  8                7742.0                 4.0                 242.0   \n",
       "  9                7742.0                 4.0                 242.0   \n",
       "  10               7742.0                 4.0                 242.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                 8.0                543.0  \n",
       "  1                 8.0                543.0  \n",
       "  2                 8.0                543.0  \n",
       "  3                 8.0                543.0  \n",
       "  4                 8.0                543.0  \n",
       "  5                 8.0                543.0  \n",
       "  6                 8.0                543.0  \n",
       "  7                 8.0                543.0  \n",
       "  8                 8.0                543.0  \n",
       "  9                 8.0                543.0  \n",
       "  10                8.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8330      0.004950           0.8168   \n",
       "  2                  0.2         0.6926      0.008355           0.6688   \n",
       "  3                  0.3         0.6310      0.009747           0.6156   \n",
       "  4                  0.4         0.5238      0.005215           0.5208   \n",
       "  5                  0.5         0.4126      0.019126           0.4174   \n",
       "  6                  0.6         0.3132      0.015450           0.3284   \n",
       "  7                  0.7         0.2216      0.020045           0.2344   \n",
       "  8                  0.8         0.1422      0.013405           0.1450   \n",
       "  9                  0.9         0.0648      0.010498           0.0634   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006099           0.9468        0.011713           0.1670   \n",
       "  2         0.010826           0.8618        0.015336           0.3074   \n",
       "  3         0.011437           0.7408        0.038271           0.3690   \n",
       "  4         0.007694           0.5464        0.039138           0.4762   \n",
       "  5         0.017111           0.3804        0.043638           0.5874   \n",
       "  6         0.018515           0.2054        0.015962           0.6868   \n",
       "  7         0.021536           0.1298        0.028691           0.7784   \n",
       "  8         0.016000           0.1214        0.021232           0.8578   \n",
       "  9         0.011261           0.0734        0.015884           0.9352   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004950             0.1832  ...        0.013631           0.9406   \n",
       "  2         0.008355             0.3312  ...        0.014588           0.9358   \n",
       "  3         0.009747             0.3844  ...        0.017277           0.9390   \n",
       "  4         0.005215             0.4792  ...        0.014859           0.9370   \n",
       "  5         0.019126             0.5826  ...        0.019761           0.9366   \n",
       "  6         0.015450             0.6716  ...        0.011323           0.9010   \n",
       "  7         0.020045             0.7656  ...        0.006580           0.8844   \n",
       "  8         0.013405             0.8550  ...        0.014826           0.8784   \n",
       "  9         0.010498             0.9366  ...        0.022672           0.9714   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              933.0   \n",
       "  1         0.012681                   0.1              933.0   \n",
       "  2         0.016392                   0.2              933.0   \n",
       "  3         0.009618                   0.3              933.0   \n",
       "  4         0.012570                   0.4              933.0   \n",
       "  5         0.018756                   0.5              933.0   \n",
       "  6         0.033548                   0.6              933.0   \n",
       "  7         0.028806                   0.7              933.0   \n",
       "  8         0.029526                   0.8              933.0   \n",
       "  9         0.063952                   0.9              933.0   \n",
       "  10        0.000000                   1.0              933.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6687.0                29.0                 236.0   \n",
       "  1                6687.0                29.0                 236.0   \n",
       "  2                6687.0                29.0                 236.0   \n",
       "  3                6687.0                29.0                 236.0   \n",
       "  4                6687.0                29.0                 236.0   \n",
       "  5                6687.0                29.0                 236.0   \n",
       "  6                6687.0                29.0                 236.0   \n",
       "  7                6687.0                29.0                 236.0   \n",
       "  8                6687.0                29.0                 236.0   \n",
       "  9                6687.0                29.0                 236.0   \n",
       "  10               6687.0                29.0                 236.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                71.0                506.0  \n",
       "  1                71.0                506.0  \n",
       "  2                71.0                506.0  \n",
       "  3                71.0                506.0  \n",
       "  4                71.0                506.0  \n",
       "  5                71.0                506.0  \n",
       "  6                71.0                506.0  \n",
       "  7                71.0                506.0  \n",
       "  8                71.0                506.0  \n",
       "  9                71.0                506.0  \n",
       "  10               71.0                506.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8550      0.009925           0.8544   \n",
       "  2                  0.2         0.7666      0.012973           0.7712   \n",
       "  3                  0.3         0.6422      0.016544           0.6468   \n",
       "  4                  0.4         0.5282      0.022588           0.5354   \n",
       "  5                  0.5         0.4266      0.020403           0.4352   \n",
       "  6                  0.6         0.3266      0.017530           0.3318   \n",
       "  7                  0.7         0.2234      0.017501           0.2262   \n",
       "  8                  0.8         0.1320      0.016956           0.1326   \n",
       "  9                  0.9         0.0592      0.015073           0.0592   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.010900             0.87        0.057009           0.1450   \n",
       "  2         0.014584             0.64        0.041833           0.2334   \n",
       "  3         0.017499             0.51        0.022361           0.3578   \n",
       "  4         0.023147             0.33        0.027386           0.4718   \n",
       "  5         0.021017             0.19        0.022361           0.5734   \n",
       "  6         0.017239             0.18        0.044721           0.6734   \n",
       "  7         0.019512             0.14        0.041833           0.7766   \n",
       "  8         0.018528             0.12        0.027386           0.8680   \n",
       "  9         0.015579             0.06        0.022361           0.9408   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.009925             0.1456  ...        0.029567           0.8026   \n",
       "  2         0.012973             0.2288  ...        0.020391           0.6044   \n",
       "  3         0.016544             0.3532  ...        0.007497           0.5564   \n",
       "  4         0.022588             0.4646  ...        0.010040           0.5034   \n",
       "  5         0.020403             0.5648  ...        0.004550           0.4376   \n",
       "  6         0.017530             0.6682  ...        0.002775           0.5364   \n",
       "  7         0.017501             0.7738  ...        0.009418           0.5534   \n",
       "  8         0.016956             0.8674  ...        0.000000           0.7002   \n",
       "  9         0.015073             0.9408  ...        0.000000           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              419.0   \n",
       "  1         0.069547                   0.1              419.0   \n",
       "  2         0.044545                   0.2              419.0   \n",
       "  3         0.036122                   0.3              419.0   \n",
       "  4         0.060011                   0.4              419.0   \n",
       "  5         0.041241                   0.5              419.0   \n",
       "  6         0.085792                   0.6              419.0   \n",
       "  7         0.076862                   0.7              419.0   \n",
       "  8         0.045461                   0.8              419.0   \n",
       "  9         0.000000                   0.9              419.0   \n",
       "  10        0.000000                   1.0              419.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7763.0                10.0                 270.0   \n",
       "  1                7763.0                10.0                 270.0   \n",
       "  2                7763.0                10.0                 270.0   \n",
       "  3                7763.0                10.0                 270.0   \n",
       "  4                7763.0                10.0                 270.0   \n",
       "  5                7763.0                10.0                 270.0   \n",
       "  6                7763.0                10.0                 270.0   \n",
       "  7                7763.0                10.0                 270.0   \n",
       "  8                7763.0                10.0                 270.0   \n",
       "  9                7763.0                10.0                 270.0   \n",
       "  10               7763.0                10.0                 270.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                20.0                548.0  \n",
       "  1                20.0                548.0  \n",
       "  2                20.0                548.0  \n",
       "  3                20.0                548.0  \n",
       "  4                20.0                548.0  \n",
       "  5                20.0                548.0  \n",
       "  6                20.0                548.0  \n",
       "  7                20.0                548.0  \n",
       "  8                20.0                548.0  \n",
       "  9                20.0                548.0  \n",
       "  10               20.0                548.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8620      0.007314           0.8570   \n",
       "  2                  0.2         0.7738      0.009497           0.7744   \n",
       "  3                  0.3         0.6476      0.020132           0.6514   \n",
       "  4                  0.4         0.5362      0.029355           0.5444   \n",
       "  5                  0.5         0.4300      0.016971           0.4404   \n",
       "  6                  0.6         0.3306      0.015258           0.3372   \n",
       "  7                  0.7         0.2272      0.011987           0.2342   \n",
       "  8                  0.8         0.1244      0.008355           0.1296   \n",
       "  9                  0.9         0.0496      0.005128           0.0506   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008631           0.9484        0.029126           0.1380   \n",
       "  2         0.011283           0.7678        0.061969           0.2262   \n",
       "  3         0.021686           0.5872        0.042145           0.3524   \n",
       "  4         0.031254           0.3936        0.042069           0.4638   \n",
       "  5         0.017897           0.2452        0.036486           0.5700   \n",
       "  6         0.015834           0.2130        0.036837           0.6694   \n",
       "  7         0.015255           0.1100        0.048959           0.7728   \n",
       "  8         0.008204           0.0322        0.022983           0.8756   \n",
       "  9         0.005941           0.0322        0.022983           0.9504   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007314             0.1430  ...        0.018317           0.9028   \n",
       "  2         0.009497             0.2256  ...        0.014433           0.7244   \n",
       "  3         0.020132             0.3486  ...        0.021534           0.6562   \n",
       "  4         0.029355             0.4556  ...        0.032906           0.6724   \n",
       "  5         0.016971             0.5596  ...        0.024542           0.6624   \n",
       "  6         0.015258             0.6628  ...        0.017598           0.7926   \n",
       "  7         0.011987             0.7658  ...        0.003347           0.7048   \n",
       "  8         0.008355             0.8704  ...        0.008246           0.6334   \n",
       "  9         0.005128             0.9494  ...        0.016100           0.8000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              204.0   \n",
       "  1         0.051992                   0.1              204.0   \n",
       "  2         0.057570                   0.2              204.0   \n",
       "  3         0.028270                   0.3              204.0   \n",
       "  4         0.074708                   0.4              204.0   \n",
       "  5         0.108436                   0.5              204.0   \n",
       "  6         0.135795                   0.6              204.0   \n",
       "  7         0.132875                   0.7              204.0   \n",
       "  8         0.415003                   0.8              204.0   \n",
       "  9         0.447214                   0.9              204.0   \n",
       "  10        0.000000                   1.0              204.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7414.0                15.0                 245.0   \n",
       "  1                7414.0                15.0                 245.0   \n",
       "  2                7414.0                15.0                 245.0   \n",
       "  3                7414.0                15.0                 245.0   \n",
       "  4                7414.0                15.0                 245.0   \n",
       "  5                7414.0                15.0                 245.0   \n",
       "  6                7414.0                15.0                 245.0   \n",
       "  7                7414.0                15.0                 245.0   \n",
       "  8                7414.0                15.0                 245.0   \n",
       "  9                7414.0                15.0                 245.0   \n",
       "  10               7414.0                15.0                 245.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                31.0                543.0  \n",
       "  1                31.0                543.0  \n",
       "  2                31.0                543.0  \n",
       "  3                31.0                543.0  \n",
       "  4                31.0                543.0  \n",
       "  5                31.0                543.0  \n",
       "  6                31.0                543.0  \n",
       "  7                31.0                543.0  \n",
       "  8                31.0                543.0  \n",
       "  9                31.0                543.0  \n",
       "  10               31.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns]],\n",
       " 'pred_test_original': [],\n",
       " 'pred_score_scp': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8604      0.014536           0.8642   \n",
       "  2                  0.2         0.7348      0.023931           0.7470   \n",
       "  3                  0.3         0.6278      0.025014           0.6434   \n",
       "  4                  0.4         0.5158      0.024712           0.5346   \n",
       "  5                  0.5         0.4226      0.028562           0.4408   \n",
       "  6                  0.6         0.3298      0.025762           0.3466   \n",
       "  7                  0.7         0.2378      0.014957           0.2504   \n",
       "  8                  0.8         0.1540      0.017059           0.1624   \n",
       "  9                  0.9         0.0746      0.011929           0.0790   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.011563           0.8000        0.077211           0.1396   \n",
       "  2         0.020482           0.5498        0.126260           0.2652   \n",
       "  3         0.027817           0.3888        0.080862           0.3722   \n",
       "  4         0.030138           0.2276        0.113751           0.4842   \n",
       "  5         0.033147           0.1444        0.045583           0.5774   \n",
       "  6         0.029821           0.0778        0.036010           0.6702   \n",
       "  7         0.016502           0.0448        0.015336           0.7622   \n",
       "  8         0.016861           0.0336        0.023426           0.8460   \n",
       "  9         0.012845           0.0112        0.015336           0.9254   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.014536             0.1358  ...          0.090704         0.7788   \n",
       "  2         0.023931             0.2530  ...          0.092899         0.7700   \n",
       "  3         0.025014             0.3566  ...          0.116695         0.8336   \n",
       "  4         0.024712             0.4654  ...          0.146293         0.8984   \n",
       "  5         0.028562             0.5592  ...          0.064070         0.9426   \n",
       "  6         0.025762             0.6534  ...          0.053392         0.9598   \n",
       "  7         0.014957             0.7496  ...          0.023426         0.9666   \n",
       "  8         0.017059             0.8376  ...          0.042004         0.9618   \n",
       "  9         0.011929             0.9210  ...          0.022950         0.9480   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.026659           0.7844        0.030484           0.6990   \n",
       "  2       0.066193           0.7816        0.070476           0.5790   \n",
       "  3       0.061549           0.8478        0.063919           0.5776   \n",
       "  4       0.068028           0.9148        0.069182           0.5264   \n",
       "  5       0.028068           0.9604        0.026595           0.4940   \n",
       "  6       0.018913           0.9790        0.015922           0.3912   \n",
       "  7       0.007403           0.9884        0.004219           0.3266   \n",
       "  8       0.012598           0.9846        0.005225           0.3266   \n",
       "  9       0.009823           0.9876        0.011415           0.1332   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.086078                   0.1            0              0  \n",
       "  2         0.067963                   0.2            0              0  \n",
       "  3         0.064632                   0.3            0              0  \n",
       "  4         0.126306                   0.4            0              0  \n",
       "  5         0.050055                   0.5            0              0  \n",
       "  6         0.099220                   0.6            0              0  \n",
       "  7         0.075085                   0.7            0              0  \n",
       "  8         0.192062                   0.8            0              0  \n",
       "  9         0.182392                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8848      0.024386           0.8820   \n",
       "  2                  0.2         0.7726      0.014467           0.7686   \n",
       "  3                  0.3         0.6710      0.019685           0.6728   \n",
       "  4                  0.4         0.5658      0.020315           0.5704   \n",
       "  5                  0.5         0.4680      0.024525           0.4712   \n",
       "  6                  0.6         0.3734      0.018393           0.3768   \n",
       "  7                  0.7         0.2782      0.012337           0.2816   \n",
       "  8                  0.8         0.1718      0.014789           0.1770   \n",
       "  9                  0.9         0.0856      0.006066           0.0902   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.026954           0.9104        0.030794           0.1152   \n",
       "  2         0.022323           0.8084        0.058731           0.2274   \n",
       "  3         0.024540           0.6572        0.036169           0.3290   \n",
       "  4         0.026150           0.5226        0.065683           0.4342   \n",
       "  5         0.029995           0.4368        0.042246           0.5320   \n",
       "  6         0.022264           0.3428        0.036588           0.6266   \n",
       "  7         0.010479           0.2450        0.072267           0.7218   \n",
       "  8         0.011769           0.1268        0.044189           0.8282   \n",
       "  9         0.007190           0.0410        0.000000           0.9144   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.024386             0.1180  ...          0.030728         0.7124   \n",
       "  2         0.014467             0.2314  ...          0.046869         0.6864   \n",
       "  3         0.019685             0.3272  ...          0.020501         0.6860   \n",
       "  4         0.020315             0.4296  ...          0.036855         0.7568   \n",
       "  5         0.024525             0.5288  ...          0.064511         0.8236   \n",
       "  6         0.018393             0.6232  ...          0.059008         0.8830   \n",
       "  7         0.012337             0.7184  ...          0.098378         0.9378   \n",
       "  8         0.014789             0.8230  ...          0.064112         0.9552   \n",
       "  9         0.006066             0.9098  ...          0.026576         0.9596   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.074188           0.6908        0.087998           0.8420   \n",
       "  2       0.026959           0.6778        0.037719           0.7586   \n",
       "  3       0.027322           0.6880        0.032404           0.6706   \n",
       "  4       0.054039           0.7660        0.066246           0.6796   \n",
       "  5       0.055392           0.8372        0.063908           0.7148   \n",
       "  6       0.048466           0.9000        0.053502           0.7476   \n",
       "  7       0.030720           0.9616        0.028684           0.7416   \n",
       "  8       0.015189           0.9900        0.005612           0.6606   \n",
       "  9       0.028343           1.0000        0.000000           0.5934   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.048306                   0.1            0              0  \n",
       "  2         0.066293                   0.2            0              0  \n",
       "  3         0.026073                   0.3            0              0  \n",
       "  4         0.056779                   0.4            0              0  \n",
       "  5         0.040382                   0.5            0              0  \n",
       "  6         0.067148                   0.6            0              0  \n",
       "  7         0.081248                   0.7            0              0  \n",
       "  8         0.060624                   0.8            0              0  \n",
       "  9         0.252127                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9156      0.010550           0.9154   \n",
       "  2                  0.2         0.7920      0.006042           0.7932   \n",
       "  3                  0.3         0.6682      0.018953           0.6710   \n",
       "  4                  0.4         0.5664      0.026913           0.5712   \n",
       "  5                  0.5         0.4584      0.012954           0.4672   \n",
       "  6                  0.6         0.3552      0.024803           0.3624   \n",
       "  7                  0.7         0.2484      0.027061           0.2536   \n",
       "  8                  0.8         0.1634      0.014519           0.1666   \n",
       "  9                  0.9         0.0826      0.007503           0.0844   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010784           0.9272        0.099686           0.0844   \n",
       "  2         0.008643           0.7454        0.252227           0.2080   \n",
       "  3         0.021529           0.5272        0.275555           0.3318   \n",
       "  4         0.027887           0.3274        0.261787           0.4336   \n",
       "  5         0.012911           0.0182        0.040696           0.5416   \n",
       "  6         0.025205           0.0000        0.000000           0.6448   \n",
       "  7         0.027501           0.0000        0.000000           0.7516   \n",
       "  8         0.014536           0.0000        0.000000           0.8366   \n",
       "  9         0.007635           0.0000        0.000000           0.9174   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.010550             0.0846  ...          0.103450         0.8134   \n",
       "  2         0.006042             0.2068  ...          0.162786         0.7550   \n",
       "  3         0.018953             0.3290  ...          0.284444         0.8052   \n",
       "  4         0.026913             0.4288  ...          0.331376         0.9402   \n",
       "  5         0.012954             0.5328  ...          0.118649         0.9930   \n",
       "  6         0.024803             0.6376  ...          0.099686         0.9958   \n",
       "  7         0.027061             0.7464  ...          0.040696         0.9984   \n",
       "  8         0.014519             0.8334  ...          0.000000         1.0000   \n",
       "  9         0.007503             0.9156  ...          0.000000         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.058183           0.8110        0.062438           0.8700   \n",
       "  2       0.107138           0.7538        0.110845           0.8024   \n",
       "  3       0.117734           0.8070        0.120397           0.6842   \n",
       "  4       0.070148           0.9450        0.071896           0.5170   \n",
       "  5       0.005000           0.9968        0.001789           0.0666   \n",
       "  6       0.005762           1.0000        0.000000           0.0000   \n",
       "  7       0.003578           1.0000        0.000000           0.0000   \n",
       "  8       0.000000           1.0000        0.000000           0.0000   \n",
       "  9       0.000000           1.0000        0.000000           0.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.185742                   0.1            0              0  \n",
       "  2         0.230350                   0.2            0              0  \n",
       "  3         0.187547                   0.3            0              0  \n",
       "  4         0.347506                   0.4            0              0  \n",
       "  5         0.148922                   0.5            0              0  \n",
       "  6         0.000000                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8624      0.018889           0.8598   \n",
       "  2                  0.2         0.7434      0.022744           0.7384   \n",
       "  3                  0.3         0.6394      0.014484           0.6346   \n",
       "  4                  0.4         0.5448      0.016037           0.5436   \n",
       "  5                  0.5         0.4508      0.014653           0.4516   \n",
       "  6                  0.6         0.3558      0.017138           0.3578   \n",
       "  7                  0.7         0.2650      0.015684           0.2656   \n",
       "  8                  0.8         0.1814      0.013520           0.1814   \n",
       "  9                  0.9         0.0908      0.013027           0.0914   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.018939           0.9366        0.023255           0.1376   \n",
       "  2         0.023093           0.8946        0.052500           0.2566   \n",
       "  3         0.014943           0.7788        0.043866           0.3606   \n",
       "  4         0.016682           0.5896        0.101298           0.4552   \n",
       "  5         0.018690           0.4210        0.139564           0.5492   \n",
       "  6         0.021241           0.3052        0.159669           0.6442   \n",
       "  7         0.016502           0.2526        0.077803           0.7350   \n",
       "  8         0.013903           0.1792        0.095591           0.8186   \n",
       "  9         0.012661           0.0738        0.079851           0.9092   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.018889             0.1402  ...          0.093999         0.6908   \n",
       "  2         0.022744             0.2616  ...          0.101298         0.6722   \n",
       "  3         0.014484             0.3654  ...          0.057511         0.6892   \n",
       "  4         0.016037             0.4564  ...          0.125594         0.7654   \n",
       "  5         0.014653             0.5484  ...          0.125719         0.8264   \n",
       "  6         0.017138             0.6422  ...          0.146222         0.8868   \n",
       "  7         0.015684             0.7344  ...          0.077938         0.9178   \n",
       "  8         0.013520             0.8186  ...          0.095482         0.9274   \n",
       "  9         0.013027             0.9086  ...          0.079917         0.9508   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.071545           0.6806        0.077594           0.8906   \n",
       "  2       0.052504           0.6650        0.055709           0.8776   \n",
       "  3       0.044997           0.6852        0.045861           0.8148   \n",
       "  4       0.036692           0.7626        0.038194           0.8504   \n",
       "  5       0.019308           0.8264        0.020268           0.8060   \n",
       "  6       0.035885           0.8888        0.040382           0.7794   \n",
       "  7       0.028252           0.9208        0.030178           0.8182   \n",
       "  8       0.025540           0.9332        0.028102           0.7314   \n",
       "  9       0.014822           0.9680        0.018561           0.4000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.043189                   0.1            0              0  \n",
       "  2         0.049998                   0.2            0              0  \n",
       "  3         0.054906                   0.3            0              0  \n",
       "  4         0.063760                   0.4            0              0  \n",
       "  5         0.097844                   0.5            0              0  \n",
       "  6         0.123634                   0.6            0              0  \n",
       "  7         0.046494                   0.7            0              0  \n",
       "  8         0.136674                   0.8            0              0  \n",
       "  9         0.379144                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8622      0.007918           0.8634   \n",
       "  2                  0.2         0.7586      0.010383           0.7624   \n",
       "  3                  0.3         0.6628      0.015498           0.6718   \n",
       "  4                  0.4         0.5670      0.022405           0.5768   \n",
       "  5                  0.5         0.4786      0.019386           0.4874   \n",
       "  6                  0.6         0.3956      0.018876           0.4050   \n",
       "  7                  0.7         0.3076      0.012759           0.3160   \n",
       "  8                  0.8         0.2084      0.013069           0.2126   \n",
       "  9                  0.9         0.1068      0.007759           0.1112   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004980           0.8536        0.049697           0.1378   \n",
       "  2         0.014893           0.7286        0.052856           0.2414   \n",
       "  3         0.015991           0.5890        0.040249           0.3372   \n",
       "  4         0.023004           0.4856        0.062228           0.4330   \n",
       "  5         0.020020           0.4038        0.020523           0.5214   \n",
       "  6         0.022506           0.3178        0.034157           0.6044   \n",
       "  7         0.015199           0.2392        0.032699           0.6924   \n",
       "  8         0.015241           0.1716        0.026904           0.7916   \n",
       "  9         0.009418           0.0716        0.035501           0.8932   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007918             0.1366  ...          0.046071         0.8510   \n",
       "  2         0.010383             0.2376  ...          0.067526         0.8598   \n",
       "  3         0.015498             0.3282  ...          0.046497         0.9078   \n",
       "  4         0.022405             0.4232  ...          0.063216         0.9244   \n",
       "  5         0.019386             0.5126  ...          0.021640         0.9332   \n",
       "  6         0.018876             0.5950  ...          0.032342         0.9458   \n",
       "  7         0.012759             0.6840  ...          0.028460         0.9528   \n",
       "  8         0.013069             0.7874  ...          0.026262         0.9552   \n",
       "  9         0.007759             0.8888  ...          0.035501         0.9812   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.005745           0.8520        0.007483           0.8400   \n",
       "  2       0.018833           0.8576        0.021161           0.8800   \n",
       "  3       0.010545           0.9052        0.010849           0.9324   \n",
       "  4       0.008325           0.9232        0.008585           0.9374   \n",
       "  5       0.006458           0.9322        0.007155           0.9420   \n",
       "  6       0.002168           0.9446        0.003507           0.9562   \n",
       "  7       0.004324           0.9524        0.005941           0.9556   \n",
       "  8       0.012091           0.9562        0.016285           0.9418   \n",
       "  9       0.027105           0.9804        0.028369           1.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.049583                   0.1            0              0  \n",
       "  2         0.018097                   0.2            0              0  \n",
       "  3         0.012402                   0.3            0              0  \n",
       "  4         0.016712                   0.4            0              0  \n",
       "  5         0.021552                   0.5            0              0  \n",
       "  6         0.025004                   0.6            0              0  \n",
       "  7         0.041247                   0.7            0              0  \n",
       "  8         0.053256                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8342      0.022753           0.8388   \n",
       "  2                  0.2         0.7126      0.010877           0.7214   \n",
       "  3                  0.3         0.6096      0.003782           0.6262   \n",
       "  4                  0.4         0.5094      0.015437           0.5260   \n",
       "  5                  0.5         0.4190      0.010700           0.4364   \n",
       "  6                  0.6         0.3326      0.006877           0.3466   \n",
       "  7                  0.7         0.2554      0.012341           0.2674   \n",
       "  8                  0.8         0.1600      0.015890           0.1668   \n",
       "  9                  0.9         0.0694      0.008820           0.0734   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.022129            0.770        0.103682           0.1658   \n",
       "  2         0.012280            0.590        0.057554           0.2874   \n",
       "  3         0.006723            0.385        0.065192           0.3904   \n",
       "  4         0.015017            0.285        0.057554           0.4906   \n",
       "  5         0.010714            0.180        0.032596           0.5810   \n",
       "  6         0.007503            0.145        0.020917           0.6674   \n",
       "  7         0.012502            0.100        0.017678           0.7446   \n",
       "  8         0.017470            0.070        0.027386           0.8400   \n",
       "  9         0.009633            0.015        0.013693           0.9306   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.022753             0.1612  ...          0.105178         0.7674   \n",
       "  2         0.010877             0.2786  ...          0.032596         0.7230   \n",
       "  3         0.003782             0.3738  ...          0.051841         0.7876   \n",
       "  4         0.015437             0.4740  ...          0.044721         0.8232   \n",
       "  5         0.010700             0.5636  ...          0.032596         0.8718   \n",
       "  6         0.006877             0.6534  ...          0.028504         0.9108   \n",
       "  7         0.012341             0.7326  ...          0.027386         0.9558   \n",
       "  8         0.015890             0.8332  ...          0.028504         0.9718   \n",
       "  9         0.008820             0.9266  ...          0.020917         0.9810   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.020354           0.7758        0.024448           0.6420   \n",
       "  2       0.022528           0.7316        0.025106           0.6020   \n",
       "  3       0.029602           0.8048        0.032268           0.5360   \n",
       "  4       0.033432           0.8380        0.036776           0.5786   \n",
       "  5       0.016932           0.8846        0.021881           0.5938   \n",
       "  6       0.037212           0.9206        0.039784           0.6882   \n",
       "  7       0.018295           0.9596        0.020744           0.8534   \n",
       "  8       0.016316           0.9768        0.014202           0.8268   \n",
       "  9       0.010932           0.9850        0.013910           0.5000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.116280                   0.1            0              0  \n",
       "  2         0.037729                   0.2            0              0  \n",
       "  3         0.064757                   0.3            0              0  \n",
       "  4         0.115294                   0.4            0              0  \n",
       "  5         0.109019                   0.5            0              0  \n",
       "  6         0.152703                   0.6            0              0  \n",
       "  7         0.144422                   0.7            0              0  \n",
       "  8         0.167173                   0.8            0              0  \n",
       "  9         0.500000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8686      0.012973           0.8722   \n",
       "  2                  0.2         0.7646      0.007925           0.7670   \n",
       "  3                  0.3         0.6542      0.014805           0.6664   \n",
       "  4                  0.4         0.5472      0.016589           0.5638   \n",
       "  5                  0.5         0.4504      0.021652           0.4706   \n",
       "  6                  0.6         0.3620      0.023896           0.3788   \n",
       "  7                  0.7         0.2762      0.016037           0.2924   \n",
       "  8                  0.8         0.1990      0.023537           0.2130   \n",
       "  9                  0.9         0.1082      0.013424           0.1152   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.014533           0.8224        0.024542           0.1314   \n",
       "  2         0.005000           0.7334        0.057774           0.2354   \n",
       "  3         0.015010           0.5000        0.058690           0.3458   \n",
       "  4         0.015547           0.3334        0.073609           0.4528   \n",
       "  5         0.018501           0.1944        0.073609           0.5496   \n",
       "  6         0.024427           0.1388        0.058572           0.6380   \n",
       "  7         0.016772           0.0612        0.036010           0.7238   \n",
       "  8         0.026115           0.0224        0.012522           0.8010   \n",
       "  9         0.014772           0.0112        0.015336           0.8918   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.012973             0.1278  ...          0.069683         0.8040   \n",
       "  2         0.007925             0.2330  ...          0.055500         0.7562   \n",
       "  3         0.014805             0.3336  ...          0.072574         0.8040   \n",
       "  4         0.016589             0.4362  ...          0.077574         0.8446   \n",
       "  5         0.021652             0.5294  ...          0.060957         0.9058   \n",
       "  6         0.023896             0.6212  ...          0.045675         0.9338   \n",
       "  7         0.016037             0.7076  ...          0.037566         0.9702   \n",
       "  8         0.023537             0.7870  ...          0.012522         0.9880   \n",
       "  9         0.013424             0.8848  ...          0.015336         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.020012           0.8106        0.020305           0.7136   \n",
       "  2       0.008167           0.7588        0.009960           0.7198   \n",
       "  3       0.009487           0.8120        0.013398           0.6818   \n",
       "  4       0.018407           0.8568        0.022532           0.6402   \n",
       "  5       0.020801           0.9240        0.024536           0.5488   \n",
       "  6       0.010569           0.9566        0.011437           0.4938   \n",
       "  7       0.021347           0.9854        0.014311           0.4934   \n",
       "  8       0.008660           0.9976        0.005367           0.5000   \n",
       "  9       0.000000           1.0000        0.000000           0.4000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.035473                   0.1            0              0  \n",
       "  2         0.045719                   0.2            0              0  \n",
       "  3         0.049338                   0.3            0              0  \n",
       "  4         0.067533                   0.4            0              0  \n",
       "  5         0.146994                   0.5            0              0  \n",
       "  6         0.153268                   0.6            0              0  \n",
       "  7         0.214155                   0.7            0              0  \n",
       "  8         0.353553                   0.8            0              0  \n",
       "  9         0.547723                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8422      0.010134           0.8314   \n",
       "  2                  0.2         0.6964      0.004336           0.6886   \n",
       "  3                  0.3         0.6014      0.015694           0.5984   \n",
       "  4                  0.4         0.5120      0.018628           0.5144   \n",
       "  5                  0.5         0.4200      0.017407           0.4268   \n",
       "  6                  0.6         0.3318      0.016649           0.3402   \n",
       "  7                  0.7         0.2412      0.015123           0.2454   \n",
       "  8                  0.8         0.1570      0.021726           0.1572   \n",
       "  9                  0.9         0.0722      0.006419           0.0706   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.017344           0.8944        0.039336           0.1578   \n",
       "  2         0.006986           0.7348        0.049646           0.3036   \n",
       "  3         0.020936           0.6158        0.060330           0.3986   \n",
       "  4         0.024172           0.4990        0.081713           0.4880   \n",
       "  5         0.022354           0.3866        0.067545           0.5800   \n",
       "  6         0.019292           0.2898        0.054733           0.6682   \n",
       "  7         0.019616           0.2202        0.033154           0.7588   \n",
       "  8         0.023059           0.1574        0.031643           0.8430   \n",
       "  9         0.005459           0.0784        0.016087           0.9278   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.010134             0.1686  ...          0.043062         0.7434   \n",
       "  2         0.004336             0.3114  ...          0.023244         0.6800   \n",
       "  3         0.015694             0.4016  ...          0.055442         0.7178   \n",
       "  4         0.018628             0.4856  ...          0.088734         0.7636   \n",
       "  5         0.017407             0.5732  ...          0.052520         0.8030   \n",
       "  6         0.016649             0.6598  ...          0.035522         0.8464   \n",
       "  7         0.015123             0.7546  ...          0.029266         0.8528   \n",
       "  8         0.021726             0.8428  ...          0.026331         0.8618   \n",
       "  9         0.006419             0.9294  ...          0.021249         0.8592   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.020107           0.7276        0.034406           0.8252   \n",
       "  2       0.008718           0.6714        0.016994           0.7210   \n",
       "  3       0.028261           0.7120        0.041755           0.7462   \n",
       "  4       0.033284           0.7576        0.047035           0.7922   \n",
       "  5       0.019647           0.7990        0.033667           0.8192   \n",
       "  6       0.018528           0.8454        0.023512           0.8456   \n",
       "  7       0.021753           0.8506        0.024296           0.8604   \n",
       "  8       0.016037           0.8588        0.019447           0.8712   \n",
       "  9       0.046149           0.8558        0.039480           0.8850   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.056698                   0.1            0              0  \n",
       "  2         0.047387                   0.2            0              0  \n",
       "  3         0.047976                   0.3            0              0  \n",
       "  4         0.068273                   0.4            0              0  \n",
       "  5         0.081091                   0.5            0              0  \n",
       "  6         0.108246                   0.6            0              0  \n",
       "  7         0.095259                   0.7            0              0  \n",
       "  8         0.075357                   0.8            0              0  \n",
       "  9         0.111745                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9028      0.027499           0.9052   \n",
       "  2                  0.2         0.7754      0.016227           0.7820   \n",
       "  3                  0.3         0.6676      0.016979           0.6768   \n",
       "  4                  0.4         0.5682      0.016873           0.5764   \n",
       "  5                  0.5         0.4676      0.017401           0.4746   \n",
       "  6                  0.6         0.3712      0.014957           0.3764   \n",
       "  7                  0.7         0.2780      0.009618           0.2824   \n",
       "  8                  0.8         0.1836      0.018770           0.1862   \n",
       "  9                  0.9         0.0988      0.010545           0.0998   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.030161            0.750        0.233854           0.0972   \n",
       "  2         0.020359            0.325        0.325960           0.2246   \n",
       "  3         0.017297            0.025        0.055902           0.3324   \n",
       "  4         0.016682            0.000        0.000000           0.4318   \n",
       "  5         0.017401            0.000        0.000000           0.5324   \n",
       "  6         0.015159            0.000        0.000000           0.6288   \n",
       "  7         0.010015            0.000        0.000000           0.7220   \n",
       "  8         0.019189            0.000        0.000000           0.8164   \n",
       "  9         0.010545            0.000        0.000000           0.9012   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.027499             0.0948  ...          0.189572         0.8262   \n",
       "  2         0.016227             0.2180  ...          0.227074         0.8458   \n",
       "  3         0.016979             0.3232  ...          0.136931         0.9764   \n",
       "  4         0.016873             0.4236  ...          0.142522         0.9894   \n",
       "  5         0.017401             0.5254  ...          0.111803         0.9926   \n",
       "  6         0.014957             0.6236  ...          0.068465         0.9970   \n",
       "  7         0.009618             0.7176  ...          0.055902         0.9988   \n",
       "  8         0.018770             0.8138  ...          0.000000         1.0000   \n",
       "  9         0.010545             0.9002  ...          0.000000         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.080803           0.8294        0.085521           0.6092   \n",
       "  2       0.090979           0.8512        0.094115           0.3392   \n",
       "  3       0.011887           0.9842        0.013627           0.0666   \n",
       "  4       0.003286           0.9970        0.000000           0.0000   \n",
       "  5       0.005128           0.9976        0.002191           0.0000   \n",
       "  6       0.002739           1.0000        0.000000           0.0000   \n",
       "  7       0.002683           1.0000        0.000000           0.0000   \n",
       "  8       0.000000           1.0000        0.000000           0.0000   \n",
       "  9       0.000000           1.0000        0.000000           0.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.306515                   0.1            0              0  \n",
       "  2         0.336854                   0.2            0              0  \n",
       "  3         0.148922                   0.3            0              0  \n",
       "  4         0.000000                   0.4            0              0  \n",
       "  5         0.000000                   0.5            0              0  \n",
       "  6         0.000000                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8540      0.014213           0.8420   \n",
       "  2                  0.2         0.7170      0.004690           0.6984   \n",
       "  3                  0.3         0.5992      0.007190           0.5822   \n",
       "  4                  0.4         0.5046      0.012915           0.4916   \n",
       "  5                  0.5         0.4186      0.011371           0.4126   \n",
       "  6                  0.6         0.3368      0.012578           0.3360   \n",
       "  7                  0.7         0.2488      0.015304           0.2546   \n",
       "  8                  0.8         0.1576      0.006693           0.1596   \n",
       "  9                  0.9         0.0658      0.005357           0.0666   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.017944           0.9408        0.023552           0.1460   \n",
       "  2         0.006387           0.8504        0.065763           0.2830   \n",
       "  3         0.006419           0.7210        0.037829           0.4008   \n",
       "  4         0.011082           0.5970        0.051551           0.4954   \n",
       "  5         0.011610           0.4622        0.036238           0.5814   \n",
       "  6         0.008367           0.3410        0.054056           0.6632   \n",
       "  7         0.013221           0.2084        0.041651           0.7512   \n",
       "  8         0.009737           0.1438        0.025044           0.8424   \n",
       "  9         0.005550           0.0588        0.011713           0.9342   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.014213             0.1580  ...          0.021232         0.8236   \n",
       "  2         0.004690             0.3016  ...          0.052785         0.8020   \n",
       "  3         0.007190             0.4178  ...          0.044053         0.8572   \n",
       "  4         0.012915             0.5084  ...          0.046041         0.8760   \n",
       "  5         0.011371             0.5874  ...          0.033716         0.8946   \n",
       "  6         0.012578             0.6640  ...          0.057238         0.9188   \n",
       "  7         0.015304             0.7454  ...          0.044323         0.9410   \n",
       "  8         0.006693             0.8404  ...          0.027291         0.9440   \n",
       "  9         0.005357             0.9334  ...          0.018716         0.9228   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.018823           0.8078        0.025263           0.9316   \n",
       "  2       0.030879           0.7836        0.037846           0.9284   \n",
       "  3       0.022298           0.8428        0.025636           0.9518   \n",
       "  4       0.019558           0.8634        0.022390           0.9586   \n",
       "  5       0.015437           0.8870        0.015700           0.9474   \n",
       "  6       0.016814           0.9172        0.017225           0.9310   \n",
       "  7       0.020125           0.9456        0.018836           0.9012   \n",
       "  8       0.013323           0.9528        0.011967           0.8792   \n",
       "  9       0.016069           0.9286        0.012896           0.8932   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.027510                   0.1            0              0  \n",
       "  2         0.024058                   0.2            0              0  \n",
       "  3         0.014498                   0.3            0              0  \n",
       "  4         0.012178                   0.4            0              0  \n",
       "  5         0.014188                   0.5            0              0  \n",
       "  6         0.016386                   0.6            0              0  \n",
       "  7         0.036169                   0.7            0              0  \n",
       "  8         0.042252                   0.8            0              0  \n",
       "  9         0.098421                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8788      0.012853           0.8790   \n",
       "  2                  0.2         0.7708      0.026874           0.7724   \n",
       "  3                  0.3         0.6642      0.016053           0.6712   \n",
       "  4                  0.4         0.5562      0.012853           0.5660   \n",
       "  5                  0.5         0.4696      0.021478           0.4782   \n",
       "  6                  0.6         0.3728      0.027317           0.3798   \n",
       "  7                  0.7         0.2898      0.026725           0.2942   \n",
       "  8                  0.8         0.1908      0.020535           0.1934   \n",
       "  9                  0.9         0.0896      0.009915           0.0906   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.013454             0.88        0.090830           0.1212   \n",
       "  2         0.025929             0.73        0.115109           0.2292   \n",
       "  3         0.016769             0.47        0.044721           0.3358   \n",
       "  4         0.014629             0.29        0.082158           0.4438   \n",
       "  5         0.022219             0.23        0.027386           0.5304   \n",
       "  6         0.028208             0.18        0.027386           0.6272   \n",
       "  7         0.027308             0.17        0.027386           0.7102   \n",
       "  8         0.021019             0.12        0.027386           0.8092   \n",
       "  9         0.010597             0.06        0.022361           0.9104   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.012853             0.1210  ...          0.089443         0.7396   \n",
       "  2         0.026874             0.2276  ...          0.130384         0.7288   \n",
       "  3         0.016053             0.3288  ...          0.114018         0.8198   \n",
       "  4         0.012853             0.4340  ...          0.129422         0.9174   \n",
       "  5         0.021478             0.5218  ...          0.044721         0.9632   \n",
       "  6         0.027317             0.6202  ...          0.041833         0.9816   \n",
       "  7         0.026725             0.7058  ...          0.044721         0.9928   \n",
       "  8         0.020535             0.8066  ...          0.044721         0.9984   \n",
       "  9         0.009915             0.9094  ...          0.022361         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.080086           0.7360        0.089786           0.7994   \n",
       "  2       0.038855           0.7300        0.041261           0.6990   \n",
       "  3       0.045069           0.8284        0.044920           0.5858   \n",
       "  4       0.050570           0.9294        0.051403           0.5356   \n",
       "  5       0.009471           0.9760        0.008337           0.5500   \n",
       "  6       0.007403           0.9932        0.005586           0.5818   \n",
       "  7       0.004764           0.9988        0.002683           0.7900   \n",
       "  8       0.003578           1.0000        0.000000           0.9500   \n",
       "  9       0.000000           1.0000        0.000000           1.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.149599                   0.1            0              0  \n",
       "  2         0.093867                   0.2            0              0  \n",
       "  3         0.073629                   0.3            0              0  \n",
       "  4         0.068755                   0.4            0              0  \n",
       "  5         0.068465                   0.5            0              0  \n",
       "  6         0.060239                   0.6            0              0  \n",
       "  7         0.143178                   0.7            0              0  \n",
       "  8         0.111803                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8748      0.003421           0.8716   \n",
       "  2                  0.2         0.7600      0.022215           0.7618   \n",
       "  3                  0.3         0.6640      0.009138           0.6678   \n",
       "  4                  0.4         0.5612      0.017196           0.5716   \n",
       "  5                  0.5         0.4570      0.026533           0.4668   \n",
       "  6                  0.6         0.3606      0.019488           0.3704   \n",
       "  7                  0.7         0.2590      0.014265           0.2686   \n",
       "  8                  0.8         0.1592      0.006834           0.1646   \n",
       "  9                  0.9         0.0728      0.007463           0.0754   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005814           0.9352        0.039601           0.1252   \n",
       "  2         0.021123           0.7352        0.066020           0.2400   \n",
       "  3         0.011541           0.5998        0.103572           0.3360   \n",
       "  4         0.021617           0.3808        0.117033           0.4388   \n",
       "  5         0.027689           0.2902        0.134941           0.5430   \n",
       "  6         0.018796           0.1872        0.080543           0.6394   \n",
       "  7         0.015339           0.0840        0.067153           0.7410   \n",
       "  8         0.008385           0.0708        0.057747           0.8408   \n",
       "  9         0.007603           0.0256        0.014311           0.9272   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.003421             0.1284  ...          0.053966         0.6940   \n",
       "  2         0.022215             0.2382  ...          0.062867         0.7066   \n",
       "  3         0.009138             0.3322  ...          0.089428         0.7268   \n",
       "  4         0.017196             0.4284  ...          0.145398         0.8294   \n",
       "  5         0.026533             0.5332  ...          0.181368         0.8888   \n",
       "  6         0.019488             0.6296  ...          0.108403         0.9374   \n",
       "  7         0.014265             0.7314  ...          0.073388         0.9704   \n",
       "  8         0.006834             0.8354  ...          0.062204         0.9724   \n",
       "  9         0.007463             0.9246  ...          0.022983         0.9900   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.092166           0.6814        0.108096           0.8654   \n",
       "  2       0.039652           0.7078        0.039996           0.6920   \n",
       "  3       0.066119           0.7302        0.071925           0.6664   \n",
       "  4       0.072958           0.8408        0.077677           0.6036   \n",
       "  5       0.089873           0.9040        0.095323           0.5784   \n",
       "  6       0.060007           0.9510        0.060712           0.6140   \n",
       "  7       0.029322           0.9802        0.029474           0.5666   \n",
       "  8       0.026035           0.9776        0.027355           0.7666   \n",
       "  9       0.013693           0.9948        0.011628           0.7000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.078350                   0.1            0              0  \n",
       "  2         0.062610                   0.2            0              0  \n",
       "  3         0.077429                   0.3            0              0  \n",
       "  4         0.094479                   0.4            0              0  \n",
       "  5         0.076275                   0.5            0              0  \n",
       "  6         0.096757                   0.6            0              0  \n",
       "  7         0.180770                   0.7            0              0  \n",
       "  8         0.252741                   0.8            0              0  \n",
       "  9         0.447214                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns]],\n",
       " 'pred_score_calupdate': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9166      0.004775           0.9186   \n",
       "  2                  0.2         0.8294      0.020983           0.8322   \n",
       "  3                  0.3         0.7178      0.015944           0.7230   \n",
       "  4                  0.4         0.6048      0.007259           0.6090   \n",
       "  5                  0.5         0.5020      0.007211           0.5052   \n",
       "  6                  0.6         0.4096      0.015978           0.4148   \n",
       "  7                  0.7         0.3152      0.021017           0.3212   \n",
       "  8                  0.8         0.2224      0.019565           0.2268   \n",
       "  9                  0.9         0.1224      0.015076           0.1268   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.002608           0.8888        0.064921           0.0834   \n",
       "  2         0.022332           0.7888        0.057556           0.1706   \n",
       "  3         0.015890           0.6388        0.058572           0.2822   \n",
       "  4         0.007141           0.5390        0.031575           0.3952   \n",
       "  5         0.006686           0.4498        0.041161           0.4980   \n",
       "  6         0.016037           0.3334        0.092037           0.5904   \n",
       "  7         0.022753           0.2220        0.028000           0.6848   \n",
       "  8         0.021406           0.1500        0.031575           0.7776   \n",
       "  9         0.014957           0.0612        0.022950           0.8776   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004775             0.0814  ...        0.026115           0.7608   \n",
       "  2         0.020983             0.1678  ...        0.034637           0.7072   \n",
       "  3         0.015944             0.2770  ...        0.026861           0.6096   \n",
       "  4         0.007259             0.3910  ...        0.026272           0.6340   \n",
       "  5         0.007211             0.4948  ...        0.031662           0.6728   \n",
       "  6         0.015978             0.5852  ...        0.037273           0.6828   \n",
       "  7         0.021017             0.6788  ...        0.033764           0.7026   \n",
       "  8         0.019565             0.7732  ...        0.031396           0.6474   \n",
       "  9         0.015076             0.8732  ...        0.007987           0.5266   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              322.0   \n",
       "  1         0.121594                   0.1              322.0   \n",
       "  2         0.051207                   0.2              322.0   \n",
       "  3         0.043403                   0.3              322.0   \n",
       "  4         0.020640                   0.4              322.0   \n",
       "  5         0.038713                   0.5              322.0   \n",
       "  6         0.090987                   0.6              322.0   \n",
       "  7         0.126059                   0.7              322.0   \n",
       "  8         0.100066                   0.8              322.0   \n",
       "  9         0.205762                   0.9              322.0   \n",
       "  10        0.000000                   1.0              322.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8179.0                25.0                 240.0   \n",
       "  1                8179.0                25.0                 240.0   \n",
       "  2                8179.0                25.0                 240.0   \n",
       "  3                8179.0                25.0                 240.0   \n",
       "  4                8179.0                25.0                 240.0   \n",
       "  5                8179.0                25.0                 240.0   \n",
       "  6                8179.0                25.0                 240.0   \n",
       "  7                8179.0                25.0                 240.0   \n",
       "  8                8179.0                25.0                 240.0   \n",
       "  9                8179.0                25.0                 240.0   \n",
       "  10               8179.0                25.0                 240.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                554.0  \n",
       "  1                36.0                554.0  \n",
       "  2                36.0                554.0  \n",
       "  3                36.0                554.0  \n",
       "  4                36.0                554.0  \n",
       "  5                36.0                554.0  \n",
       "  6                36.0                554.0  \n",
       "  7                36.0                554.0  \n",
       "  8                36.0                554.0  \n",
       "  9                36.0                554.0  \n",
       "  10               36.0                554.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9396      0.014656           0.9352   \n",
       "  2                  0.2         0.8722      0.009203           0.8704   \n",
       "  3                  0.3         0.8000      0.014000           0.8030   \n",
       "  4                  0.4         0.7084      0.006542           0.7168   \n",
       "  5                  0.5         0.5760      0.011511           0.5812   \n",
       "  6                  0.6         0.4556      0.017228           0.4544   \n",
       "  7                  0.7         0.3252      0.020216           0.3210   \n",
       "  8                  0.8         0.1936      0.014519           0.1864   \n",
       "  9                  0.9         0.0730      0.011769           0.0674   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.017712           0.9796        0.020501           0.0604   \n",
       "  2         0.010040           0.8900        0.017889           0.1278   \n",
       "  3         0.018588           0.7716        0.026576           0.2000   \n",
       "  4         0.009524           0.6326        0.032098           0.2916   \n",
       "  5         0.012296           0.5268        0.009391           0.4240   \n",
       "  6         0.017387           0.4652        0.033656           0.5444   \n",
       "  7         0.024114           0.3632        0.046397           0.6748   \n",
       "  8         0.016227           0.2570        0.037020           0.8064   \n",
       "  9         0.012422           0.1224        0.020501           0.9270   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.014656             0.0648  ...        0.154447           0.9436   \n",
       "  2         0.009203             0.1296  ...        0.055308           0.8132   \n",
       "  3         0.014000             0.1970  ...        0.038633           0.7090   \n",
       "  4         0.006542             0.2832  ...        0.018377           0.6442   \n",
       "  5         0.011511             0.4188  ...        0.020535           0.6832   \n",
       "  6         0.017228             0.5456  ...        0.020801           0.7354   \n",
       "  7         0.020216             0.6790  ...        0.026243           0.8208   \n",
       "  8         0.014519             0.8136  ...        0.026235           0.8436   \n",
       "  9         0.011769             0.9326  ...        0.046168           0.9714   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              901.0   \n",
       "  1         0.057335                   0.1              901.0   \n",
       "  2         0.032660                   0.2              901.0   \n",
       "  3         0.025150                   0.3              901.0   \n",
       "  4         0.015515                   0.4              901.0   \n",
       "  5         0.019202                   0.5              901.0   \n",
       "  6         0.020256                   0.6              901.0   \n",
       "  7         0.048463                   0.7              901.0   \n",
       "  8         0.056646                   0.8              901.0   \n",
       "  9         0.063952                   0.9              901.0   \n",
       "  10        0.000000                   1.0              901.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6290.0                27.0                 231.0   \n",
       "  1                6290.0                27.0                 231.0   \n",
       "  2                6290.0                27.0                 231.0   \n",
       "  3                6290.0                27.0                 231.0   \n",
       "  4                6290.0                27.0                 231.0   \n",
       "  5                6290.0                27.0                 231.0   \n",
       "  6                6290.0                27.0                 231.0   \n",
       "  7                6290.0                27.0                 231.0   \n",
       "  8                6290.0                27.0                 231.0   \n",
       "  9                6290.0                27.0                 231.0   \n",
       "  10               6290.0                27.0                 231.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                49.0                441.0  \n",
       "  1                49.0                441.0  \n",
       "  2                49.0                441.0  \n",
       "  3                49.0                441.0  \n",
       "  4                49.0                441.0  \n",
       "  5                49.0                441.0  \n",
       "  6                49.0                441.0  \n",
       "  7                49.0                441.0  \n",
       "  8                49.0                441.0  \n",
       "  9                49.0                441.0  \n",
       "  10               49.0                441.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9526      0.004219           0.9516   \n",
       "  2                  0.2         0.8864      0.011950           0.8850   \n",
       "  3                  0.3         0.8000      0.015232           0.7980   \n",
       "  4                  0.4         0.6986      0.019152           0.6954   \n",
       "  5                  0.5         0.5932      0.026100           0.5880   \n",
       "  6                  0.6         0.4724      0.032700           0.4664   \n",
       "  7                  0.7         0.3334      0.026111           0.3250   \n",
       "  8                  0.8         0.2058      0.019563           0.1976   \n",
       "  9                  0.9         0.0872      0.018240           0.0874   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004219           1.0000        0.000000           0.0474   \n",
       "  2         0.013266           0.9636        0.049843           0.1136   \n",
       "  3         0.015811           0.9090        0.000000           0.2000   \n",
       "  4         0.019321           0.8726        0.049843           0.3014   \n",
       "  5         0.026344           0.8544        0.049843           0.4068   \n",
       "  6         0.033923           0.7816        0.049843           0.5276   \n",
       "  7         0.027230           0.7452        0.118649           0.6666   \n",
       "  8         0.021138           0.6180        0.134672           0.7942   \n",
       "  9         0.019034           0.0910        0.091000           0.9128   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004219             0.0484  ...        0.064585           1.0000   \n",
       "  2         0.011950             0.1150  ...        0.187555           0.9464   \n",
       "  3         0.015232             0.2020  ...        0.137250           0.8750   \n",
       "  4         0.019152             0.3046  ...        0.101503           0.8492   \n",
       "  5         0.026100             0.4120  ...        0.090937           0.8450   \n",
       "  6         0.032700             0.5336  ...        0.078865           0.8450   \n",
       "  7         0.026111             0.6750  ...        0.074460           0.8728   \n",
       "  8         0.019563             0.8024  ...        0.094166           0.9014   \n",
       "  9         0.018240             0.9126  ...        0.044651           0.5334   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              373.0   \n",
       "  1         0.000000                   0.1              373.0   \n",
       "  2         0.073670                   0.2              373.0   \n",
       "  3         0.024249                   0.3              373.0   \n",
       "  4         0.064348                   0.4              373.0   \n",
       "  5         0.045946                   0.5              373.0   \n",
       "  6         0.045946                   0.6              373.0   \n",
       "  7         0.035337                   0.7              373.0   \n",
       "  8         0.057204                   0.8              373.0   \n",
       "  9         0.505547                   0.9              373.0   \n",
       "  10        0.000000                   1.0              373.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8370.0                 3.0                 282.0   \n",
       "  1                8370.0                 3.0                 282.0   \n",
       "  2                8370.0                 3.0                 282.0   \n",
       "  3                8370.0                 3.0                 282.0   \n",
       "  4                8370.0                 3.0                 282.0   \n",
       "  5                8370.0                 3.0                 282.0   \n",
       "  6                8370.0                 3.0                 282.0   \n",
       "  7                8370.0                 3.0                 282.0   \n",
       "  8                8370.0                 3.0                 282.0   \n",
       "  9                8370.0                 3.0                 282.0   \n",
       "  10               8370.0                 3.0                 282.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                11.0                549.0  \n",
       "  1                11.0                549.0  \n",
       "  2                11.0                549.0  \n",
       "  3                11.0                549.0  \n",
       "  4                11.0                549.0  \n",
       "  5                11.0                549.0  \n",
       "  6                11.0                549.0  \n",
       "  7                11.0                549.0  \n",
       "  8                11.0                549.0  \n",
       "  9                11.0                549.0  \n",
       "  10               11.0                549.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9296      0.007956           0.9288   \n",
       "  2                  0.2         0.8566      0.005320           0.8570   \n",
       "  3                  0.3         0.7500      0.010770           0.7488   \n",
       "  4                  0.4         0.6198      0.021112           0.6194   \n",
       "  5                  0.5         0.4742      0.022027           0.4732   \n",
       "  6                  0.6         0.3178      0.023700           0.3166   \n",
       "  7                  0.7         0.1986      0.017184           0.1970   \n",
       "  8                  0.8         0.1070      0.012207           0.1044   \n",
       "  9                  0.9         0.0386      0.008142           0.0368   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008258           0.9470        0.000000           0.0704   \n",
       "  2         0.004301           0.8418        0.074600           0.1434   \n",
       "  3         0.012558           0.7788        0.043866           0.2500   \n",
       "  4         0.022401           0.6318        0.064503           0.3802   \n",
       "  5         0.022797           0.5052        0.028482           0.5258   \n",
       "  6         0.025383           0.3580        0.086571           0.6822   \n",
       "  7         0.017635           0.2526        0.023255           0.8014   \n",
       "  8         0.011803           0.1790        0.087849           0.8930   \n",
       "  9         0.009365           0.0846        0.070660           0.9614   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007956             0.0712  ...        0.106698           0.8900   \n",
       "  2         0.005320             0.1430  ...        0.061145           0.7906   \n",
       "  3         0.010770             0.2512  ...        0.023681           0.7656   \n",
       "  4         0.021112             0.3806  ...        0.036928           0.7588   \n",
       "  5         0.022027             0.5268  ...        0.032859           0.7658   \n",
       "  6         0.023700             0.6834  ...        0.045411           0.7914   \n",
       "  7         0.017184             0.8030  ...        0.030517           0.8026   \n",
       "  8         0.012207             0.8956  ...        0.041669           0.7332   \n",
       "  9         0.008142             0.9632  ...        0.082218           0.6000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              386.0   \n",
       "  1         0.013693                   0.1              386.0   \n",
       "  2         0.086835                   0.2              386.0   \n",
       "  3         0.051714                   0.3              386.0   \n",
       "  4         0.029474                   0.4              386.0   \n",
       "  5         0.056694                   0.5              386.0   \n",
       "  6         0.085372                   0.6              386.0   \n",
       "  7         0.051549                   0.7              386.0   \n",
       "  8         0.136809                   0.8              386.0   \n",
       "  9         0.223607                   0.9              386.0   \n",
       "  10        0.000000                   1.0              386.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7233.0                10.0                 250.0   \n",
       "  1                7233.0                10.0                 250.0   \n",
       "  2                7233.0                10.0                 250.0   \n",
       "  3                7233.0                10.0                 250.0   \n",
       "  4                7233.0                10.0                 250.0   \n",
       "  5                7233.0                10.0                 250.0   \n",
       "  6                7233.0                10.0                 250.0   \n",
       "  7                7233.0                10.0                 250.0   \n",
       "  8                7233.0                10.0                 250.0   \n",
       "  9                7233.0                10.0                 250.0   \n",
       "  10               7233.0                10.0                 250.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                19.0                558.0  \n",
       "  1                19.0                558.0  \n",
       "  2                19.0                558.0  \n",
       "  3                19.0                558.0  \n",
       "  4                19.0                558.0  \n",
       "  5                19.0                558.0  \n",
       "  6                19.0                558.0  \n",
       "  7                19.0                558.0  \n",
       "  8                19.0                558.0  \n",
       "  9                19.0                558.0  \n",
       "  10               19.0                558.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9232      0.005586           0.9272   \n",
       "  2                  0.2         0.8568      0.010986           0.8700   \n",
       "  3                  0.3         0.7778      0.011883           0.7920   \n",
       "  4                  0.4         0.6684      0.014135           0.6798   \n",
       "  5                  0.5         0.5274      0.008355           0.5330   \n",
       "  6                  0.6         0.4032      0.021347           0.4046   \n",
       "  7                  0.7         0.2634      0.007797           0.2578   \n",
       "  8                  0.8         0.1522      0.020499           0.1518   \n",
       "  9                  0.9         0.0564      0.005857           0.0540   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007050           0.8894        0.015060           0.0768   \n",
       "  2         0.012728           0.7500        0.033675           0.1432   \n",
       "  3         0.013077           0.6610        0.012728           0.2222   \n",
       "  4         0.018267           0.5748        0.031894           0.3316   \n",
       "  5         0.008860           0.4822        0.048931           0.4726   \n",
       "  6         0.022601           0.3930        0.033675           0.5968   \n",
       "  7         0.012637           0.3108        0.048153           0.7366   \n",
       "  8         0.019473           0.1536        0.039049           0.8478   \n",
       "  9         0.005000           0.0786        0.029704           0.9436   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.005586             0.0728  ...        0.007893           0.8404   \n",
       "  2         0.010986             0.1300  ...        0.010526           0.7474   \n",
       "  3         0.011883             0.2080  ...        0.003701           0.8384   \n",
       "  4         0.014135             0.3202  ...        0.008614           0.9316   \n",
       "  5         0.008355             0.4670  ...        0.010831           0.9564   \n",
       "  6         0.021347             0.5954  ...        0.004637           0.9900   \n",
       "  7         0.007797             0.7422  ...        0.006427           1.0000   \n",
       "  8         0.020499             0.8482  ...        0.018317           1.0000   \n",
       "  9         0.005857             0.9460  ...        0.030525           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1094.0   \n",
       "  1         0.020305                   0.1             1094.0   \n",
       "  2         0.033374                   0.2             1094.0   \n",
       "  3         0.040979                   0.3             1094.0   \n",
       "  4         0.028979                   0.4             1094.0   \n",
       "  5         0.020452                   0.5             1094.0   \n",
       "  6         0.022361                   0.6             1094.0   \n",
       "  7         0.000000                   0.7             1094.0   \n",
       "  8         0.000000                   0.8             1094.0   \n",
       "  9         0.000000                   0.9             1094.0   \n",
       "  10        0.000000                   1.0             1094.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5719.0                38.0                 195.0   \n",
       "  1                5719.0                38.0                 195.0   \n",
       "  2                5719.0                38.0                 195.0   \n",
       "  3                5719.0                38.0                 195.0   \n",
       "  4                5719.0                38.0                 195.0   \n",
       "  5                5719.0                38.0                 195.0   \n",
       "  6                5719.0                38.0                 195.0   \n",
       "  7                5719.0                38.0                 195.0   \n",
       "  8                5719.0                38.0                 195.0   \n",
       "  9                5719.0                38.0                 195.0   \n",
       "  10               5719.0                38.0                 195.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                56.0                457.0  \n",
       "  1                56.0                457.0  \n",
       "  2                56.0                457.0  \n",
       "  3                56.0                457.0  \n",
       "  4                56.0                457.0  \n",
       "  5                56.0                457.0  \n",
       "  6                56.0                457.0  \n",
       "  7                56.0                457.0  \n",
       "  8                56.0                457.0  \n",
       "  9                56.0                457.0  \n",
       "  10               56.0                457.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9554      0.007127           0.9558   \n",
       "  2                  0.2         0.8830      0.008216           0.8886   \n",
       "  3                  0.3         0.7968      0.016679           0.8040   \n",
       "  4                  0.4         0.6990      0.017421           0.7074   \n",
       "  5                  0.5         0.5852      0.013330           0.5950   \n",
       "  6                  0.6         0.4764      0.014258           0.4896   \n",
       "  7                  0.7         0.3696      0.018690           0.3786   \n",
       "  8                  0.8         0.2412      0.019447           0.2478   \n",
       "  9                  0.9         0.1114      0.015947           0.1160   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.007596            0.950        0.030619           0.0446   \n",
       "  2         0.008961            0.810        0.013693           0.1170   \n",
       "  3         0.016477            0.700        0.063738           0.2032   \n",
       "  4         0.017925            0.585        0.022361           0.3010   \n",
       "  5         0.013248            0.455        0.037081           0.4148   \n",
       "  6         0.014484            0.300        0.017678           0.5236   \n",
       "  7         0.018528            0.245        0.027386           0.6304   \n",
       "  8         0.019018            0.150        0.035355           0.7588   \n",
       "  9         0.016016            0.050        0.017678           0.8886   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007127             0.0442  ...        0.037586           0.8430   \n",
       "  2         0.008216             0.1114  ...        0.016471           0.6604   \n",
       "  3         0.016679             0.1960  ...        0.016257           0.6296   \n",
       "  4         0.017421             0.2926  ...        0.020693           0.6136   \n",
       "  5         0.013330             0.4050  ...        0.020792           0.6598   \n",
       "  6         0.014258             0.5104  ...        0.017627           0.6320   \n",
       "  7         0.018690             0.6214  ...        0.003114           0.7232   \n",
       "  8         0.019447             0.7522  ...        0.012728           0.7984   \n",
       "  9         0.015947             0.8840  ...        0.019008           0.8534   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              515.0   \n",
       "  1         0.095729                   0.1              515.0   \n",
       "  2         0.027364                   0.2              515.0   \n",
       "  3         0.058028                   0.3              515.0   \n",
       "  4         0.038888                   0.4              515.0   \n",
       "  5         0.023721                   0.5              515.0   \n",
       "  6         0.027450                   0.6              515.0   \n",
       "  7         0.110201                   0.7              515.0   \n",
       "  8         0.120278                   0.8              515.0   \n",
       "  9         0.202133                   0.9              515.0   \n",
       "  10        0.000000                   1.0              515.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7542.0                28.0                 234.0   \n",
       "  1                7542.0                28.0                 234.0   \n",
       "  2                7542.0                28.0                 234.0   \n",
       "  3                7542.0                28.0                 234.0   \n",
       "  4                7542.0                28.0                 234.0   \n",
       "  5                7542.0                28.0                 234.0   \n",
       "  6                7542.0                28.0                 234.0   \n",
       "  7                7542.0                28.0                 234.0   \n",
       "  8                7542.0                28.0                 234.0   \n",
       "  9                7542.0                28.0                 234.0   \n",
       "  10               7542.0                28.0                 234.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                40.0                543.0  \n",
       "  1                40.0                543.0  \n",
       "  2                40.0                543.0  \n",
       "  3                40.0                543.0  \n",
       "  4                40.0                543.0  \n",
       "  5                40.0                543.0  \n",
       "  6                40.0                543.0  \n",
       "  7                40.0                543.0  \n",
       "  8                40.0                543.0  \n",
       "  9                40.0                543.0  \n",
       "  10               40.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9244      0.007797           0.9284   \n",
       "  2                  0.2         0.8586      0.009317           0.8656   \n",
       "  3                  0.3         0.7602      0.015271           0.7682   \n",
       "  4                  0.4         0.6502      0.020327           0.6628   \n",
       "  5                  0.5         0.5264      0.015518           0.5394   \n",
       "  6                  0.6         0.3814      0.005550           0.3926   \n",
       "  7                  0.7         0.2650      0.007348           0.2694   \n",
       "  8                  0.8         0.1328      0.010354           0.1318   \n",
       "  9                  0.9         0.0548      0.004817           0.0520   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006465           0.8778        0.031925           0.0756   \n",
       "  2         0.008385           0.7612        0.042464           0.1414   \n",
       "  3         0.018887           0.6556        0.042069           0.2398   \n",
       "  4         0.023510           0.4946        0.082182           0.3498   \n",
       "  5         0.015076           0.3554        0.081910           0.4736   \n",
       "  6         0.006580           0.2388        0.042464           0.6186   \n",
       "  7         0.008234           0.2054        0.042069           0.7350   \n",
       "  8         0.010733           0.1502        0.025044           0.8672   \n",
       "  9         0.005701           0.0888        0.023069           0.9452   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007797             0.0716  ...        0.028314           0.7244   \n",
       "  2         0.009317             0.1344  ...        0.026109           0.6874   \n",
       "  3         0.015271             0.2318  ...        0.036674           0.6668   \n",
       "  4         0.020327             0.3372  ...        0.025521           0.6780   \n",
       "  5         0.015518             0.4606  ...        0.024566           0.7172   \n",
       "  6         0.005550             0.6074  ...        0.024631           0.7134   \n",
       "  7         0.007348             0.7306  ...        0.030171           0.8040   \n",
       "  8         0.010354             0.8682  ...        0.043563           0.9666   \n",
       "  9         0.004817             0.9480  ...        0.047445           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              338.0   \n",
       "  1         0.069482                   0.1              338.0   \n",
       "  2         0.015192                   0.2              338.0   \n",
       "  3         0.023242                   0.3              338.0   \n",
       "  4         0.023484                   0.4              338.0   \n",
       "  5         0.061973                   0.5              338.0   \n",
       "  6         0.058110                   0.6              338.0   \n",
       "  7         0.080842                   0.7              338.0   \n",
       "  8         0.074685                   0.8              338.0   \n",
       "  9         0.000000                   0.9              338.0   \n",
       "  10        0.000000                   1.0              338.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6362.0                18.0                 192.0   \n",
       "  1                6362.0                18.0                 192.0   \n",
       "  2                6362.0                18.0                 192.0   \n",
       "  3                6362.0                18.0                 192.0   \n",
       "  4                6362.0                18.0                 192.0   \n",
       "  5                6362.0                18.0                 192.0   \n",
       "  6                6362.0                18.0                 192.0   \n",
       "  7                6362.0                18.0                 192.0   \n",
       "  8                6362.0                18.0                 192.0   \n",
       "  9                6362.0                18.0                 192.0   \n",
       "  10               6362.0                18.0                 192.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                466.0  \n",
       "  1                36.0                466.0  \n",
       "  2                36.0                466.0  \n",
       "  3                36.0                466.0  \n",
       "  4                36.0                466.0  \n",
       "  5                36.0                466.0  \n",
       "  6                36.0                466.0  \n",
       "  7                36.0                466.0  \n",
       "  8                36.0                466.0  \n",
       "  9                36.0                466.0  \n",
       "  10               36.0                466.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9302      0.012677           0.9394   \n",
       "  2                  0.2         0.8532      0.013255           0.8710   \n",
       "  3                  0.3         0.7374      0.010854           0.7572   \n",
       "  4                  0.4         0.6324      0.009099           0.6532   \n",
       "  5                  0.5         0.5106      0.014656           0.5294   \n",
       "  6                  0.6         0.3876      0.020379           0.4034   \n",
       "  7                  0.7         0.2636      0.023881           0.2678   \n",
       "  8                  0.8         0.1410      0.008000           0.1388   \n",
       "  9                  0.9         0.0490      0.006000           0.0472   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.012198           0.8854        0.033261           0.0698   \n",
       "  2         0.014089           0.7666        0.047784           0.1468   \n",
       "  3         0.010710           0.6406        0.041235           0.2626   \n",
       "  4         0.006017           0.5328        0.045538           0.3676   \n",
       "  5         0.018609           0.4202        0.036942           0.4894   \n",
       "  6         0.027709           0.3122        0.025568           0.6124   \n",
       "  7         0.028350           0.2426        0.029356           0.7364   \n",
       "  8         0.008438           0.1530        0.020506           0.8590   \n",
       "  9         0.008701           0.0584        0.012462           0.9510   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.012677             0.0606  ...        0.016622           0.7282   \n",
       "  2         0.013255             0.1290  ...        0.019731           0.6822   \n",
       "  3         0.010854             0.2428  ...        0.028805           0.6578   \n",
       "  4         0.009099             0.3468  ...        0.024170           0.7218   \n",
       "  5         0.014656             0.4706  ...        0.018147           0.7658   \n",
       "  6         0.020379             0.5966  ...        0.023826           0.8470   \n",
       "  7         0.023881             0.7322  ...        0.035710           0.8978   \n",
       "  8         0.008000             0.8612  ...        0.034717           0.9722   \n",
       "  9         0.006000             0.9528  ...        0.096356           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1032.0   \n",
       "  1         0.059705                   0.1             1032.0   \n",
       "  2         0.039802                   0.2             1032.0   \n",
       "  3         0.022565                   0.3             1032.0   \n",
       "  4         0.019097                   0.4             1032.0   \n",
       "  5         0.025519                   0.5             1032.0   \n",
       "  6         0.024990                   0.6             1032.0   \n",
       "  7         0.059893                   0.7             1032.0   \n",
       "  8         0.038434                   0.8             1032.0   \n",
       "  9         0.000000                   0.9             1032.0   \n",
       "  10        0.000000                   1.0             1032.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5653.0                47.0                 181.0   \n",
       "  1                5653.0                47.0                 181.0   \n",
       "  2                5653.0                47.0                 181.0   \n",
       "  3                5653.0                47.0                 181.0   \n",
       "  4                5653.0                47.0                 181.0   \n",
       "  5                5653.0                47.0                 181.0   \n",
       "  6                5653.0                47.0                 181.0   \n",
       "  7                5653.0                47.0                 181.0   \n",
       "  8                5653.0                47.0                 181.0   \n",
       "  9                5653.0                47.0                 181.0   \n",
       "  10               5653.0                47.0                 181.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                89.0                433.0  \n",
       "  1                89.0                433.0  \n",
       "  2                89.0                433.0  \n",
       "  3                89.0                433.0  \n",
       "  4                89.0                433.0  \n",
       "  5                89.0                433.0  \n",
       "  6                89.0                433.0  \n",
       "  7                89.0                433.0  \n",
       "  8                89.0                433.0  \n",
       "  9                89.0                433.0  \n",
       "  10               89.0                433.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9398      0.005404           0.9392   \n",
       "  2                  0.2         0.8620      0.009823           0.8604   \n",
       "  3                  0.3         0.7710      0.011511           0.7708   \n",
       "  4                  0.4         0.6814      0.020452           0.6826   \n",
       "  5                  0.5         0.5800      0.031757           0.5830   \n",
       "  6                  0.6         0.4694      0.032601           0.4744   \n",
       "  7                  0.7         0.3744      0.026274           0.3800   \n",
       "  8                  0.8         0.2642      0.020645           0.2682   \n",
       "  9                  0.9         0.1510      0.018588           0.1532   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.005070            1.000        0.000000           0.0602   \n",
       "  2         0.010644            0.975        0.055902           0.1380   \n",
       "  3         0.012716            0.775        0.162980           0.2290   \n",
       "  4         0.022390            0.600        0.136931           0.3186   \n",
       "  5         0.032734            0.375        0.000000           0.4200   \n",
       "  6         0.032601            0.125        0.000000           0.5306   \n",
       "  7         0.026618            0.000        0.000000           0.6256   \n",
       "  8         0.021253            0.000        0.000000           0.7358   \n",
       "  9         0.018780            0.000        0.000000           0.8490   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.005404             0.0608  ...        0.211927           0.8000   \n",
       "  2         0.009823             0.1396  ...        0.158804           0.9500   \n",
       "  3         0.011511             0.2292  ...        0.049378           0.7076   \n",
       "  4         0.020452             0.3174  ...        0.040567           0.5962   \n",
       "  5         0.031757             0.4170  ...        0.056857           0.5058   \n",
       "  6         0.032601             0.5256  ...        0.038442           0.2666   \n",
       "  7         0.026274             0.6200  ...        0.013928           0.0000   \n",
       "  8         0.020645             0.7318  ...        0.004147           0.0000   \n",
       "  9         0.018588             0.8468  ...        0.004919           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              295.0   \n",
       "  1         0.447214                   0.1              295.0   \n",
       "  2         0.111803                   0.2              295.0   \n",
       "  3         0.198394                   0.3              295.0   \n",
       "  4         0.079421                   0.4              295.0   \n",
       "  5         0.060977                   0.5              295.0   \n",
       "  6         0.037119                   0.6              295.0   \n",
       "  7         0.000000                   0.7              295.0   \n",
       "  8         0.000000                   0.8              295.0   \n",
       "  9         0.000000                   0.9              295.0   \n",
       "  10        0.000000                   1.0              295.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7742.0                 4.0                 242.0   \n",
       "  1                7742.0                 4.0                 242.0   \n",
       "  2                7742.0                 4.0                 242.0   \n",
       "  3                7742.0                 4.0                 242.0   \n",
       "  4                7742.0                 4.0                 242.0   \n",
       "  5                7742.0                 4.0                 242.0   \n",
       "  6                7742.0                 4.0                 242.0   \n",
       "  7                7742.0                 4.0                 242.0   \n",
       "  8                7742.0                 4.0                 242.0   \n",
       "  9                7742.0                 4.0                 242.0   \n",
       "  10               7742.0                 4.0                 242.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                 8.0                543.0  \n",
       "  1                 8.0                543.0  \n",
       "  2                 8.0                543.0  \n",
       "  3                 8.0                543.0  \n",
       "  4                 8.0                543.0  \n",
       "  5                 8.0                543.0  \n",
       "  6                 8.0                543.0  \n",
       "  7                 8.0                543.0  \n",
       "  8                 8.0                543.0  \n",
       "  9                 8.0                543.0  \n",
       "  10                8.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9542      0.003834           0.9548   \n",
       "  2                  0.2         0.8880      0.011576           0.8978   \n",
       "  3                  0.3         0.8124      0.003435           0.8352   \n",
       "  4                  0.4         0.7110      0.019235           0.7438   \n",
       "  5                  0.5         0.5830      0.011895           0.6206   \n",
       "  6                  0.6         0.4362      0.021719           0.4652   \n",
       "  7                  0.7         0.3086      0.022030           0.3288   \n",
       "  8                  0.8         0.1740      0.018802           0.1826   \n",
       "  9                  0.9         0.0842      0.017824           0.0850   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004604           0.9496        0.012522           0.0458   \n",
       "  2         0.011367           0.8170        0.034293           0.1120   \n",
       "  3         0.011713           0.6510        0.066378           0.1876   \n",
       "  4         0.019980           0.4762        0.036238           0.2890   \n",
       "  5         0.012542           0.3156        0.036508           0.4170   \n",
       "  6         0.023531           0.2308        0.019084           0.5638   \n",
       "  7         0.023091           0.1634        0.023426           0.6914   \n",
       "  8         0.020120           0.1130        0.032833           0.8260   \n",
       "  9         0.018330           0.0762        0.021696           0.9158   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.003834             0.0452  ...        0.007021           0.8974   \n",
       "  2         0.011576             0.1022  ...        0.009864           0.7916   \n",
       "  3         0.003435             0.1648  ...        0.017079           0.7846   \n",
       "  4         0.019235             0.2562  ...        0.013428           0.8370   \n",
       "  5         0.011895             0.3794  ...        0.017254           0.8672   \n",
       "  6         0.021719             0.5348  ...        0.008989           0.8908   \n",
       "  7         0.022030             0.6712  ...        0.010474           0.8758   \n",
       "  8         0.018802             0.8174  ...        0.012418           0.8636   \n",
       "  9         0.017824             0.9150  ...        0.010964           0.9750   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              933.0   \n",
       "  1         0.017358                   0.1              933.0   \n",
       "  2         0.035508                   0.2              933.0   \n",
       "  3         0.041531                   0.3              933.0   \n",
       "  4         0.011358                   0.4              933.0   \n",
       "  5         0.024427                   0.5              933.0   \n",
       "  6         0.008289                   0.6              933.0   \n",
       "  7         0.050603                   0.7              933.0   \n",
       "  8         0.055514                   0.8              933.0   \n",
       "  9         0.055902                   0.9              933.0   \n",
       "  10        0.000000                   1.0              933.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6687.0                29.0                 236.0   \n",
       "  1                6687.0                29.0                 236.0   \n",
       "  2                6687.0                29.0                 236.0   \n",
       "  3                6687.0                29.0                 236.0   \n",
       "  4                6687.0                29.0                 236.0   \n",
       "  5                6687.0                29.0                 236.0   \n",
       "  6                6687.0                29.0                 236.0   \n",
       "  7                6687.0                29.0                 236.0   \n",
       "  8                6687.0                29.0                 236.0   \n",
       "  9                6687.0                29.0                 236.0   \n",
       "  10               6687.0                29.0                 236.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                71.0                506.0  \n",
       "  1                71.0                506.0  \n",
       "  2                71.0                506.0  \n",
       "  3                71.0                506.0  \n",
       "  4                71.0                506.0  \n",
       "  5                71.0                506.0  \n",
       "  6                71.0                506.0  \n",
       "  7                71.0                506.0  \n",
       "  8                71.0                506.0  \n",
       "  9                71.0                506.0  \n",
       "  10               71.0                506.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9468      0.007596           0.9480   \n",
       "  2                  0.2         0.8806      0.002191           0.8830   \n",
       "  3                  0.3         0.7834      0.023554           0.7864   \n",
       "  4                  0.4         0.6570      0.025466           0.6586   \n",
       "  5                  0.5         0.5410      0.016568           0.5386   \n",
       "  6                  0.6         0.4320      0.021213           0.4280   \n",
       "  7                  0.7         0.3124      0.012681           0.3122   \n",
       "  8                  0.8         0.1904      0.019756           0.1908   \n",
       "  9                  0.9         0.0902      0.012418           0.0878   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.005000             0.91        0.082158           0.0532   \n",
       "  2         0.002000             0.81        0.041833           0.1194   \n",
       "  3         0.025540             0.70        0.061237           0.2166   \n",
       "  4         0.027437             0.61        0.041833           0.3430   \n",
       "  5         0.016787             0.60        0.050000           0.4590   \n",
       "  6         0.020676             0.54        0.041833           0.5680   \n",
       "  7         0.015222             0.32        0.075829           0.6876   \n",
       "  8         0.020729             0.18        0.044721           0.8096   \n",
       "  9         0.011819             0.15        0.050000           0.9098   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007596             0.0520  ...        0.053901           0.8172   \n",
       "  2         0.002191             0.1170  ...        0.017108           0.7178   \n",
       "  3         0.023554             0.2136  ...        0.020340           0.6454   \n",
       "  4         0.025466             0.3414  ...        0.017155           0.6058   \n",
       "  5         0.016568             0.4614  ...        0.020671           0.6546   \n",
       "  6         0.021213             0.5720  ...        0.039879           0.7126   \n",
       "  7         0.012681             0.6878  ...        0.032070           0.6830   \n",
       "  8         0.019756             0.8092  ...        0.010114           0.7134   \n",
       "  9         0.012418             0.9122  ...        0.016971           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              419.0   \n",
       "  1         0.147196                   0.1              419.0   \n",
       "  2         0.047840                   0.2              419.0   \n",
       "  3         0.038116                   0.3              419.0   \n",
       "  4         0.044082                   0.4              419.0   \n",
       "  5         0.061683                   0.5              419.0   \n",
       "  6         0.056016                   0.6              419.0   \n",
       "  7         0.080281                   0.7              419.0   \n",
       "  8         0.132468                   0.8              419.0   \n",
       "  9         0.000000                   0.9              419.0   \n",
       "  10        0.000000                   1.0              419.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7763.0                10.0                 270.0   \n",
       "  1                7763.0                10.0                 270.0   \n",
       "  2                7763.0                10.0                 270.0   \n",
       "  3                7763.0                10.0                 270.0   \n",
       "  4                7763.0                10.0                 270.0   \n",
       "  5                7763.0                10.0                 270.0   \n",
       "  6                7763.0                10.0                 270.0   \n",
       "  7                7763.0                10.0                 270.0   \n",
       "  8                7763.0                10.0                 270.0   \n",
       "  9                7763.0                10.0                 270.0   \n",
       "  10               7763.0                10.0                 270.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                20.0                548.0  \n",
       "  1                20.0                548.0  \n",
       "  2                20.0                548.0  \n",
       "  3                20.0                548.0  \n",
       "  4                20.0                548.0  \n",
       "  5                20.0                548.0  \n",
       "  6                20.0                548.0  \n",
       "  7                20.0                548.0  \n",
       "  8                20.0                548.0  \n",
       "  9                20.0                548.0  \n",
       "  10               20.0                548.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9352      0.008983           0.9330   \n",
       "  2                  0.2         0.8518      0.011883           0.8502   \n",
       "  3                  0.3         0.7446      0.019807           0.7464   \n",
       "  4                  0.4         0.6310      0.011136           0.6318   \n",
       "  5                  0.5         0.5150      0.003742           0.5130   \n",
       "  6                  0.6         0.4106      0.021326           0.4072   \n",
       "  7                  0.7         0.3022      0.029474           0.2986   \n",
       "  8                  0.8         0.1950      0.020976           0.1918   \n",
       "  9                  0.9         0.0922      0.017513           0.0890   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009381           0.9744        0.014311           0.0648   \n",
       "  2         0.011862           0.8774        0.041723           0.1482   \n",
       "  3         0.021536           0.7096        0.039602           0.2554   \n",
       "  4         0.011584           0.6194        0.070066           0.3690   \n",
       "  5         0.005568           0.5484        0.051072           0.4850   \n",
       "  6         0.023983           0.4646        0.074039           0.5894   \n",
       "  7         0.029980           0.3678        0.028622           0.6978   \n",
       "  8         0.021891           0.2450        0.048959           0.8050   \n",
       "  9         0.017649           0.1550        0.042184           0.9078   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.008983             0.0670  ...        0.079967           0.9212   \n",
       "  2         0.011883             0.1498  ...        0.048289           0.8036   \n",
       "  3         0.019807             0.2536  ...        0.035412           0.6828   \n",
       "  4         0.011136             0.3682  ...        0.052142           0.6872   \n",
       "  5         0.003742             0.4870  ...        0.044102           0.7518   \n",
       "  6         0.021326             0.5928  ...        0.037713           0.8616   \n",
       "  7         0.029474             0.7014  ...        0.034010           0.8554   \n",
       "  8         0.020976             0.8082  ...        0.054386           0.8606   \n",
       "  9         0.017513             0.9110  ...        0.016962           0.9600   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              204.0   \n",
       "  1         0.045174                   0.1              204.0   \n",
       "  2         0.047690                   0.2              204.0   \n",
       "  3         0.042967                   0.3              204.0   \n",
       "  4         0.044640                   0.4              204.0   \n",
       "  5         0.063900                   0.5              204.0   \n",
       "  6         0.095513                   0.6              204.0   \n",
       "  7         0.094865                   0.7              204.0   \n",
       "  8         0.139737                   0.8              204.0   \n",
       "  9         0.089443                   0.9              204.0   \n",
       "  10        0.000000                   1.0              204.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7414.0                15.0                 245.0   \n",
       "  1                7414.0                15.0                 245.0   \n",
       "  2                7414.0                15.0                 245.0   \n",
       "  3                7414.0                15.0                 245.0   \n",
       "  4                7414.0                15.0                 245.0   \n",
       "  5                7414.0                15.0                 245.0   \n",
       "  6                7414.0                15.0                 245.0   \n",
       "  7                7414.0                15.0                 245.0   \n",
       "  8                7414.0                15.0                 245.0   \n",
       "  9                7414.0                15.0                 245.0   \n",
       "  10               7414.0                15.0                 245.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                31.0                543.0  \n",
       "  1                31.0                543.0  \n",
       "  2                31.0                543.0  \n",
       "  3                31.0                543.0  \n",
       "  4                31.0                543.0  \n",
       "  5                31.0                543.0  \n",
       "  6                31.0                543.0  \n",
       "  7                31.0                543.0  \n",
       "  8                31.0                543.0  \n",
       "  9                31.0                543.0  \n",
       "  10               31.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns]],\n",
       " 'pred_score_calupdate2': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9016      0.019527           0.9026   \n",
       "  2                  0.2         0.8100      0.043801           0.8116   \n",
       "  3                  0.3         0.7096      0.040507           0.7128   \n",
       "  4                  0.4         0.6076      0.019769           0.6064   \n",
       "  5                  0.5         0.5184      0.007197           0.5176   \n",
       "  6                  0.6         0.3868      0.008556           0.3868   \n",
       "  7                  0.7         0.2724      0.027510           0.2708   \n",
       "  8                  0.8         0.1794      0.016637           0.1804   \n",
       "  9                  0.9         0.0772      0.015189           0.0770   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.026698           0.8888        0.103698           0.0984   \n",
       "  2         0.048247           0.7886        0.126559           0.1900   \n",
       "  3         0.044364           0.6666        0.078312           0.2904   \n",
       "  4         0.027116           0.6222        0.120483           0.3924   \n",
       "  5         0.013315           0.5334        0.115353           0.4816   \n",
       "  6         0.014940           0.3890        0.141792           0.6132   \n",
       "  7         0.022786           0.3000        0.127814           0.7276   \n",
       "  8         0.016456           0.1668        0.039245           0.8206   \n",
       "  9         0.017903           0.0778        0.049585           0.9228   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.019527             0.0974  ...        0.185816           0.7752   \n",
       "  2         0.043801             0.1884  ...        0.068152           0.7270   \n",
       "  3         0.040507             0.2872  ...        0.050742           0.6334   \n",
       "  4         0.019769             0.3936  ...        0.060681           0.6550   \n",
       "  5         0.007197             0.4824  ...        0.080722           0.6646   \n",
       "  6         0.008556             0.6132  ...        0.050512           0.6786   \n",
       "  7         0.027510             0.7292  ...        0.033471           0.7072   \n",
       "  8         0.016637             0.8196  ...        0.032777           0.6400   \n",
       "  9         0.015189             0.9230  ...        0.064531           0.4134   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              322.0   \n",
       "  1         0.205878                   0.1              322.0   \n",
       "  2         0.144632                   0.2              322.0   \n",
       "  3         0.088780                   0.3              322.0   \n",
       "  4         0.095530                   0.4              322.0   \n",
       "  5         0.103341                   0.5              322.0   \n",
       "  6         0.200444                   0.6              322.0   \n",
       "  7         0.226023                   0.7              322.0   \n",
       "  8         0.178185                   0.8              322.0   \n",
       "  9         0.250196                   0.9              322.0   \n",
       "  10        0.000000                   1.0              322.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8179.0                25.0                 240.0   \n",
       "  1                8179.0                25.0                 240.0   \n",
       "  2                8179.0                25.0                 240.0   \n",
       "  3                8179.0                25.0                 240.0   \n",
       "  4                8179.0                25.0                 240.0   \n",
       "  5                8179.0                25.0                 240.0   \n",
       "  6                8179.0                25.0                 240.0   \n",
       "  7                8179.0                25.0                 240.0   \n",
       "  8                8179.0                25.0                 240.0   \n",
       "  9                8179.0                25.0                 240.0   \n",
       "  10               8179.0                25.0                 240.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                554.0  \n",
       "  1                36.0                554.0  \n",
       "  2                36.0                554.0  \n",
       "  3                36.0                554.0  \n",
       "  4                36.0                554.0  \n",
       "  5                36.0                554.0  \n",
       "  6                36.0                554.0  \n",
       "  7                36.0                554.0  \n",
       "  8                36.0                554.0  \n",
       "  9                36.0                554.0  \n",
       "  10               36.0                554.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9100      0.012649           0.9056   \n",
       "  2                  0.2         0.8128      0.024894           0.8138   \n",
       "  3                  0.3         0.7144      0.037159           0.7120   \n",
       "  4                  0.4         0.6010      0.040515           0.6004   \n",
       "  5                  0.5         0.4904      0.056867           0.4858   \n",
       "  6                  0.6         0.3960      0.057541           0.3880   \n",
       "  7                  0.7         0.2840      0.055754           0.2742   \n",
       "  8                  0.8         0.1704      0.046068           0.1656   \n",
       "  9                  0.9         0.0654      0.018338           0.0660   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.014519           0.9514        0.052629           0.0900   \n",
       "  2         0.015189           0.8050        0.126590           0.1872   \n",
       "  3         0.027758           0.7320        0.175271           0.2856   \n",
       "  4         0.032098           0.6034        0.149525           0.3990   \n",
       "  5         0.054053           0.5310        0.116211           0.5096   \n",
       "  6         0.056343           0.4660        0.142056           0.6040   \n",
       "  7         0.053425           0.3696        0.131380           0.7160   \n",
       "  8         0.041156           0.2174        0.107209           0.8296   \n",
       "  9         0.016658           0.0564        0.066819           0.9346   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.012649             0.0944  ...        0.079783           0.9074   \n",
       "  2         0.024894             0.1862  ...        0.047205           0.7482   \n",
       "  3         0.037159             0.2880  ...        0.047510           0.7294   \n",
       "  4         0.040515             0.3996  ...        0.054023           0.6860   \n",
       "  5         0.056867             0.5142  ...        0.040208           0.7442   \n",
       "  6         0.057541             0.6120  ...        0.022698           0.7906   \n",
       "  7         0.055754             0.7258  ...        0.027725           0.8382   \n",
       "  8         0.046068             0.8344  ...        0.013465           0.8550   \n",
       "  9         0.018338             0.9340  ...        0.030964           0.4600   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              901.0   \n",
       "  1         0.100667                   0.1              901.0   \n",
       "  2         0.146158                   0.2              901.0   \n",
       "  3         0.156768                   0.3              901.0   \n",
       "  4         0.114359                   0.4              901.0   \n",
       "  5         0.075582                   0.5              901.0   \n",
       "  6         0.108978                   0.6              901.0   \n",
       "  7         0.099993                   0.7              901.0   \n",
       "  8         0.121735                   0.8              901.0   \n",
       "  9         0.456070                   0.9              901.0   \n",
       "  10        0.000000                   1.0              901.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6290.0                27.0                 231.0   \n",
       "  1                6290.0                27.0                 231.0   \n",
       "  2                6290.0                27.0                 231.0   \n",
       "  3                6290.0                27.0                 231.0   \n",
       "  4                6290.0                27.0                 231.0   \n",
       "  5                6290.0                27.0                 231.0   \n",
       "  6                6290.0                27.0                 231.0   \n",
       "  7                6290.0                27.0                 231.0   \n",
       "  8                6290.0                27.0                 231.0   \n",
       "  9                6290.0                27.0                 231.0   \n",
       "  10               6290.0                27.0                 231.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                49.0                441.0  \n",
       "  1                49.0                441.0  \n",
       "  2                49.0                441.0  \n",
       "  3                49.0                441.0  \n",
       "  4                49.0                441.0  \n",
       "  5                49.0                441.0  \n",
       "  6                49.0                441.0  \n",
       "  7                49.0                441.0  \n",
       "  8                49.0                441.0  \n",
       "  9                49.0                441.0  \n",
       "  10               49.0                441.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9314      0.019034           0.9314   \n",
       "  2                  0.2         0.8406      0.040777           0.8420   \n",
       "  3                  0.3         0.7280      0.051701           0.7292   \n",
       "  4                  0.4         0.6186      0.038578           0.6212   \n",
       "  5                  0.5         0.5110      0.027148           0.5172   \n",
       "  6                  0.6         0.3902      0.010986           0.3940   \n",
       "  7                  0.7         0.2662      0.020278           0.2680   \n",
       "  8                  0.8         0.1616      0.014588           0.1624   \n",
       "  9                  0.9         0.0600      0.025933           0.0606   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.017700           0.9266        0.101182           0.0686   \n",
       "  2         0.038249           0.7800        0.178885           0.1594   \n",
       "  3         0.048659           0.6600        0.240832           0.2720   \n",
       "  4         0.036616           0.4800        0.164317           0.3814   \n",
       "  5         0.026214           0.1934        0.245393           0.4890   \n",
       "  6         0.010607           0.1934        0.245393           0.6098   \n",
       "  7         0.017059           0.1934        0.245393           0.7338   \n",
       "  8         0.014206           0.1134        0.104393           0.8384   \n",
       "  9         0.024835           0.0400        0.089443           0.9400   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.019034             0.0686  ...        0.205860           0.9000   \n",
       "  2         0.040777             0.1580  ...        0.100026           0.7100   \n",
       "  3         0.051701             0.2708  ...        0.073689           0.6300   \n",
       "  4         0.038578             0.3788  ...        0.042499           0.6866   \n",
       "  5         0.027148             0.4828  ...        0.029774           0.3500   \n",
       "  6         0.010986             0.6060  ...        0.020194           0.3500   \n",
       "  7         0.020278             0.7320  ...        0.025505           0.3500   \n",
       "  8         0.014588             0.8376  ...        0.021817           0.4000   \n",
       "  9         0.025933             0.9394  ...        0.051437           0.2000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              373.0   \n",
       "  1         0.136931                   0.1              373.0   \n",
       "  2         0.213307                   0.2              373.0   \n",
       "  3         0.286356                   0.3              373.0   \n",
       "  4         0.244331                   0.4              373.0   \n",
       "  5         0.335410                   0.5              373.0   \n",
       "  6         0.335410                   0.6              373.0   \n",
       "  7         0.335410                   0.7              373.0   \n",
       "  8         0.418330                   0.8              373.0   \n",
       "  9         0.447214                   0.9              373.0   \n",
       "  10        0.000000                   1.0              373.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8370.0                 3.0                 282.0   \n",
       "  1                8370.0                 3.0                 282.0   \n",
       "  2                8370.0                 3.0                 282.0   \n",
       "  3                8370.0                 3.0                 282.0   \n",
       "  4                8370.0                 3.0                 282.0   \n",
       "  5                8370.0                 3.0                 282.0   \n",
       "  6                8370.0                 3.0                 282.0   \n",
       "  7                8370.0                 3.0                 282.0   \n",
       "  8                8370.0                 3.0                 282.0   \n",
       "  9                8370.0                 3.0                 282.0   \n",
       "  10               8370.0                 3.0                 282.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                11.0                549.0  \n",
       "  1                11.0                549.0  \n",
       "  2                11.0                549.0  \n",
       "  3                11.0                549.0  \n",
       "  4                11.0                549.0  \n",
       "  5                11.0                549.0  \n",
       "  6                11.0                549.0  \n",
       "  7                11.0                549.0  \n",
       "  8                11.0                549.0  \n",
       "  9                11.0                549.0  \n",
       "  10               11.0                549.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9044      0.031342           0.9010   \n",
       "  2                  0.2         0.8028      0.034528           0.7984   \n",
       "  3                  0.3         0.7004      0.043189           0.6966   \n",
       "  4                  0.4         0.6006      0.054340           0.6000   \n",
       "  5                  0.5         0.5024      0.051627           0.5010   \n",
       "  6                  0.6         0.3842      0.052661           0.3812   \n",
       "  7                  0.7         0.2596      0.051627           0.2552   \n",
       "  8                  0.8         0.1766      0.043827           0.1742   \n",
       "  9                  0.9         0.0870      0.030919           0.0876   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.033008             1.00        0.000000           0.0956   \n",
       "  2         0.033931             0.92        0.130384           0.1972   \n",
       "  3         0.037806             0.80        0.244949           0.2996   \n",
       "  4         0.047212             0.62        0.294958           0.3994   \n",
       "  5         0.045227             0.54        0.336155           0.4976   \n",
       "  6         0.045472             0.46        0.336155           0.6158   \n",
       "  7         0.046046             0.38        0.294958           0.7404   \n",
       "  8         0.036300             0.24        0.270185           0.8234   \n",
       "  9         0.031445             0.08        0.044721           0.9130   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.031342             0.0990  ...        0.130474           1.0000   \n",
       "  2         0.034528             0.2016  ...        0.116625           0.9084   \n",
       "  3         0.043189             0.3034  ...        0.069251           0.8342   \n",
       "  4         0.054340             0.4000  ...        0.071671           0.7534   \n",
       "  5         0.051627             0.4990  ...        0.105112           0.6984   \n",
       "  6         0.052661             0.6188  ...        0.106422           0.6914   \n",
       "  7         0.051627             0.7448  ...        0.091647           0.7666   \n",
       "  8         0.043827             0.8258  ...        0.099527           0.7000   \n",
       "  9         0.030919             0.9124  ...        0.036817           0.8000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              386.0   \n",
       "  1         0.000000                   0.1              386.0   \n",
       "  2         0.145397                   0.2              386.0   \n",
       "  3         0.177899                   0.3              386.0   \n",
       "  4         0.225082                   0.4              386.0   \n",
       "  5         0.411177                   0.5              386.0   \n",
       "  6         0.419607                   0.6              386.0   \n",
       "  7         0.434601                   0.7              386.0   \n",
       "  8         0.447214                   0.8              386.0   \n",
       "  9         0.447214                   0.9              386.0   \n",
       "  10        0.000000                   1.0              386.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7233.0                10.0                 250.0   \n",
       "  1                7233.0                10.0                 250.0   \n",
       "  2                7233.0                10.0                 250.0   \n",
       "  3                7233.0                10.0                 250.0   \n",
       "  4                7233.0                10.0                 250.0   \n",
       "  5                7233.0                10.0                 250.0   \n",
       "  6                7233.0                10.0                 250.0   \n",
       "  7                7233.0                10.0                 250.0   \n",
       "  8                7233.0                10.0                 250.0   \n",
       "  9                7233.0                10.0                 250.0   \n",
       "  10               7233.0                10.0                 250.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                19.0                558.0  \n",
       "  1                19.0                558.0  \n",
       "  2                19.0                558.0  \n",
       "  3                19.0                558.0  \n",
       "  4                19.0                558.0  \n",
       "  5                19.0                558.0  \n",
       "  6                19.0                558.0  \n",
       "  7                19.0                558.0  \n",
       "  8                19.0                558.0  \n",
       "  9                19.0                558.0  \n",
       "  10               19.0                558.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9192      0.019817           0.9142   \n",
       "  2                  0.2         0.8224      0.035367           0.8192   \n",
       "  3                  0.3         0.7112      0.041264           0.7076   \n",
       "  4                  0.4         0.6014      0.039778           0.5966   \n",
       "  5                  0.5         0.5130      0.048939           0.5126   \n",
       "  6                  0.6         0.4186      0.033887           0.4174   \n",
       "  7                  0.7         0.3152      0.034186           0.3118   \n",
       "  8                  0.8         0.2124      0.027264           0.2140   \n",
       "  9                  0.9         0.0902      0.020067           0.0918   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.023274           0.9572        0.029643           0.0808   \n",
       "  2         0.041318           0.8500        0.039026           0.1776   \n",
       "  3         0.047321           0.7428        0.030120           0.2888   \n",
       "  4         0.042495           0.6428        0.071625           0.3986   \n",
       "  5         0.057877           0.5144        0.081901           0.4870   \n",
       "  6         0.045621           0.4286        0.104100           0.5814   \n",
       "  7         0.042839           0.3428        0.140010           0.6848   \n",
       "  8         0.025000           0.2002        0.117182           0.7876   \n",
       "  9         0.023994           0.0784        0.029762           0.9098   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.019817             0.0858  ...        0.030108           0.9414   \n",
       "  2         0.035367             0.1808  ...        0.033870           0.8544   \n",
       "  3         0.041264             0.2924  ...        0.023660           0.9468   \n",
       "  4         0.039778             0.4034  ...        0.028974           0.9670   \n",
       "  5         0.048939             0.4874  ...        0.026920           0.9728   \n",
       "  6         0.033887             0.5826  ...        0.022810           1.0000   \n",
       "  7         0.034186             0.6882  ...        0.021123           1.0000   \n",
       "  8         0.027264             0.7860  ...        0.030030           1.0000   \n",
       "  9         0.020067             0.9082  ...        0.054358           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1094.0   \n",
       "  1         0.038843                   0.1             1094.0   \n",
       "  2         0.049722                   0.2             1094.0   \n",
       "  3         0.035053                   0.3             1094.0   \n",
       "  4         0.030299                   0.4             1094.0   \n",
       "  5         0.037785                   0.5             1094.0   \n",
       "  6         0.000000                   0.6             1094.0   \n",
       "  7         0.000000                   0.7             1094.0   \n",
       "  8         0.000000                   0.8             1094.0   \n",
       "  9         0.000000                   0.9             1094.0   \n",
       "  10        0.000000                   1.0             1094.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5719.0                38.0                 195.0   \n",
       "  1                5719.0                38.0                 195.0   \n",
       "  2                5719.0                38.0                 195.0   \n",
       "  3                5719.0                38.0                 195.0   \n",
       "  4                5719.0                38.0                 195.0   \n",
       "  5                5719.0                38.0                 195.0   \n",
       "  6                5719.0                38.0                 195.0   \n",
       "  7                5719.0                38.0                 195.0   \n",
       "  8                5719.0                38.0                 195.0   \n",
       "  9                5719.0                38.0                 195.0   \n",
       "  10               5719.0                38.0                 195.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                56.0                457.0  \n",
       "  1                56.0                457.0  \n",
       "  2                56.0                457.0  \n",
       "  3                56.0                457.0  \n",
       "  4                56.0                457.0  \n",
       "  5                56.0                457.0  \n",
       "  6                56.0                457.0  \n",
       "  7                56.0                457.0  \n",
       "  8                56.0                457.0  \n",
       "  9                56.0                457.0  \n",
       "  10               56.0                457.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9100      0.022305           0.9094   \n",
       "  2                  0.2         0.8022      0.038532           0.8044   \n",
       "  3                  0.3         0.7052      0.026253           0.7068   \n",
       "  4                  0.4         0.5712      0.034716           0.5706   \n",
       "  5                  0.5         0.4680      0.038710           0.4700   \n",
       "  6                  0.6         0.3672      0.040027           0.3710   \n",
       "  7                  0.7         0.2574      0.041380           0.2582   \n",
       "  8                  0.8         0.1624      0.024966           0.1638   \n",
       "  9                  0.9         0.0768      0.026593           0.0766   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.018119             0.92        0.103682           0.0900   \n",
       "  2         0.034093             0.77        0.103682           0.1978   \n",
       "  3         0.017627             0.69        0.155724           0.2948   \n",
       "  4         0.029467             0.58        0.130384           0.4288   \n",
       "  5         0.034037             0.44        0.102470           0.5320   \n",
       "  6         0.036139             0.31        0.114018           0.6328   \n",
       "  7         0.040357             0.25        0.061237           0.7426   \n",
       "  8         0.029853             0.14        0.065192           0.8376   \n",
       "  9         0.032114             0.08        0.057009           0.9232   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.022305             0.0906  ...        0.058393           0.8048   \n",
       "  2         0.038532             0.1956  ...        0.022884           0.6690   \n",
       "  3         0.026253             0.2932  ...        0.015405           0.6668   \n",
       "  4         0.034716             0.4294  ...        0.013928           0.6954   \n",
       "  5         0.038710             0.5300  ...        0.022147           0.6922   \n",
       "  6         0.040027             0.6290  ...        0.032798           0.7284   \n",
       "  7         0.041380             0.7418  ...        0.016754           0.8600   \n",
       "  8         0.024966             0.8362  ...        0.056071           0.8800   \n",
       "  9         0.026593             0.9234  ...        0.226374           0.7334   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              515.0   \n",
       "  1         0.218416                   0.1              515.0   \n",
       "  2         0.097142                   0.2              515.0   \n",
       "  3         0.145574                   0.3              515.0   \n",
       "  4         0.086138                   0.4              515.0   \n",
       "  5         0.086667                   0.5              515.0   \n",
       "  6         0.176245                   0.6              515.0   \n",
       "  7         0.142107                   0.7              515.0   \n",
       "  8         0.178885                   0.8              515.0   \n",
       "  9         0.434601                   0.9              515.0   \n",
       "  10        0.000000                   1.0              515.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7542.0                28.0                 234.0   \n",
       "  1                7542.0                28.0                 234.0   \n",
       "  2                7542.0                28.0                 234.0   \n",
       "  3                7542.0                28.0                 234.0   \n",
       "  4                7542.0                28.0                 234.0   \n",
       "  5                7542.0                28.0                 234.0   \n",
       "  6                7542.0                28.0                 234.0   \n",
       "  7                7542.0                28.0                 234.0   \n",
       "  8                7542.0                28.0                 234.0   \n",
       "  9                7542.0                28.0                 234.0   \n",
       "  10               7542.0                28.0                 234.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                40.0                543.0  \n",
       "  1                40.0                543.0  \n",
       "  2                40.0                543.0  \n",
       "  3                40.0                543.0  \n",
       "  4                40.0                543.0  \n",
       "  5                40.0                543.0  \n",
       "  6                40.0                543.0  \n",
       "  7                40.0                543.0  \n",
       "  8                40.0                543.0  \n",
       "  9                40.0                543.0  \n",
       "  10               40.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9050      0.031953           0.9032   \n",
       "  2                  0.2         0.7962      0.029853           0.7984   \n",
       "  3                  0.3         0.6770      0.024000           0.6772   \n",
       "  4                  0.4         0.5756      0.025861           0.5732   \n",
       "  5                  0.5         0.4812      0.020278           0.4790   \n",
       "  6                  0.6         0.3628      0.036169           0.3632   \n",
       "  7                  0.7         0.2718      0.039028           0.2736   \n",
       "  8                  0.8         0.1630      0.024819           0.1634   \n",
       "  9                  0.9         0.0704      0.015126           0.0704   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.032306           0.9332        0.072517           0.0950   \n",
       "  2         0.030762           0.7668        0.099198           0.2038   \n",
       "  3         0.024944           0.6778        0.106601           0.3230   \n",
       "  4         0.022939           0.6002        0.072517           0.4244   \n",
       "  5         0.019144           0.5112        0.061345           0.5188   \n",
       "  6         0.035337           0.3554        0.084269           0.6372   \n",
       "  7         0.038869           0.2442        0.049641           0.7282   \n",
       "  8         0.022678           0.1668        0.067769           0.8370   \n",
       "  9         0.012661           0.0668        0.072517           0.9296   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.031953             0.0968  ...        0.116913           0.8806   \n",
       "  2         0.029853             0.2016  ...        0.056892           0.7264   \n",
       "  3         0.024000             0.3228  ...        0.043658           0.6992   \n",
       "  4         0.025861             0.4268  ...        0.031571           0.7316   \n",
       "  5         0.020278             0.5210  ...        0.020192           0.7906   \n",
       "  6         0.036169             0.6368  ...        0.030695           0.7532   \n",
       "  7         0.039028             0.7264  ...        0.045593           0.8114   \n",
       "  8         0.024819             0.8366  ...        0.045801           0.9500   \n",
       "  9         0.015126             0.9296  ...        0.048716           0.6000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              338.0   \n",
       "  1         0.118456                   0.1              338.0   \n",
       "  2         0.098713                   0.2              338.0   \n",
       "  3         0.091595                   0.3              338.0   \n",
       "  4         0.099523                   0.4              338.0   \n",
       "  5         0.058059                   0.5              338.0   \n",
       "  6         0.114977                   0.6              338.0   \n",
       "  7         0.025491                   0.7              338.0   \n",
       "  8         0.111803                   0.8              338.0   \n",
       "  9         0.547723                   0.9              338.0   \n",
       "  10        0.000000                   1.0              338.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6362.0                18.0                 192.0   \n",
       "  1                6362.0                18.0                 192.0   \n",
       "  2                6362.0                18.0                 192.0   \n",
       "  3                6362.0                18.0                 192.0   \n",
       "  4                6362.0                18.0                 192.0   \n",
       "  5                6362.0                18.0                 192.0   \n",
       "  6                6362.0                18.0                 192.0   \n",
       "  7                6362.0                18.0                 192.0   \n",
       "  8                6362.0                18.0                 192.0   \n",
       "  9                6362.0                18.0                 192.0   \n",
       "  10               6362.0                18.0                 192.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                466.0  \n",
       "  1                36.0                466.0  \n",
       "  2                36.0                466.0  \n",
       "  3                36.0                466.0  \n",
       "  4                36.0                466.0  \n",
       "  5                36.0                466.0  \n",
       "  6                36.0                466.0  \n",
       "  7                36.0                466.0  \n",
       "  8                36.0                466.0  \n",
       "  9                36.0                466.0  \n",
       "  10               36.0                466.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9096      0.015010           0.9074   \n",
       "  2                  0.2         0.8236      0.026444           0.8244   \n",
       "  3                  0.3         0.7174      0.043212           0.7208   \n",
       "  4                  0.4         0.6068      0.043769           0.6130   \n",
       "  5                  0.5         0.4912      0.030236           0.4982   \n",
       "  6                  0.6         0.3984      0.026283           0.4056   \n",
       "  7                  0.7         0.2874      0.036555           0.2932   \n",
       "  8                  0.8         0.1824      0.025958           0.1800   \n",
       "  9                  0.9         0.0706      0.006066           0.0666   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007436           0.9200        0.079382           0.0904   \n",
       "  2         0.029645           0.8208        0.064426           0.1764   \n",
       "  3         0.055065           0.6998        0.058598           0.2826   \n",
       "  4         0.044604           0.5784        0.081023           0.3932   \n",
       "  5         0.031909           0.4570        0.076573           0.5088   \n",
       "  6         0.030353           0.3626        0.082264           0.6016   \n",
       "  7         0.038803           0.2596        0.051330           0.7126   \n",
       "  8         0.026000           0.1926        0.062951           0.8176   \n",
       "  9         0.008649           0.0898        0.041985           0.9294   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.015010             0.0926  ...        0.019829           0.8386   \n",
       "  2         0.026444             0.1756  ...        0.038402           0.7642   \n",
       "  3         0.043212             0.2792  ...        0.052305           0.7116   \n",
       "  4         0.043769             0.3870  ...        0.039894           0.7614   \n",
       "  5         0.030236             0.5018  ...        0.029828           0.8150   \n",
       "  6         0.026283             0.5944  ...        0.009460           0.8768   \n",
       "  7         0.036555             0.7068  ...        0.033630           0.8914   \n",
       "  8         0.025958             0.8200  ...        0.044584           0.9578   \n",
       "  9         0.006066             0.9334  ...        0.099245           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1032.0   \n",
       "  1         0.112050                   0.1             1032.0   \n",
       "  2         0.073792                   0.2             1032.0   \n",
       "  3         0.034435                   0.3             1032.0   \n",
       "  4         0.079980                   0.4             1032.0   \n",
       "  5         0.059599                   0.5             1032.0   \n",
       "  6         0.030842                   0.6             1032.0   \n",
       "  7         0.084497                   0.7             1032.0   \n",
       "  8         0.057915                   0.8             1032.0   \n",
       "  9         0.000000                   0.9             1032.0   \n",
       "  10        0.000000                   1.0             1032.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5653.0                47.0                 181.0   \n",
       "  1                5653.0                47.0                 181.0   \n",
       "  2                5653.0                47.0                 181.0   \n",
       "  3                5653.0                47.0                 181.0   \n",
       "  4                5653.0                47.0                 181.0   \n",
       "  5                5653.0                47.0                 181.0   \n",
       "  6                5653.0                47.0                 181.0   \n",
       "  7                5653.0                47.0                 181.0   \n",
       "  8                5653.0                47.0                 181.0   \n",
       "  9                5653.0                47.0                 181.0   \n",
       "  10               5653.0                47.0                 181.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                89.0                433.0  \n",
       "  1                89.0                433.0  \n",
       "  2                89.0                433.0  \n",
       "  3                89.0                433.0  \n",
       "  4                89.0                433.0  \n",
       "  5                89.0                433.0  \n",
       "  6                89.0                433.0  \n",
       "  7                89.0                433.0  \n",
       "  8                89.0                433.0  \n",
       "  9                89.0                433.0  \n",
       "  10               89.0                433.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9122      0.029752           0.9118   \n",
       "  2                  0.2         0.8050      0.047149           0.8058   \n",
       "  3                  0.3         0.7060      0.045371           0.7060   \n",
       "  4                  0.4         0.5912      0.039556           0.5912   \n",
       "  5                  0.5         0.4694      0.044545           0.4682   \n",
       "  6                  0.6         0.3680      0.051444           0.3682   \n",
       "  7                  0.7         0.2680      0.055430           0.2700   \n",
       "  8                  0.8         0.1770      0.044559           0.1788   \n",
       "  9                  0.9         0.0962      0.031180           0.0980   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.029995             0.95        0.111803           0.0878   \n",
       "  2         0.048608             0.75        0.353553           0.1950   \n",
       "  3         0.045711             0.70        0.325960           0.2940   \n",
       "  4         0.043246             0.60        0.285044           0.4088   \n",
       "  5         0.047199             0.55        0.209165           0.5306   \n",
       "  6         0.055454             0.35        0.285044           0.6320   \n",
       "  7         0.059131             0.15        0.223607           0.7320   \n",
       "  8         0.045833             0.05        0.111803           0.8230   \n",
       "  9         0.031488             0.00        0.000000           0.9038   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.029752             0.0882  ...        0.226619           0.5000   \n",
       "  2         0.047149             0.1942  ...        0.140677           0.7166   \n",
       "  3         0.045371             0.2940  ...        0.092519           0.7000   \n",
       "  4         0.039556             0.4088  ...        0.099716           0.6000   \n",
       "  5         0.044545             0.5318  ...        0.137482           0.6000   \n",
       "  6         0.051444             0.6318  ...        0.157516           0.5500   \n",
       "  7         0.055430             0.7300  ...        0.151178           0.4000   \n",
       "  8         0.044559             0.8212  ...        0.121624           0.2000   \n",
       "  9         0.031180             0.9020  ...        0.077090           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              295.0   \n",
       "  1         0.500000                   0.1              295.0   \n",
       "  2         0.389169                   0.2              295.0   \n",
       "  3         0.325960                   0.3              295.0   \n",
       "  4         0.285044                   0.4              295.0   \n",
       "  5         0.285044                   0.5              295.0   \n",
       "  6         0.447214                   0.6              295.0   \n",
       "  7         0.547723                   0.7              295.0   \n",
       "  8         0.447214                   0.8              295.0   \n",
       "  9         0.000000                   0.9              295.0   \n",
       "  10        0.000000                   1.0              295.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7742.0                 4.0                 242.0   \n",
       "  1                7742.0                 4.0                 242.0   \n",
       "  2                7742.0                 4.0                 242.0   \n",
       "  3                7742.0                 4.0                 242.0   \n",
       "  4                7742.0                 4.0                 242.0   \n",
       "  5                7742.0                 4.0                 242.0   \n",
       "  6                7742.0                 4.0                 242.0   \n",
       "  7                7742.0                 4.0                 242.0   \n",
       "  8                7742.0                 4.0                 242.0   \n",
       "  9                7742.0                 4.0                 242.0   \n",
       "  10               7742.0                 4.0                 242.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                 8.0                543.0  \n",
       "  1                 8.0                543.0  \n",
       "  2                 8.0                543.0  \n",
       "  3                 8.0                543.0  \n",
       "  4                 8.0                543.0  \n",
       "  5                 8.0                543.0  \n",
       "  6                 8.0                543.0  \n",
       "  7                 8.0                543.0  \n",
       "  8                 8.0                543.0  \n",
       "  9                 8.0                543.0  \n",
       "  10                8.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9134      0.031182           0.9116   \n",
       "  2                  0.2         0.8168      0.039067           0.8094   \n",
       "  3                  0.3         0.7198      0.040270           0.7108   \n",
       "  4                  0.4         0.6042      0.043240           0.6008   \n",
       "  5                  0.5         0.4870      0.030692           0.4840   \n",
       "  6                  0.6         0.3832      0.017065           0.3866   \n",
       "  7                  0.7         0.2570      0.022338           0.2570   \n",
       "  8                  0.8         0.1640      0.023885           0.1636   \n",
       "  9                  0.9         0.0726      0.020107           0.0726   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.032708           0.9276        0.042004           0.0866   \n",
       "  2         0.037786           0.8666        0.090980           0.1832   \n",
       "  3         0.036725           0.7834        0.099027           0.2802   \n",
       "  4         0.042623           0.6280        0.082253           0.3958   \n",
       "  5         0.038749           0.5112        0.072344           0.5130   \n",
       "  6         0.023713           0.3612        0.125727           0.6168   \n",
       "  7         0.014142           0.2556        0.120388           0.7430   \n",
       "  8         0.029203           0.1666        0.112629           0.8360   \n",
       "  9         0.020120           0.0724        0.050342           0.9274   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.031182             0.0884  ...        0.035889           0.9050   \n",
       "  2         0.039067             0.1906  ...        0.029521           0.8938   \n",
       "  3         0.040270             0.2892  ...        0.023565           0.9130   \n",
       "  4         0.043240             0.3992  ...        0.026584           0.9258   \n",
       "  5         0.030692             0.5160  ...        0.033076           0.9476   \n",
       "  6         0.017065             0.6134  ...        0.033941           0.9500   \n",
       "  7         0.022338             0.7430  ...        0.039437           0.9290   \n",
       "  8         0.023885             0.8364  ...        0.036162           0.8790   \n",
       "  9         0.020107             0.9274  ...        0.067994           0.9334   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              933.0   \n",
       "  1         0.051633                   0.1              933.0   \n",
       "  2         0.044008                   0.2              933.0   \n",
       "  3         0.037014                   0.3              933.0   \n",
       "  4         0.019829                   0.4              933.0   \n",
       "  5         0.008444                   0.5              933.0   \n",
       "  6         0.028098                   0.6              933.0   \n",
       "  7         0.043365                   0.7              933.0   \n",
       "  8         0.094120                   0.8              933.0   \n",
       "  9         0.148922                   0.9              933.0   \n",
       "  10        0.000000                   1.0              933.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6687.0                29.0                 236.0   \n",
       "  1                6687.0                29.0                 236.0   \n",
       "  2                6687.0                29.0                 236.0   \n",
       "  3                6687.0                29.0                 236.0   \n",
       "  4                6687.0                29.0                 236.0   \n",
       "  5                6687.0                29.0                 236.0   \n",
       "  6                6687.0                29.0                 236.0   \n",
       "  7                6687.0                29.0                 236.0   \n",
       "  8                6687.0                29.0                 236.0   \n",
       "  9                6687.0                29.0                 236.0   \n",
       "  10               6687.0                29.0                 236.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                71.0                506.0  \n",
       "  1                71.0                506.0  \n",
       "  2                71.0                506.0  \n",
       "  3                71.0                506.0  \n",
       "  4                71.0                506.0  \n",
       "  5                71.0                506.0  \n",
       "  6                71.0                506.0  \n",
       "  7                71.0                506.0  \n",
       "  8                71.0                506.0  \n",
       "  9                71.0                506.0  \n",
       "  10               71.0                506.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9176      0.019540           0.9160   \n",
       "  2                  0.2         0.8248      0.019071           0.8210   \n",
       "  3                  0.3         0.7232      0.043900           0.7206   \n",
       "  4                  0.4         0.5952      0.051090           0.5874   \n",
       "  5                  0.5         0.4836      0.050698           0.4804   \n",
       "  6                  0.6         0.3776      0.049207           0.3760   \n",
       "  7                  0.7         0.2728      0.046880           0.2728   \n",
       "  8                  0.8         0.1640      0.035398           0.1620   \n",
       "  9                  0.9         0.0788      0.024833           0.0758   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.019183             0.96        0.054772           0.0824   \n",
       "  2         0.017393             0.92        0.083666           0.1752   \n",
       "  3         0.041440             0.80        0.187083           0.2768   \n",
       "  4         0.051042             0.80        0.187083           0.4048   \n",
       "  5         0.057461             0.58        0.164317           0.5164   \n",
       "  6         0.053828             0.42        0.130384           0.6224   \n",
       "  7         0.051173             0.26        0.134164           0.7272   \n",
       "  8         0.038158             0.22        0.083666           0.8360   \n",
       "  9         0.024611             0.16        0.151658           0.9212   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.019540             0.0840  ...        0.095772           0.9332   \n",
       "  2         0.019071             0.1790  ...        0.053276           0.8844   \n",
       "  3         0.043900             0.2794  ...        0.046644           0.7950   \n",
       "  4         0.051090             0.4126  ...        0.086668           0.7950   \n",
       "  5         0.050698             0.5196  ...        0.124710           0.7762   \n",
       "  6         0.049207             0.6240  ...        0.085597           0.7738   \n",
       "  7         0.046880             0.7272  ...        0.067607           0.7400   \n",
       "  8         0.035398             0.8380  ...        0.062796           0.7500   \n",
       "  9         0.024833             0.9242  ...        0.031752           0.6000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              419.0   \n",
       "  1         0.091470                   0.1              419.0   \n",
       "  2         0.120927                   0.2              419.0   \n",
       "  3         0.184052                   0.3              419.0   \n",
       "  4         0.184052                   0.4              419.0   \n",
       "  5         0.189056                   0.5              419.0   \n",
       "  6         0.212748                   0.6              419.0   \n",
       "  7         0.279285                   0.7              419.0   \n",
       "  8         0.250000                   0.8              419.0   \n",
       "  9         0.547723                   0.9              419.0   \n",
       "  10        0.000000                   1.0              419.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7763.0                10.0                 270.0   \n",
       "  1                7763.0                10.0                 270.0   \n",
       "  2                7763.0                10.0                 270.0   \n",
       "  3                7763.0                10.0                 270.0   \n",
       "  4                7763.0                10.0                 270.0   \n",
       "  5                7763.0                10.0                 270.0   \n",
       "  6                7763.0                10.0                 270.0   \n",
       "  7                7763.0                10.0                 270.0   \n",
       "  8                7763.0                10.0                 270.0   \n",
       "  9                7763.0                10.0                 270.0   \n",
       "  10               7763.0                10.0                 270.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                20.0                548.0  \n",
       "  1                20.0                548.0  \n",
       "  2                20.0                548.0  \n",
       "  3                20.0                548.0  \n",
       "  4                20.0                548.0  \n",
       "  5                20.0                548.0  \n",
       "  6                20.0                548.0  \n",
       "  7                20.0                548.0  \n",
       "  8                20.0                548.0  \n",
       "  9                20.0                548.0  \n",
       "  10               20.0                548.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9124      0.030997           0.9116   \n",
       "  2                  0.2         0.7994      0.035487           0.7990   \n",
       "  3                  0.3         0.6864      0.053687           0.6846   \n",
       "  4                  0.4         0.5766      0.057834           0.5736   \n",
       "  5                  0.5         0.4718      0.049952           0.4698   \n",
       "  6                  0.6         0.3756      0.042934           0.3728   \n",
       "  7                  0.7         0.2726      0.037078           0.2682   \n",
       "  8                  0.8         0.1680      0.035965           0.1648   \n",
       "  9                  0.9         0.0748      0.026715           0.0706   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.032300           0.9220        0.056227           0.0876   \n",
       "  2         0.036256           0.8052        0.191853           0.2006   \n",
       "  3         0.053440           0.7144        0.153122           0.3136   \n",
       "  4         0.053505           0.6260        0.227089           0.4234   \n",
       "  5         0.050682           0.5076        0.200466           0.5282   \n",
       "  6         0.049262           0.4284        0.165045           0.6244   \n",
       "  7         0.045019           0.3502        0.157047           0.7274   \n",
       "  8         0.042169           0.2200        0.143758           0.8320   \n",
       "  9         0.029168           0.1424        0.145717           0.9252   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.030997             0.0884  ...        0.078850           0.8278   \n",
       "  2         0.035487             0.2010  ...        0.061403           0.7560   \n",
       "  3         0.053687             0.3154  ...        0.060568           0.7052   \n",
       "  4         0.057834             0.4264  ...        0.062894           0.7210   \n",
       "  5         0.049952             0.5302  ...        0.071664           0.7762   \n",
       "  6         0.042934             0.6272  ...        0.083688           0.8574   \n",
       "  7         0.037078             0.7318  ...        0.088138           0.8234   \n",
       "  8         0.035965             0.8352  ...        0.108355           0.7534   \n",
       "  9         0.026715             0.9294  ...        0.048680           0.6000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              204.0   \n",
       "  1         0.127803                   0.1              204.0   \n",
       "  2         0.202278                   0.2              204.0   \n",
       "  3         0.133593                   0.3              204.0   \n",
       "  4         0.139936                   0.4              204.0   \n",
       "  5         0.142330                   0.5              204.0   \n",
       "  6         0.094725                   0.6              204.0   \n",
       "  7         0.129857                   0.7              204.0   \n",
       "  8         0.232826                   0.8              204.0   \n",
       "  9         0.547723                   0.9              204.0   \n",
       "  10        0.000000                   1.0              204.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7414.0                15.0                 245.0   \n",
       "  1                7414.0                15.0                 245.0   \n",
       "  2                7414.0                15.0                 245.0   \n",
       "  3                7414.0                15.0                 245.0   \n",
       "  4                7414.0                15.0                 245.0   \n",
       "  5                7414.0                15.0                 245.0   \n",
       "  6                7414.0                15.0                 245.0   \n",
       "  7                7414.0                15.0                 245.0   \n",
       "  8                7414.0                15.0                 245.0   \n",
       "  9                7414.0                15.0                 245.0   \n",
       "  10               7414.0                15.0                 245.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                31.0                543.0  \n",
       "  1                31.0                543.0  \n",
       "  2                31.0                543.0  \n",
       "  3                31.0                543.0  \n",
       "  4                31.0                543.0  \n",
       "  5                31.0                543.0  \n",
       "  6                31.0                543.0  \n",
       "  7                31.0                543.0  \n",
       "  8                31.0                543.0  \n",
       "  9                31.0                543.0  \n",
       "  10               31.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns]],\n",
       " 'cv_trainupdate': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9172      0.009576           0.9172   \n",
       "  2                  0.2         0.8176      0.007021           0.8168   \n",
       "  3                  0.3         0.7144      0.002702           0.7140   \n",
       "  4                  0.4         0.6100      0.006364           0.6082   \n",
       "  5                  0.5         0.4994      0.010877           0.4968   \n",
       "  6                  0.6         0.3896      0.014188           0.3872   \n",
       "  7                  0.7         0.2858      0.013480           0.2832   \n",
       "  8                  0.8         0.1834      0.010455           0.1816   \n",
       "  9                  0.9         0.0854      0.012361           0.0860   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010663           0.9224        0.021927           0.0828   \n",
       "  2         0.008167           0.8352        0.051857           0.1824   \n",
       "  3         0.004301           0.7260        0.088620           0.2856   \n",
       "  4         0.009706           0.6488        0.093687           0.3900   \n",
       "  5         0.013882           0.5588        0.075758           0.5006   \n",
       "  6         0.016976           0.4592        0.087070           0.6104   \n",
       "  7         0.016300           0.3506        0.086717           0.7142   \n",
       "  8         0.011803           0.2294        0.081463           0.8166   \n",
       "  9         0.012145           0.0714        0.023554           0.9146   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.009576             0.0828  ...          0.070517         0.8624   \n",
       "  2         0.007021             0.1832  ...          0.020137         0.8090   \n",
       "  3         0.002702             0.2860  ...          0.076930         0.8798   \n",
       "  4         0.006364             0.3918  ...          0.082198         0.9330   \n",
       "  5         0.010877             0.5032  ...          0.065064         0.9606   \n",
       "  6         0.014188             0.6128  ...          0.090034         0.9744   \n",
       "  7         0.013480             0.7168  ...          0.078519         0.9806   \n",
       "  8         0.010455             0.8184  ...          0.076379         0.9872   \n",
       "  9         0.012361             0.9140  ...          0.029143         0.9886   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.020513           0.8598        0.023167           0.9012   \n",
       "  2       0.012288           0.8084        0.014433           0.8306   \n",
       "  3       0.028934           0.8808        0.030720           0.8488   \n",
       "  4       0.020112           0.9358        0.022163           0.8678   \n",
       "  5       0.013315           0.9648        0.014789           0.8756   \n",
       "  6       0.007570           0.9792        0.007791           0.8788   \n",
       "  7       0.003362           0.9856        0.004037           0.8846   \n",
       "  8       0.002168           0.9888        0.001789           0.9542   \n",
       "  9       0.006427           0.9910        0.006325           0.9380   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.029677                   0.1            0              0  \n",
       "  2         0.052472                   0.2            0              0  \n",
       "  3         0.033056                   0.3            0              0  \n",
       "  4         0.034838                   0.4            0              0  \n",
       "  5         0.041669                   0.5            0              0  \n",
       "  6         0.025975                   0.6            0              0  \n",
       "  7         0.053524                   0.7            0              0  \n",
       "  8         0.042787                   0.8            0              0  \n",
       "  9         0.085320                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9196      0.011546           0.9182   \n",
       "  2                  0.2         0.8252      0.009757           0.8262   \n",
       "  3                  0.3         0.7384      0.016920           0.7422   \n",
       "  4                  0.4         0.6046      0.015582           0.6038   \n",
       "  5                  0.5         0.4990      0.013058           0.4980   \n",
       "  6                  0.6         0.3810      0.017607           0.3754   \n",
       "  7                  0.7         0.2748      0.020474           0.2678   \n",
       "  8                  0.8         0.1614      0.022678           0.1568   \n",
       "  9                  0.9         0.0700      0.011136           0.0660   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009731           0.9302        0.027815           0.0804   \n",
       "  2         0.007190           0.8170        0.041061           0.1748   \n",
       "  3         0.011819           0.7126        0.062820           0.2616   \n",
       "  4         0.011234           0.6096        0.056985           0.3954   \n",
       "  5         0.015297           0.5062        0.052156           0.5010   \n",
       "  6         0.018325           0.4216        0.059635           0.6190   \n",
       "  7         0.019058           0.3264        0.061431           0.7252   \n",
       "  8         0.018860           0.1952        0.063959           0.8386   \n",
       "  9         0.009618           0.0976        0.035606           0.9300   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.011546             0.0818  ...          0.049211         0.7366   \n",
       "  2         0.009757             0.1738  ...          0.028517         0.7286   \n",
       "  3         0.016920             0.2578  ...          0.020428         0.7274   \n",
       "  4         0.015582             0.3962  ...          0.034107         0.7788   \n",
       "  5         0.013058             0.5020  ...          0.041461         0.8536   \n",
       "  6         0.017607             0.6246  ...          0.061057         0.8960   \n",
       "  7         0.020474             0.7322  ...          0.073598         0.9162   \n",
       "  8         0.022678             0.8432  ...          0.067170         0.9364   \n",
       "  9         0.011136             0.9340  ...          0.032863         0.9312   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.028562           0.6888        0.029609           0.8832   \n",
       "  2       0.006107           0.7204        0.007021           0.7714   \n",
       "  3       0.005941           0.7308        0.005630           0.7050   \n",
       "  4       0.012598           0.7892        0.018794           0.7130   \n",
       "  5       0.024399           0.8784        0.029168           0.7154   \n",
       "  6       0.013583           0.9288        0.014738           0.7332   \n",
       "  7       0.014601           0.9508        0.012296           0.7560   \n",
       "  8       0.026689           0.9806        0.012116           0.7398   \n",
       "  9       0.030020           0.9852        0.015897           0.7246   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.038623                   0.1            0              0  \n",
       "  2         0.051169                   0.2            0              0  \n",
       "  3         0.059904                   0.3            0              0  \n",
       "  4         0.043960                   0.4            0              0  \n",
       "  5         0.053682                   0.5            0              0  \n",
       "  6         0.041782                   0.6            0              0  \n",
       "  7         0.038419                   0.7            0              0  \n",
       "  8         0.107281                   0.8            0              0  \n",
       "  9         0.147698                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9252      0.011256           0.9260   \n",
       "  2                  0.2         0.8234      0.014381           0.8234   \n",
       "  3                  0.3         0.7218      0.015073           0.7228   \n",
       "  4                  0.4         0.6034      0.007925           0.6038   \n",
       "  5                  0.5         0.4810      0.006745           0.4788   \n",
       "  6                  0.6         0.3656      0.015241           0.3630   \n",
       "  7                  0.7         0.2516      0.008649           0.2486   \n",
       "  8                  0.8         0.1566      0.005899           0.1544   \n",
       "  9                  0.9         0.0664      0.004561           0.0656   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.011023           0.9144        0.079992           0.0748   \n",
       "  2         0.013221           0.8286        0.069421           0.1766   \n",
       "  3         0.014061           0.7024        0.077439           0.2782   \n",
       "  4         0.007530           0.5980        0.046524           0.3966   \n",
       "  5         0.006870           0.5282        0.043837           0.5190   \n",
       "  6         0.013491           0.4240        0.095512           0.6344   \n",
       "  7         0.007635           0.3112        0.074814           0.7484   \n",
       "  8         0.007668           0.2010        0.069127           0.8434   \n",
       "  9         0.005941           0.0884        0.039431           0.9336   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.011256             0.0740  ...          0.044415         0.7062   \n",
       "  2         0.014381             0.1766  ...          0.042317         0.7056   \n",
       "  3         0.015073             0.2772  ...          0.035773         0.7446   \n",
       "  4         0.007925             0.3962  ...          0.029677         0.9490   \n",
       "  5         0.006745             0.5212  ...          0.041817         0.9762   \n",
       "  6         0.015241             0.6370  ...          0.064137         0.9790   \n",
       "  7         0.008649             0.7514  ...          0.063650         0.9780   \n",
       "  8         0.005899             0.8456  ...          0.091685         0.9786   \n",
       "  9         0.004561             0.9344  ...          0.070808         0.9714   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.032584           0.6802        0.044673           0.8876   \n",
       "  2       0.030664           0.6994        0.035746           0.7970   \n",
       "  3       0.042864           0.7464        0.046715           0.7110   \n",
       "  4       0.023259           0.9630        0.025700           0.7146   \n",
       "  5       0.004550           0.9940        0.002121           0.7174   \n",
       "  6       0.003674           0.9968        0.002049           0.7214   \n",
       "  7       0.010368           0.9986        0.002191           0.7162   \n",
       "  8       0.015821           1.0000        0.000000           0.7312   \n",
       "  9       0.025481           1.0000        0.000000           0.7378   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.100455                   0.1            0              0  \n",
       "  2         0.069735                   0.2            0              0  \n",
       "  3         0.051088                   0.3            0              0  \n",
       "  4         0.046570                   0.4            0              0  \n",
       "  5         0.057540                   0.5            0              0  \n",
       "  6         0.103435                   0.6            0              0  \n",
       "  7         0.134094                   0.7            0              0  \n",
       "  8         0.165622                   0.8            0              0  \n",
       "  9         0.210047                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9196      0.004930           0.9204   \n",
       "  2                  0.2         0.8380      0.009849           0.8390   \n",
       "  3                  0.3         0.7126      0.012422           0.7124   \n",
       "  4                  0.4         0.6072      0.016514           0.6066   \n",
       "  5                  0.5         0.4894      0.014926           0.4886   \n",
       "  6                  0.6         0.3776      0.013502           0.3754   \n",
       "  7                  0.7         0.2716      0.012422           0.2680   \n",
       "  8                  0.8         0.1660      0.013172           0.1618   \n",
       "  9                  0.9         0.0752      0.010498           0.0746   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004393           0.9044        0.064260           0.0804   \n",
       "  2         0.008746           0.8188        0.092961           0.1620   \n",
       "  3         0.007021           0.7178        0.123753           0.2874   \n",
       "  4         0.010714           0.6142        0.118711           0.3928   \n",
       "  5         0.011524           0.5026        0.082585           0.5106   \n",
       "  6         0.010644           0.4256        0.085623           0.6224   \n",
       "  7         0.012410           0.3426        0.073992           0.7284   \n",
       "  8         0.013387           0.2440        0.048903           0.8340   \n",
       "  9         0.011610           0.0882        0.041817           0.9248   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.004930             0.0796  ...          0.065284         0.7944   \n",
       "  2         0.009849             0.1610  ...          0.070706         0.7860   \n",
       "  3         0.012422             0.2876  ...          0.055333         0.7710   \n",
       "  4         0.016514             0.3934  ...          0.090509         0.8560   \n",
       "  5         0.014926             0.5114  ...          0.043906         0.9048   \n",
       "  6         0.013502             0.6246  ...          0.027590         0.9334   \n",
       "  7         0.012422             0.7320  ...          0.038981         0.9534   \n",
       "  8         0.013172             0.8382  ...          0.024306         0.9654   \n",
       "  9         0.010498             0.9254  ...          0.038160         0.9896   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.014673           0.7876        0.021559           0.8602   \n",
       "  2       0.007583           0.7858        0.011520           0.7888   \n",
       "  3       0.023184           0.7722        0.029141           0.7518   \n",
       "  4       0.007810           0.8614        0.014100           0.7658   \n",
       "  5       0.004817           0.9144        0.010738           0.7640   \n",
       "  6       0.010644           0.9446        0.012837           0.7790   \n",
       "  7       0.007092           0.9662        0.004550           0.7934   \n",
       "  8       0.010877           0.9748        0.003033           0.8584   \n",
       "  9       0.003912           0.9904        0.001949           0.9500   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.089603                   0.1            0              0  \n",
       "  2         0.105980                   0.2            0              0  \n",
       "  3         0.093657                   0.3            0              0  \n",
       "  4         0.108040                   0.4            0              0  \n",
       "  5         0.114215                   0.5            0              0  \n",
       "  6         0.142222                   0.6            0              0  \n",
       "  7         0.121352                   0.7            0              0  \n",
       "  8         0.130783                   0.8            0              0  \n",
       "  9         0.111803                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9122      0.008349           0.9132   \n",
       "  2                  0.2         0.8244      0.008444           0.8244   \n",
       "  3                  0.3         0.7102      0.011345           0.7056   \n",
       "  4                  0.4         0.6024      0.017501           0.5934   \n",
       "  5                  0.5         0.4992      0.016649           0.4906   \n",
       "  6                  0.6         0.3944      0.018352           0.3824   \n",
       "  7                  0.7         0.2776      0.015694           0.2748   \n",
       "  8                  0.8         0.1846      0.011014           0.1830   \n",
       "  9                  0.9         0.0892      0.010426           0.0896   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009391           0.9076        0.018942           0.0878   \n",
       "  2         0.010831           0.8254        0.014859           0.1756   \n",
       "  3         0.010945           0.7332        0.015336           0.2898   \n",
       "  4         0.015027           0.6500        0.034533           0.3976   \n",
       "  5         0.015947           0.5456        0.024765           0.5008   \n",
       "  6         0.020032           0.4570        0.028965           0.6056   \n",
       "  7         0.016888           0.2916        0.036177           0.7224   \n",
       "  8         0.011554           0.1932        0.022084           0.8154   \n",
       "  9         0.010922           0.0886        0.018569           0.9108   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.008349             0.0868  ...          0.021879         0.9034   \n",
       "  2         0.008444             0.1756  ...          0.016574         0.9104   \n",
       "  3         0.011345             0.2944  ...          0.009915         0.9404   \n",
       "  4         0.017501             0.4066  ...          0.039753         0.9610   \n",
       "  5         0.016649             0.5094  ...          0.029467         0.9674   \n",
       "  6         0.018352             0.6176  ...          0.030550         0.9706   \n",
       "  7         0.015694             0.7252  ...          0.041006         0.9788   \n",
       "  8         0.011014             0.8170  ...          0.024243         0.9790   \n",
       "  9         0.010426             0.9104  ...          0.020611         0.9724   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.008877           0.9038        0.010450           0.9010   \n",
       "  2       0.005771           0.9142        0.008701           0.8906   \n",
       "  3       0.005639           0.9442        0.004324           0.9200   \n",
       "  4       0.003162           0.9644        0.005030           0.9458   \n",
       "  5       0.007635           0.9702        0.007662           0.9556   \n",
       "  6       0.009370           0.9720        0.008031           0.9652   \n",
       "  7       0.009257           0.9802        0.007155           0.9744   \n",
       "  8       0.009975           0.9784        0.009236           0.9824   \n",
       "  9       0.016103           0.9724        0.016456           0.9726   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.018385                   0.1            0              0  \n",
       "  2         0.011283                   0.2            0              0  \n",
       "  3         0.020833                   0.3            0              0  \n",
       "  4         0.015320                   0.4            0              0  \n",
       "  5         0.017644                   0.5            0              0  \n",
       "  6         0.020080                   0.6            0              0  \n",
       "  7         0.026736                   0.7            0              0  \n",
       "  8         0.017672                   0.8            0              0  \n",
       "  9         0.025861                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9206      0.014363           0.9212   \n",
       "  2                  0.2         0.8366      0.013428           0.8368   \n",
       "  3                  0.3         0.7068      0.010183           0.7054   \n",
       "  4                  0.4         0.6082      0.018116           0.6048   \n",
       "  5                  0.5         0.4988      0.015563           0.4942   \n",
       "  6                  0.6         0.3966      0.018420           0.3920   \n",
       "  7                  0.7         0.2898      0.011925           0.2854   \n",
       "  8                  0.8         0.1828      0.012071           0.1830   \n",
       "  9                  0.9         0.0842      0.011777           0.0866   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.015482           0.9104        0.040352           0.0794   \n",
       "  2         0.015611           0.8292        0.043757           0.1634   \n",
       "  3         0.015159           0.7278        0.071657           0.2932   \n",
       "  4         0.023274           0.6582        0.060702           0.3918   \n",
       "  5         0.017852           0.5650        0.082137           0.5012   \n",
       "  6         0.021260           0.4660        0.069094           0.6034   \n",
       "  7         0.014276           0.3556        0.055622           0.7102   \n",
       "  8         0.013928           0.1862        0.026920           0.8172   \n",
       "  9         0.011992           0.0506        0.023394           0.9158   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.014363             0.0788  ...          0.064445         0.8776   \n",
       "  2         0.013428             0.1632  ...          0.010922         0.8362   \n",
       "  3         0.010183             0.2946  ...          0.040357         0.8972   \n",
       "  4         0.018116             0.3952  ...          0.050757         0.9358   \n",
       "  5         0.015563             0.5058  ...          0.095392         0.9600   \n",
       "  6         0.018420             0.6080  ...          0.078049         0.9750   \n",
       "  7         0.011925             0.7146  ...          0.064084         0.9878   \n",
       "  8         0.012071             0.8170  ...          0.024712         0.9920   \n",
       "  9         0.011777             0.9134  ...          0.019008         0.9912   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.024048           0.8762        0.028084           0.8914   \n",
       "  2       0.019486           0.8364        0.022098           0.8306   \n",
       "  3       0.020801           0.9008        0.024160           0.8450   \n",
       "  4       0.015023           0.9408        0.015928           0.8730   \n",
       "  5       0.012268           0.9652        0.011904           0.8990   \n",
       "  6       0.006782           0.9780        0.006928           0.9392   \n",
       "  7       0.003114           0.9894        0.005459           0.9704   \n",
       "  8       0.005568           0.9944        0.006229           0.9588   \n",
       "  9       0.002588           0.9942        0.006017           0.8934   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.051810                   0.1            0              0  \n",
       "  2         0.046662                   0.2            0              0  \n",
       "  3         0.050656                   0.3            0              0  \n",
       "  4         0.043977                   0.4            0              0  \n",
       "  5         0.036503                   0.5            0              0  \n",
       "  6         0.047893                   0.6            0              0  \n",
       "  7         0.021617                   0.7            0              0  \n",
       "  8         0.040034                   0.8            0              0  \n",
       "  9         0.153355                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9166      0.012896           0.9164   \n",
       "  2                  0.2         0.8124      0.011104           0.8116   \n",
       "  3                  0.3         0.7056      0.010621           0.7064   \n",
       "  4                  0.4         0.5996      0.006309           0.5988   \n",
       "  5                  0.5         0.4906      0.012522           0.4888   \n",
       "  6                  0.6         0.3904      0.015598           0.3872   \n",
       "  7                  0.7         0.2816      0.015566           0.2772   \n",
       "  8                  0.8         0.1834      0.007092           0.1786   \n",
       "  9                  0.9         0.0814      0.005595           0.0828   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.011415           0.9200        0.046899           0.0834   \n",
       "  2         0.009503           0.8254        0.043810           0.1876   \n",
       "  3         0.010139           0.6952        0.062906           0.2944   \n",
       "  4         0.005263           0.6094        0.059702           0.4004   \n",
       "  5         0.011256           0.5264        0.046699           0.5094   \n",
       "  6         0.012814           0.4526        0.068383           0.6096   \n",
       "  7         0.012337           0.3548        0.084449           0.7184   \n",
       "  8         0.005225           0.2692        0.083383           0.8166   \n",
       "  9         0.005119           0.0534        0.035275           0.9186   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.012896             0.0836  ...          0.042571         0.8676   \n",
       "  2         0.011104             0.1884  ...          0.012442         0.8022   \n",
       "  3         0.010621             0.2936  ...          0.036355         0.8622   \n",
       "  4         0.006309             0.4012  ...          0.055495         0.9168   \n",
       "  5         0.012522             0.5112  ...          0.043638         0.9478   \n",
       "  6         0.015598             0.6128  ...          0.056060         0.9722   \n",
       "  7         0.015566             0.7228  ...          0.078290         0.9884   \n",
       "  8         0.007092             0.8214  ...          0.080972         0.9920   \n",
       "  9         0.005595             0.9172  ...          0.035019         0.9932   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.016682           0.8660        0.015133           0.8936   \n",
       "  2       0.008927           0.8012        0.007727           0.8140   \n",
       "  3       0.015271           0.8636        0.017771           0.8294   \n",
       "  4       0.007596           0.9200        0.009192           0.8656   \n",
       "  5       0.007155           0.9512        0.004817           0.8956   \n",
       "  6       0.007396           0.9744        0.006309           0.9366   \n",
       "  7       0.003578           0.9912        0.004658           0.9480   \n",
       "  8       0.005657           0.9938        0.004970           0.9632   \n",
       "  9       0.007120           0.9946        0.008050           0.9500   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.060694                   0.1            0              0  \n",
       "  2         0.046594                   0.2            0              0  \n",
       "  3         0.047758                   0.3            0              0  \n",
       "  4         0.047611                   0.4            0              0  \n",
       "  5         0.063343                   0.5            0              0  \n",
       "  6         0.048034                   0.6            0              0  \n",
       "  7         0.049320                   0.7            0              0  \n",
       "  8         0.036616                   0.8            0              0  \n",
       "  9         0.111803                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9166      0.005983           0.9154   \n",
       "  2                  0.2         0.8198      0.009602           0.8216   \n",
       "  3                  0.3         0.7220      0.004637           0.7214   \n",
       "  4                  0.4         0.5944      0.008678           0.5892   \n",
       "  5                  0.5         0.4974      0.008905           0.4946   \n",
       "  6                  0.6         0.3824      0.018407           0.3776   \n",
       "  7                  0.7         0.2820      0.014248           0.2752   \n",
       "  8                  0.8         0.1792      0.011432           0.1726   \n",
       "  9                  0.9         0.0720      0.004472           0.0724   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009450           0.9234        0.018022           0.0834   \n",
       "  2         0.009290           0.8100        0.031089           0.1802   \n",
       "  3         0.007021           0.7236        0.012779           0.2780   \n",
       "  4         0.010986           0.6242        0.022565           0.4056   \n",
       "  5         0.015043           0.5126        0.026736           0.5026   \n",
       "  6         0.024552           0.4090        0.018358           0.6176   \n",
       "  7         0.018807           0.3190        0.025768           0.7180   \n",
       "  8         0.014223           0.2154        0.034085           0.8208   \n",
       "  9         0.005030           0.0696        0.030997           0.9280   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.005983             0.0846  ...          0.020567         0.8560   \n",
       "  2         0.009602             0.1784  ...          0.010085         0.8110   \n",
       "  3         0.004637             0.2786  ...          0.013069         0.8482   \n",
       "  4         0.008678             0.4108  ...          0.017824         0.8814   \n",
       "  5         0.008905             0.5054  ...          0.027166         0.9066   \n",
       "  6         0.018407             0.6224  ...          0.021260         0.9236   \n",
       "  7         0.014248             0.7248  ...          0.026006         0.9354   \n",
       "  8         0.011432             0.8274  ...          0.033982         0.9362   \n",
       "  9         0.004472             0.9276  ...          0.032929         0.9272   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.011402           0.8468        0.019018           0.8942   \n",
       "  2       0.007681           0.8124        0.008473           0.8038   \n",
       "  3       0.008167           0.8544        0.013885           0.8166   \n",
       "  4       0.007701           0.8898        0.013387           0.8396   \n",
       "  5       0.010526           0.9176        0.014046           0.8532   \n",
       "  6       0.012896           0.9312        0.014307           0.8866   \n",
       "  7       0.009788           0.9450        0.011424           0.8912   \n",
       "  8       0.011323           0.9420        0.013928           0.9090   \n",
       "  9       0.018647           0.9382        0.007662           0.8584   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.022488                   0.1            0              0  \n",
       "  2         0.030801                   0.2            0              0  \n",
       "  3         0.022210                   0.3            0              0  \n",
       "  4         0.022832                   0.4            0              0  \n",
       "  5         0.018807                   0.5            0              0  \n",
       "  6         0.017473                   0.6            0              0  \n",
       "  7         0.030136                   0.7            0              0  \n",
       "  8         0.044028                   0.8            0              0  \n",
       "  9         0.105263                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9254      0.012054           0.9254   \n",
       "  2                  0.2         0.8218      0.015547           0.8206   \n",
       "  3                  0.3         0.7168      0.020364           0.7162   \n",
       "  4                  0.4         0.6076      0.024876           0.6066   \n",
       "  5                  0.5         0.4980      0.021142           0.4960   \n",
       "  6                  0.6         0.3878      0.015255           0.3866   \n",
       "  7                  0.7         0.2764      0.017558           0.2760   \n",
       "  8                  0.8         0.1714      0.013012           0.1708   \n",
       "  9                  0.9         0.0762      0.012498           0.0762   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.011887           0.9218        0.025782           0.0746   \n",
       "  2         0.016334           0.8472        0.049135           0.1782   \n",
       "  3         0.022186           0.7256        0.052946           0.2832   \n",
       "  4         0.025066           0.6406        0.047173           0.3924   \n",
       "  5         0.020285           0.5422        0.094248           0.5020   \n",
       "  6         0.015678           0.4102        0.095413           0.6122   \n",
       "  7         0.018207           0.2846        0.060583           0.7236   \n",
       "  8         0.012950           0.1930        0.050145           0.8286   \n",
       "  9         0.013142           0.0782        0.033139           0.9238   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.012054             0.0746  ...          0.043909         0.8670   \n",
       "  2         0.015547             0.1794  ...          0.007603         0.8422   \n",
       "  3         0.020364             0.2838  ...          0.046101         0.9822   \n",
       "  4         0.024876             0.3934  ...          0.040587         0.9898   \n",
       "  5         0.021142             0.5040  ...          0.074684         0.9916   \n",
       "  6         0.015255             0.6134  ...          0.091568         0.9926   \n",
       "  7         0.017558             0.7240  ...          0.058149         0.9932   \n",
       "  8         0.013012             0.8292  ...          0.048350         0.9946   \n",
       "  9         0.012498             0.9238  ...          0.026879         0.9970   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.029283           0.8642        0.030744           0.9100   \n",
       "  2       0.037009           0.8424        0.040079           0.8468   \n",
       "  3       0.004658           0.9886        0.005225           0.8392   \n",
       "  4       0.001304           0.9960        0.001871           0.8626   \n",
       "  5       0.002510           0.9968        0.000837           0.8746   \n",
       "  6       0.001517           0.9982        0.001643           0.8712   \n",
       "  7       0.001095           0.9988        0.001789           0.8700   \n",
       "  8       0.004219           1.0000        0.000000           0.8888   \n",
       "  9       0.004123           1.0000        0.000000           0.8934   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.030356                   0.1            0              0  \n",
       "  2         0.048798                   0.2            0              0  \n",
       "  3         0.040684                   0.3            0              0  \n",
       "  4         0.030843                   0.4            0              0  \n",
       "  5         0.063359                   0.5            0              0  \n",
       "  6         0.042681                   0.6            0              0  \n",
       "  7         0.048842                   0.7            0              0  \n",
       "  8         0.074985                   0.8            0              0  \n",
       "  9         0.153355                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9216      0.005030           0.9228   \n",
       "  2                  0.2         0.8332      0.006419           0.8340   \n",
       "  3                  0.3         0.7204      0.013315           0.7198   \n",
       "  4                  0.4         0.6122      0.013424           0.6094   \n",
       "  5                  0.5         0.5068      0.011300           0.5020   \n",
       "  6                  0.6         0.3982      0.011904           0.3914   \n",
       "  7                  0.7         0.2872      0.010756           0.2802   \n",
       "  8                  0.8         0.1720      0.004000           0.1736   \n",
       "  9                  0.9         0.0816      0.008591           0.0816   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005541           0.9134        0.024276           0.0784   \n",
       "  2         0.008944           0.8296        0.032578           0.1668   \n",
       "  3         0.017006           0.7226        0.034818           0.2796   \n",
       "  4         0.018284           0.6346        0.043149           0.3878   \n",
       "  5         0.016778           0.5434        0.056074           0.4932   \n",
       "  6         0.012779           0.4470        0.036633           0.6018   \n",
       "  7         0.011234           0.3376        0.020268           0.7128   \n",
       "  8         0.007232           0.1586        0.021173           0.8280   \n",
       "  9         0.009965           0.0826        0.009607           0.9184   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.005030             0.0772  ...          0.020117         0.9018   \n",
       "  2         0.006419             0.1660  ...          0.013828         0.8906   \n",
       "  3         0.013315             0.2802  ...          0.029704         0.9266   \n",
       "  4         0.013424             0.3906  ...          0.042833         0.9470   \n",
       "  5         0.011300             0.4980  ...          0.055003         0.9594   \n",
       "  6         0.011904             0.6086  ...          0.035893         0.9698   \n",
       "  7         0.010756             0.7198  ...          0.025793         0.9772   \n",
       "  8         0.004000             0.8264  ...          0.022634         0.9842   \n",
       "  9         0.008591             0.9184  ...          0.009094         0.9820   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.005119           0.9014        0.007797           0.9012   \n",
       "  2       0.008414           0.8950        0.013000           0.8618   \n",
       "  3       0.007232           0.9332        0.011692           0.8834   \n",
       "  4       0.008972           0.9546        0.012661           0.8970   \n",
       "  5       0.008649           0.9660        0.010559           0.9182   \n",
       "  6       0.006140           0.9780        0.005148           0.9224   \n",
       "  7       0.004658           0.9864        0.002881           0.9274   \n",
       "  8       0.006573           0.9930        0.005050           0.9192   \n",
       "  9       0.016432           0.9848        0.011432           0.9648   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.026300                   0.1            0              0  \n",
       "  2         0.026109                   0.2            0              0  \n",
       "  3         0.030452                   0.3            0              0  \n",
       "  4         0.032992                   0.4            0              0  \n",
       "  5         0.031467                   0.5            0              0  \n",
       "  6         0.029871                   0.6            0              0  \n",
       "  7         0.014690                   0.7            0              0  \n",
       "  8         0.034888                   0.8            0              0  \n",
       "  9         0.078710                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9252      0.004550           0.9254   \n",
       "  2                  0.2         0.8190      0.008337           0.8184   \n",
       "  3                  0.3         0.7120      0.009247           0.7112   \n",
       "  4                  0.4         0.6024      0.010090           0.6006   \n",
       "  5                  0.5         0.4918      0.016529           0.4896   \n",
       "  6                  0.6         0.3858      0.015944           0.3812   \n",
       "  7                  0.7         0.2754      0.015043           0.2730   \n",
       "  8                  0.8         0.1750      0.015149           0.1738   \n",
       "  9                  0.9         0.0720      0.007517           0.0710   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004393           0.9144        0.017430           0.0748   \n",
       "  2         0.008706           0.8280        0.032863           0.1810   \n",
       "  3         0.011100           0.7234        0.046414           0.2880   \n",
       "  4         0.010164           0.6372        0.046778           0.3976   \n",
       "  5         0.017658           0.5368        0.042810           0.5082   \n",
       "  6         0.016814           0.4676        0.005367           0.6142   \n",
       "  7         0.015890           0.3152        0.013809           0.7246   \n",
       "  8         0.015205           0.1958        0.036286           0.8250   \n",
       "  9         0.007517           0.0858        0.022643           0.9280   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.004550             0.0746  ...          0.045779         0.8050   \n",
       "  2         0.008337             0.1816  ...          0.050761         0.7794   \n",
       "  3         0.009247             0.2888  ...          0.032408         0.8422   \n",
       "  4         0.010090             0.3994  ...          0.055493         0.9466   \n",
       "  5         0.016529             0.5104  ...          0.046246         0.9712   \n",
       "  6         0.015944             0.6188  ...          0.017430         0.9752   \n",
       "  7         0.015043             0.7270  ...          0.026442         0.9804   \n",
       "  8         0.015149             0.8262  ...          0.043079         0.9818   \n",
       "  9         0.007517             0.9290  ...          0.027718         0.9850   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.022661           0.7952        0.026253           0.8888   \n",
       "  2       0.012462           0.7772        0.014307           0.8130   \n",
       "  3       0.023360           0.8462        0.025352           0.7786   \n",
       "  4       0.010359           0.9566        0.011781           0.7992   \n",
       "  5       0.002588           0.9830        0.003082           0.8060   \n",
       "  6       0.004919           0.9890        0.003674           0.8072   \n",
       "  7       0.005030           0.9946        0.003847           0.7972   \n",
       "  8       0.006943           0.9978        0.002049           0.7806   \n",
       "  9       0.006403           1.0000        0.000000           0.8010   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.022432                   0.1            0              0  \n",
       "  2         0.035263                   0.2            0              0  \n",
       "  3         0.031493                   0.3            0              0  \n",
       "  4         0.017964                   0.4            0              0  \n",
       "  5         0.015281                   0.5            0              0  \n",
       "  6         0.028482                   0.6            0              0  \n",
       "  7         0.047209                   0.7            0              0  \n",
       "  8         0.057243                   0.8            0              0  \n",
       "  9         0.062865                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9156      0.008173           0.9150   \n",
       "  2                  0.2         0.8094      0.008562           0.8086   \n",
       "  3                  0.3         0.7046      0.005177           0.7036   \n",
       "  4                  0.4         0.5990      0.014265           0.5988   \n",
       "  5                  0.5         0.4934      0.011393           0.4932   \n",
       "  6                  0.6         0.3908      0.014255           0.3900   \n",
       "  7                  0.7         0.2820      0.020396           0.2810   \n",
       "  8                  0.8         0.1758      0.011189           0.1740   \n",
       "  9                  0.9         0.0806      0.007765           0.0808   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008307           0.9408        0.057626           0.0844   \n",
       "  2         0.010015           0.8330        0.057044           0.1906   \n",
       "  3         0.005273           0.7450        0.092944           0.2954   \n",
       "  4         0.013480           0.5980        0.102225           0.4010   \n",
       "  5         0.011946           0.5054        0.097818           0.5066   \n",
       "  6         0.013416           0.4168        0.111985           0.6092   \n",
       "  7         0.019634           0.3232        0.096011           0.7180   \n",
       "  8         0.010840           0.2450        0.076315           0.8242   \n",
       "  9         0.007294           0.0782        0.046634           0.9194   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.008173             0.0850  ...          0.131238         0.8094   \n",
       "  2         0.008562             0.1914  ...          0.046875         0.7692   \n",
       "  3         0.005177             0.2964  ...          0.051863         0.7978   \n",
       "  4         0.014265             0.4012  ...          0.115132         0.8894   \n",
       "  5         0.011393             0.5068  ...          0.143305         0.9382   \n",
       "  6         0.014255             0.6100  ...          0.145126         0.9738   \n",
       "  7         0.020396             0.7190  ...          0.119105         0.9830   \n",
       "  8         0.011189             0.8260  ...          0.091644         0.9868   \n",
       "  9         0.007765             0.9192  ...          0.049505         0.9934   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.020440           0.8054        0.022634           0.9192   \n",
       "  2       0.013809           0.7674        0.016196           0.8200   \n",
       "  3       0.017641           0.7976        0.019347           0.8020   \n",
       "  4       0.018447           0.8916        0.020182           0.8188   \n",
       "  5       0.015611           0.9412        0.016858           0.8534   \n",
       "  6       0.013590           0.9772        0.013517           0.8920   \n",
       "  7       0.014300           0.9860        0.014265           0.9222   \n",
       "  8       0.008468           0.9894        0.007635           0.9364   \n",
       "  9       0.006542           0.9984        0.003578           0.8334   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.075602                   0.1            0              0  \n",
       "  2         0.062506                   0.2            0              0  \n",
       "  3         0.061530                   0.3            0              0  \n",
       "  4         0.057903                   0.4            0              0  \n",
       "  5         0.069816                   0.5            0              0  \n",
       "  6         0.098522                   0.6            0              0  \n",
       "  7         0.127668                   0.7            0              0  \n",
       "  8         0.091787                   0.8            0              0  \n",
       "  9         0.235643                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns]],\n",
       " 'pred_score_trainupdate': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8326      0.012116           0.8334   \n",
       "  2                  0.2         0.7464      0.008264           0.7528   \n",
       "  3                  0.3         0.6428      0.011345           0.6472   \n",
       "  4                  0.4         0.5254      0.013390           0.5294   \n",
       "  5                  0.5         0.4108      0.003564           0.4170   \n",
       "  6                  0.6         0.3086      0.010968           0.3162   \n",
       "  7                  0.7         0.2108      0.008955           0.2220   \n",
       "  8                  0.8         0.1356      0.007733           0.1442   \n",
       "  9                  0.9         0.0650      0.005657           0.0694   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.011908           0.8168        0.050425           0.1674   \n",
       "  2         0.011454           0.6498        0.041937           0.2536   \n",
       "  3         0.013103           0.5722        0.057556           0.3572   \n",
       "  4         0.017544           0.4666        0.066451           0.4746   \n",
       "  5         0.005701           0.3112        0.041094           0.5892   \n",
       "  6         0.011189           0.1886        0.045583           0.6914   \n",
       "  7         0.010886           0.0334        0.036164           0.7892   \n",
       "  8         0.008228           0.0000        0.000000           0.8644   \n",
       "  9         0.005899           0.0000        0.000000           0.9350   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.012116             0.1666  ...          0.086419         0.7284   \n",
       "  2         0.008264             0.2472  ...          0.028000         0.7304   \n",
       "  3         0.011345             0.3528  ...          0.031925         0.7740   \n",
       "  4         0.013390             0.4706  ...          0.046465         0.8334   \n",
       "  5         0.003564             0.5830  ...          0.042464         0.9010   \n",
       "  6         0.010968             0.6838  ...          0.037045         0.9440   \n",
       "  7         0.008955             0.7780  ...          0.046465         0.9672   \n",
       "  8         0.007733             0.8558  ...          0.024542         0.9636   \n",
       "  9         0.005657             0.9306  ...          0.023069         0.9504   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.020256           0.7258        0.025538           0.7592   \n",
       "  2       0.013334           0.7366        0.015453           0.6400   \n",
       "  3       0.021131           0.7824        0.022810           0.6514   \n",
       "  4       0.023416           0.8464        0.026293           0.6548   \n",
       "  5       0.023195           0.9192        0.028778           0.6374   \n",
       "  6       0.004848           0.9672        0.010686           0.5860   \n",
       "  7       0.008585           0.9934        0.006768           0.2166   \n",
       "  8       0.008620           0.9948        0.007120           0.0000   \n",
       "  9       0.024613           0.9948        0.011628           0.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.051446                   0.1            0              0  \n",
       "  2         0.041707                   0.2            0              0  \n",
       "  3         0.053552                   0.3            0              0  \n",
       "  4         0.070602                   0.4            0              0  \n",
       "  5         0.079651                   0.5            0              0  \n",
       "  6         0.128901                   0.6            0              0  \n",
       "  7         0.217262                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8980      0.008367           0.8916   \n",
       "  2                  0.2         0.7768      0.012357           0.7698   \n",
       "  3                  0.3         0.6494      0.012837           0.6412   \n",
       "  4                  0.4         0.5900      0.012166           0.5896   \n",
       "  5                  0.5         0.4830      0.012450           0.4878   \n",
       "  6                  0.6         0.3624      0.017601           0.3710   \n",
       "  7                  0.7         0.2340      0.017234           0.2480   \n",
       "  8                  0.8         0.1228      0.008701           0.1286   \n",
       "  9                  0.9         0.0494      0.004336           0.0488   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008473           0.9552        0.017094           0.1020   \n",
       "  2         0.016574           0.8408        0.026883           0.2232   \n",
       "  3         0.018913           0.7224        0.053036           0.3506   \n",
       "  4         0.016502           0.5918        0.059340           0.4100   \n",
       "  5         0.012950           0.4368        0.055093           0.5170   \n",
       "  6         0.020845           0.2856        0.020501           0.6376   \n",
       "  7         0.018344           0.1060        0.016733           0.7660   \n",
       "  8         0.009044           0.0694        0.011502           0.8772   \n",
       "  9         0.004087           0.0532        0.018281           0.9506   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.008367             0.1084  ...          0.022594         0.6484   \n",
       "  2         0.012357             0.2302  ...          0.036281         0.6702   \n",
       "  3         0.012837             0.3588  ...          0.008944         0.6468   \n",
       "  4         0.012166             0.4104  ...          0.044503         0.7252   \n",
       "  5         0.012450             0.5122  ...          0.057895         0.8288   \n",
       "  6         0.017601             0.6290  ...          0.014498         0.9044   \n",
       "  7         0.017234             0.7520  ...          0.030794         0.9584   \n",
       "  8         0.008701             0.8714  ...          0.033856         0.9646   \n",
       "  9         0.004336             0.9512  ...          0.017094         0.9914   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.034012           0.5926        0.043690           0.9116   \n",
       "  2       0.021230           0.6546        0.028094           0.7904   \n",
       "  3       0.018019           0.6386        0.023850           0.7220   \n",
       "  4       0.029227           0.7286        0.037720           0.6970   \n",
       "  5       0.018075           0.8424        0.021995           0.7120   \n",
       "  6       0.021102           0.9220        0.027586           0.7368   \n",
       "  7       0.008849           0.9856        0.005079           0.6066   \n",
       "  8       0.018270           0.9962        0.008497           0.6534   \n",
       "  9       0.019230           1.0000        0.000000           0.9334   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.032098                   0.1            0              0  \n",
       "  2         0.033516                   0.2            0              0  \n",
       "  3         0.051069                   0.3            0              0  \n",
       "  4         0.054704                   0.4            0              0  \n",
       "  5         0.039198                   0.5            0              0  \n",
       "  6         0.049525                   0.6            0              0  \n",
       "  7         0.048444                   0.7            0              0  \n",
       "  8         0.106338                   0.8            0              0  \n",
       "  9         0.148922                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8988      0.007294           0.8970   \n",
       "  2                  0.2         0.8280      0.008000           0.8276   \n",
       "  3                  0.3         0.7122      0.008614           0.7114   \n",
       "  4                  0.4         0.5940      0.014714           0.5990   \n",
       "  5                  0.5         0.4688      0.019867           0.4784   \n",
       "  6                  0.6         0.3526      0.007925           0.3596   \n",
       "  7                  0.7         0.2368      0.015865           0.2416   \n",
       "  8                  0.8         0.1468      0.011167           0.1498   \n",
       "  9                  0.9         0.0650      0.012610           0.0664   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007176           0.9818        0.040696           0.1012   \n",
       "  2         0.008905           0.8544        0.122089           0.1720   \n",
       "  3         0.008562           0.7454        0.174626           0.2878   \n",
       "  4         0.012227           0.3456        0.174756           0.4060   \n",
       "  5         0.020070           0.0000        0.000000           0.5312   \n",
       "  6         0.007925           0.0000        0.000000           0.6474   \n",
       "  7         0.016273           0.0000        0.000000           0.7632   \n",
       "  8         0.011167           0.0000        0.000000           0.8532   \n",
       "  9         0.012542           0.0000        0.000000           0.9350   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007294             0.1030  ...          0.103406         0.6060   \n",
       "  2         0.008000             0.1724  ...          0.081393         0.6996   \n",
       "  3         0.008614             0.2886  ...          0.081393         0.7362   \n",
       "  4         0.014714             0.4010  ...          0.128163         0.9532   \n",
       "  5         0.019867             0.5216  ...          0.111452         0.9894   \n",
       "  6         0.007925             0.6404  ...          0.000000         0.9940   \n",
       "  7         0.015865             0.7584  ...          0.040696         0.9940   \n",
       "  8         0.011167             0.8502  ...          0.040696         0.9978   \n",
       "  9         0.012610             0.9336  ...          0.000000         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.038275           0.5884        0.042069           0.9714   \n",
       "  2       0.034166           0.6960        0.039051           0.8160   \n",
       "  3       0.045587           0.7356        0.048773           0.7620   \n",
       "  4       0.028525           0.9590        0.031631           0.6128   \n",
       "  5       0.003209           0.9968        0.003347           0.0000   \n",
       "  6       0.002236           0.9990        0.002236           0.0000   \n",
       "  7       0.003391           1.0000        0.000000           0.0000   \n",
       "  8       0.004919           1.0000        0.000000           0.0000   \n",
       "  9       0.000000           1.0000        0.000000           0.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.063952                   0.1            0              0  \n",
       "  2         0.146003                   0.2            0              0  \n",
       "  3         0.132146                   0.3            0              0  \n",
       "  4         0.242217                   0.4            0              0  \n",
       "  5         0.000000                   0.5            0              0  \n",
       "  6         0.000000                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8602      0.007563           0.8574   \n",
       "  2                  0.2         0.7538      0.015531           0.7520   \n",
       "  3                  0.3         0.6766      0.013631           0.6750   \n",
       "  4                  0.4         0.5712      0.012194           0.5702   \n",
       "  5                  0.5         0.4736      0.009839           0.4726   \n",
       "  6                  0.6         0.3588      0.009602           0.3576   \n",
       "  7                  0.7         0.2388      0.003033           0.2398   \n",
       "  8                  0.8         0.1464      0.008355           0.1494   \n",
       "  9                  0.9         0.0760      0.002550           0.0770   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007266           0.9366        0.023255           0.1398   \n",
       "  2         0.017986           0.8104        0.060123           0.2462   \n",
       "  3         0.013342           0.7262        0.043985           0.3234   \n",
       "  4         0.011670           0.6000        0.060079           0.4288   \n",
       "  5         0.010502           0.4946        0.046902           0.5264   \n",
       "  6         0.008295           0.3894        0.079983           0.6412   \n",
       "  7         0.003033           0.2108        0.037124           0.7612   \n",
       "  8         0.007197           0.0632        0.043866           0.8536   \n",
       "  9         0.002449           0.0424        0.023702           0.9240   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007563             0.1426  ...          0.044343         0.6622   \n",
       "  2         0.015531             0.2480  ...          0.083326         0.6934   \n",
       "  3         0.013631             0.3250  ...          0.000000         0.7140   \n",
       "  4         0.012194             0.4298  ...          0.113841         0.7696   \n",
       "  5         0.009839             0.5274  ...          0.088208         0.8366   \n",
       "  6         0.009602             0.6424  ...          0.101090         0.8894   \n",
       "  7         0.003033             0.7602  ...          0.043985         0.9248   \n",
       "  8         0.008355             0.8506  ...          0.043985         0.9544   \n",
       "  9         0.002550             0.9230  ...          0.023255         0.9736   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.026640           0.6506        0.028343           0.8936   \n",
       "  2       0.025462           0.6898        0.028004           0.7918   \n",
       "  3       0.022417           0.7138        0.023742           0.7262   \n",
       "  4       0.023416           0.7700        0.025348           0.7552   \n",
       "  5       0.022766           0.8398        0.024366           0.7622   \n",
       "  6       0.023975           0.8926        0.025205           0.8076   \n",
       "  7       0.009445           0.9306        0.008019           0.7700   \n",
       "  8       0.008444           0.9650        0.008000           0.4668   \n",
       "  9       0.009317           0.9954        0.010286           0.4000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.034406                   0.1            0              0  \n",
       "  2         0.049937                   0.2            0              0  \n",
       "  3         0.043985                   0.3            0              0  \n",
       "  4         0.059521                   0.4            0              0  \n",
       "  5         0.053002                   0.5            0              0  \n",
       "  6         0.064446                   0.6            0              0  \n",
       "  7         0.064765                   0.7            0              0  \n",
       "  8         0.273983                   0.8            0              0  \n",
       "  9         0.223607                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8766      0.004775           0.8698   \n",
       "  2                  0.2         0.7404      0.009839           0.7370   \n",
       "  3                  0.3         0.6706      0.014775           0.6828   \n",
       "  4                  0.4         0.5788      0.014738           0.5974   \n",
       "  5                  0.5         0.4902      0.015189           0.5094   \n",
       "  6                  0.6         0.3960      0.015540           0.4176   \n",
       "  7                  0.7         0.2920      0.006595           0.3070   \n",
       "  8                  0.8         0.1914      0.012442           0.1990   \n",
       "  9                  0.9         0.1030      0.006782           0.1080   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006611           0.9320        0.023011           0.1234   \n",
       "  2         0.009950           0.7680        0.018000           0.2596   \n",
       "  3         0.013971           0.5712        0.030744           0.3294   \n",
       "  4         0.012934           0.4284        0.053500           0.4212   \n",
       "  5         0.016134           0.3322        0.042915           0.5098   \n",
       "  6         0.016365           0.2212        0.020523           0.6040   \n",
       "  7         0.008573           0.1714        0.023628           0.7080   \n",
       "  8         0.011832           0.1286        0.026698           0.8086   \n",
       "  9         0.005657           0.0642        0.020042           0.8970   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.004775             0.1302  ...          0.041439         0.8570   \n",
       "  2         0.009839             0.2630  ...          0.038610         0.8694   \n",
       "  3         0.014775             0.3172  ...          0.028460         0.9176   \n",
       "  4         0.014738             0.4026  ...          0.054994         0.9470   \n",
       "  5         0.015189             0.4906  ...          0.042494         0.9596   \n",
       "  6         0.015540             0.5824  ...          0.020523         0.9670   \n",
       "  7         0.006595             0.6930  ...          0.023628         0.9616   \n",
       "  8         0.012442             0.8010  ...          0.026698         0.9514   \n",
       "  9         0.006782             0.8920  ...          0.020042         0.9852   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.005000           0.8494        0.006542           0.9224   \n",
       "  2       0.006731           0.8638        0.007294           0.9196   \n",
       "  3       0.006580           0.9156        0.005459           0.9414   \n",
       "  4       0.005788           0.9458        0.005450           0.9612   \n",
       "  5       0.003286           0.9572        0.003114           0.9894   \n",
       "  6       0.005244           0.9648        0.005215           1.0000   \n",
       "  7       0.008905           0.9590        0.009247           1.0000   \n",
       "  8       0.010237           0.9476        0.011371           1.0000   \n",
       "  9       0.015802           0.9844        0.016637           1.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.022390                   0.1            0              0  \n",
       "  2         0.023298                   0.2            0              0  \n",
       "  3         0.029771                   0.3            0              0  \n",
       "  4         0.053598                   0.4            0              0  \n",
       "  5         0.023702                   0.5            0              0  \n",
       "  6         0.000000                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8416      0.008295           0.8430   \n",
       "  2                  0.2         0.7162      0.010826           0.7220   \n",
       "  3                  0.3         0.6404      0.008142           0.6548   \n",
       "  4                  0.4         0.5334      0.007021           0.5494   \n",
       "  5                  0.5         0.4412      0.005718           0.4598   \n",
       "  6                  0.6         0.3460      0.009407           0.3642   \n",
       "  7                  0.7         0.2292      0.004604           0.2430   \n",
       "  8                  0.8         0.1324      0.004722           0.1406   \n",
       "  9                  0.9         0.0544      0.003782           0.0578   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.010747            0.820        0.048088           0.1584   \n",
       "  2         0.009407            0.635        0.041833           0.2838   \n",
       "  3         0.009550            0.450        0.030619           0.3596   \n",
       "  4         0.006656            0.315        0.028504           0.4666   \n",
       "  5         0.007596            0.190        0.028504           0.5588   \n",
       "  6         0.008643            0.105        0.032596           0.6540   \n",
       "  7         0.005050            0.045        0.011180           0.7708   \n",
       "  8         0.004561            0.025        0.017678           0.8676   \n",
       "  9         0.004147            0.010        0.013693           0.9456   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.008295             0.1570  ...          0.064711         0.7630   \n",
       "  2         0.010826             0.2780  ...          0.020917         0.7246   \n",
       "  3         0.008142             0.3452  ...          0.041833         0.8010   \n",
       "  4         0.007021             0.4506  ...          0.059687         0.8728   \n",
       "  5         0.005718             0.5402  ...          0.028504         0.9326   \n",
       "  6         0.009407             0.6358  ...          0.051841         0.9592   \n",
       "  7         0.004604             0.7570  ...          0.013693         0.9768   \n",
       "  8         0.004722             0.8594  ...          0.033541         0.9900   \n",
       "  9         0.003782             0.9422  ...          0.020917         0.9830   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.018111           0.7658        0.022376           0.7238   \n",
       "  2       0.015534           0.7306        0.015662           0.6438   \n",
       "  3       0.017248           0.8142        0.016362           0.6136   \n",
       "  4       0.017513           0.8902        0.017527           0.5956   \n",
       "  5       0.005225           0.9476        0.002881           0.6172   \n",
       "  6       0.007225           0.9694        0.004336           0.6552   \n",
       "  7       0.002683           0.9880        0.008337           0.5502   \n",
       "  8       0.016492           0.9974        0.005814           0.6000   \n",
       "  9       0.025159           0.9942        0.012969           0.3000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.058551                   0.1            0              0  \n",
       "  2         0.050371                   0.2            0              0  \n",
       "  3         0.048537                   0.3            0              0  \n",
       "  4         0.021790                   0.4            0              0  \n",
       "  5         0.113836                   0.5            0              0  \n",
       "  6         0.156744                   0.6            0              0  \n",
       "  7         0.182734                   0.7            0              0  \n",
       "  8         0.434677                   0.8            0              0  \n",
       "  9         0.447214                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8758      0.005263           0.8786   \n",
       "  2                  0.2         0.7654      0.011781           0.7714   \n",
       "  3                  0.3         0.6766      0.008989           0.6866   \n",
       "  4                  0.4         0.5696      0.011524           0.5828   \n",
       "  5                  0.5         0.4652      0.010354           0.4820   \n",
       "  6                  0.6         0.3604      0.010807           0.3762   \n",
       "  7                  0.7         0.2634      0.010714           0.2792   \n",
       "  8                  0.8         0.1810      0.006325           0.1914   \n",
       "  9                  0.9         0.0860      0.007483           0.0900   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004450           0.8388        0.041161           0.1242   \n",
       "  2         0.008849           0.6888        0.049585           0.2346   \n",
       "  3         0.009127           0.5502        0.041161           0.3234   \n",
       "  4         0.009985           0.3944        0.053496           0.4304   \n",
       "  5         0.008337           0.2498        0.048065           0.5348   \n",
       "  6         0.011476           0.1556        0.050535           0.6396   \n",
       "  7         0.010281           0.0614        0.030262           0.7366   \n",
       "  8         0.007021           0.0504        0.012522           0.8190   \n",
       "  9         0.008155           0.0280        0.000000           0.9140   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.005263             0.1214  ...          0.078666         0.8088   \n",
       "  2         0.011781             0.2286  ...          0.030262         0.7556   \n",
       "  3         0.008989             0.3134  ...          0.064049         0.8090   \n",
       "  4         0.011524             0.4172  ...          0.036010         0.8562   \n",
       "  5         0.010354             0.5180  ...          0.042464         0.9126   \n",
       "  6         0.010807             0.6238  ...          0.053496         0.9636   \n",
       "  7         0.010714             0.7208  ...          0.031575         0.9820   \n",
       "  8         0.006325             0.8086  ...          0.012075         0.9892   \n",
       "  9         0.007483             0.9100  ...          0.012522         0.9948   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.008289           0.8128        0.007823           0.7604   \n",
       "  2       0.009072           0.7612        0.006834           0.6840   \n",
       "  3       0.019558           0.8172        0.021638           0.6934   \n",
       "  4       0.012911           0.8682        0.017427           0.6814   \n",
       "  5       0.011393           0.9262        0.010545           0.6718   \n",
       "  6       0.007021           0.9798        0.004919           0.6288   \n",
       "  7       0.009220           0.9922        0.005675           0.5934   \n",
       "  8       0.007791           0.9932        0.006221           0.8334   \n",
       "  9       0.011628           1.0000        0.000000           0.9000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.043160                   0.1            0              0  \n",
       "  2         0.043081                   0.2            0              0  \n",
       "  3         0.035592                   0.3            0              0  \n",
       "  4         0.067356                   0.4            0              0  \n",
       "  5         0.095072                   0.5            0              0  \n",
       "  6         0.121420                   0.6            0              0  \n",
       "  7         0.136264                   0.7            0              0  \n",
       "  8         0.235643                   0.8            0              0  \n",
       "  9         0.223607                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8586      0.010945           0.8404   \n",
       "  2                  0.2         0.7090      0.005099           0.6816   \n",
       "  3                  0.3         0.5888      0.008075           0.5676   \n",
       "  4                  0.4         0.5058      0.005495           0.5056   \n",
       "  5                  0.5         0.4306      0.010407           0.4474   \n",
       "  6                  0.6         0.3462      0.008167           0.3580   \n",
       "  7                  0.7         0.2382      0.012988           0.2504   \n",
       "  8                  0.8         0.1304      0.011929           0.1394   \n",
       "  9                  0.9         0.0570      0.009772           0.0544   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.012054           0.9484        0.012542           0.1414   \n",
       "  2         0.005595           0.8404        0.009685           0.2910   \n",
       "  3         0.007668           0.6922        0.013027           0.4112   \n",
       "  4         0.006986           0.5058        0.015912           0.4942   \n",
       "  5         0.015176           0.3506        0.021629           0.5694   \n",
       "  6         0.014748           0.2900        0.031353           0.6538   \n",
       "  7         0.018379           0.1798        0.026224           0.7618   \n",
       "  8         0.010597           0.0854        0.020342           0.8696   \n",
       "  9         0.010139           0.0698        0.021603           0.9430   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.010945             0.1596  ...          0.009203         0.7612   \n",
       "  2         0.005099             0.3184  ...          0.035076         0.6904   \n",
       "  3         0.008075             0.4324  ...          0.012542         0.7278   \n",
       "  4         0.005495             0.4944  ...          0.009685         0.7998   \n",
       "  5         0.010407             0.5526  ...          0.014765         0.8424   \n",
       "  6         0.008167             0.6420  ...          0.032929         0.8854   \n",
       "  7         0.012988             0.7496  ...          0.033306         0.9000   \n",
       "  8         0.011929             0.8606  ...          0.012050         0.8942   \n",
       "  9         0.009772             0.9456  ...          0.017146         0.8690   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.010085           0.7274        0.008820           0.9162   \n",
       "  2       0.006148           0.6612        0.007362           0.8318   \n",
       "  3       0.007328           0.7026        0.008385           0.8506   \n",
       "  4       0.016392           0.7880        0.017277           0.8620   \n",
       "  5       0.006504           0.8380        0.007810           0.8714   \n",
       "  6       0.012157           0.8798        0.010803           0.9214   \n",
       "  7       0.012923           0.8970        0.016171           0.9232   \n",
       "  8       0.027851           0.8910        0.020384           0.9178   \n",
       "  9       0.024073           0.8462        0.026033           0.9500   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.019892                   0.1            0              0  \n",
       "  2         0.007259                   0.2            0              0  \n",
       "  3         0.014381                   0.3            0              0  \n",
       "  4         0.024860                   0.4            0              0  \n",
       "  5         0.038266                   0.5            0              0  \n",
       "  6         0.030640                   0.6            0              0  \n",
       "  7         0.053369                   0.7            0              0  \n",
       "  8         0.126132                   0.8            0              0  \n",
       "  9         0.111803                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8968      0.012458           0.8978   \n",
       "  2                  0.2         0.8116      0.011908           0.8168   \n",
       "  3                  0.3         0.6884      0.015915           0.6984   \n",
       "  4                  0.4         0.5798      0.011713           0.5880   \n",
       "  5                  0.5         0.4564      0.009940           0.4632   \n",
       "  6                  0.6         0.3434      0.019616           0.3484   \n",
       "  7                  0.7         0.2436      0.019139           0.2470   \n",
       "  8                  0.8         0.1550      0.006856           0.1570   \n",
       "  9                  0.9         0.0714      0.007436           0.0726   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.012174            0.850        0.055902           0.1032   \n",
       "  2         0.010780            0.475        0.185405           0.1884   \n",
       "  3         0.015915            0.000        0.000000           0.3116   \n",
       "  4         0.012000            0.000        0.000000           0.4202   \n",
       "  5         0.010010            0.000        0.000000           0.5436   \n",
       "  6         0.020281            0.000        0.000000           0.6566   \n",
       "  7         0.018960            0.000        0.000000           0.7564   \n",
       "  8         0.006856            0.000        0.000000           0.8450   \n",
       "  9         0.008173            0.000        0.000000           0.9286   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.012458             0.1022  ...          0.055902         0.8126   \n",
       "  2         0.011908             0.1832  ...          0.055902         0.8302   \n",
       "  3         0.015915             0.3016  ...          0.142522         0.9750   \n",
       "  4         0.011713             0.4120  ...          0.088388         0.9894   \n",
       "  5         0.009940             0.5368  ...          0.104583         0.9904   \n",
       "  6         0.019616             0.6516  ...          0.068465         0.9968   \n",
       "  7         0.019139             0.7530  ...          0.000000         1.0000   \n",
       "  8         0.006856             0.8430  ...          0.000000         1.0000   \n",
       "  9         0.007436             0.9274  ...          0.000000         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.022244           0.8148        0.022421           0.6168   \n",
       "  2       0.029269           0.8350        0.030757           0.4716   \n",
       "  3       0.006042           0.9814        0.006986           0.0000   \n",
       "  4       0.003912           0.9958        0.001643           0.0000   \n",
       "  5       0.004561           0.9976        0.002191           0.0000   \n",
       "  6       0.002950           1.0000        0.000000           0.0000   \n",
       "  7       0.000000           1.0000        0.000000           0.0000   \n",
       "  8       0.000000           1.0000        0.000000           0.0000   \n",
       "  9       0.000000           1.0000        0.000000           0.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.162669                   0.1            0              0  \n",
       "  2         0.156238                   0.2            0              0  \n",
       "  3         0.000000                   0.3            0              0  \n",
       "  4         0.000000                   0.4            0              0  \n",
       "  5         0.000000                   0.5            0              0  \n",
       "  6         0.000000                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8652      0.004438           0.8532   \n",
       "  2                  0.2         0.7160      0.004848           0.6960   \n",
       "  3                  0.3         0.6398      0.009418           0.6306   \n",
       "  4                  0.4         0.5306      0.009990           0.5292   \n",
       "  5                  0.5         0.4160      0.006928           0.4286   \n",
       "  6                  0.6         0.3210      0.011576           0.3368   \n",
       "  7                  0.7         0.2256      0.009990           0.2390   \n",
       "  8                  0.8         0.1440      0.011916           0.1484   \n",
       "  9                  0.9         0.0674      0.008961           0.0662   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005215           0.9524        0.015962           0.1348   \n",
       "  2         0.008000           0.8590        0.032833           0.2840   \n",
       "  3         0.010286           0.7012        0.031925           0.3602   \n",
       "  4         0.009445           0.5434        0.030672           0.4694   \n",
       "  5         0.011082           0.3270        0.060934           0.5840   \n",
       "  6         0.013312           0.2082        0.020765           0.6790   \n",
       "  7         0.011045           0.1298        0.018254           0.7744   \n",
       "  8         0.014100           0.1102        0.011713           0.8560   \n",
       "  9         0.008786           0.0732        0.012194           0.9326   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.004438             0.1468  ...          0.032230         0.8260   \n",
       "  2         0.004848             0.3040  ...          0.027779         0.8072   \n",
       "  3         0.009418             0.3694  ...          0.021696         0.8706   \n",
       "  4         0.009990             0.4708  ...          0.031153         0.9096   \n",
       "  5         0.006928             0.5714  ...          0.055171         0.9344   \n",
       "  6         0.011576             0.6632  ...          0.015748         0.9568   \n",
       "  7         0.009990             0.7610  ...          0.018254         0.9602   \n",
       "  8         0.011916             0.8516  ...          0.012522         0.9550   \n",
       "  9         0.008961             0.9338  ...          0.016447         0.9438   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.006964           0.8070        0.008367           0.9452   \n",
       "  2       0.010281           0.7888        0.012988           0.9328   \n",
       "  3       0.007635           0.8616        0.008849           0.9320   \n",
       "  4       0.004099           0.9040        0.004528           0.9504   \n",
       "  5       0.010164           0.9338        0.013442           0.9400   \n",
       "  6       0.008758           0.9608        0.011946           0.9124   \n",
       "  7       0.009576           0.9650        0.010173           0.9004   \n",
       "  8       0.017607           0.9578        0.017254           0.9306   \n",
       "  9       0.020560           0.9404        0.022766           0.9714   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.017441                   0.1            0              0  \n",
       "  2         0.017754                   0.2            0              0  \n",
       "  3         0.018507                   0.3            0              0  \n",
       "  4         0.002608                   0.4            0              0  \n",
       "  5         0.030389                   0.5            0              0  \n",
       "  6         0.037978                   0.6            0              0  \n",
       "  7         0.014724                   0.7            0              0  \n",
       "  8         0.063611                   0.8            0              0  \n",
       "  9         0.063952                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8738      0.012235           0.8724   \n",
       "  2                  0.2         0.7974      0.016149           0.7996   \n",
       "  3                  0.3         0.6766      0.015915           0.6810   \n",
       "  4                  0.4         0.5586      0.015773           0.5658   \n",
       "  5                  0.5         0.4532      0.016932           0.4630   \n",
       "  6                  0.6         0.3460      0.017819           0.3522   \n",
       "  7                  0.7         0.2384      0.020403           0.2422   \n",
       "  8                  0.8         0.1398      0.014377           0.1420   \n",
       "  9                  0.9         0.0590      0.011247           0.0590   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.012075             0.90        0.035355           0.1262   \n",
       "  2         0.016562             0.74        0.022361           0.2026   \n",
       "  3         0.015748             0.55        0.035355           0.3234   \n",
       "  4         0.016514             0.36        0.041833           0.4414   \n",
       "  5         0.017635             0.19        0.022361           0.5468   \n",
       "  6         0.018102             0.18        0.044721           0.6540   \n",
       "  7         0.022421             0.13        0.044721           0.7616   \n",
       "  8         0.014950             0.08        0.027386           0.8602   \n",
       "  9         0.012629             0.05        0.035355           0.9410   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.012235             0.1276  ...          0.027386         0.6812   \n",
       "  2         0.016149             0.2004  ...          0.035355         0.7470   \n",
       "  3         0.015915             0.3190  ...          0.057009         0.7966   \n",
       "  4         0.015773             0.4342  ...          0.065192         0.9258   \n",
       "  5         0.016932             0.5370  ...          0.057009         0.9718   \n",
       "  6         0.017819             0.6478  ...          0.041833         0.9780   \n",
       "  7         0.020403             0.7578  ...          0.075829         0.9736   \n",
       "  8         0.014377             0.8580  ...          0.057009         0.9896   \n",
       "  9         0.011247             0.9410  ...          0.035355         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.039252           0.6718        0.039890           0.8422   \n",
       "  2       0.015199           0.7492        0.015547           0.6946   \n",
       "  3       0.011104           0.8032        0.010941           0.6260   \n",
       "  4       0.015928           0.9370        0.017132           0.6116   \n",
       "  5       0.005215           0.9860        0.003937           0.5030   \n",
       "  6       0.003742           0.9908        0.002387           0.5752   \n",
       "  7       0.010040           0.9878        0.007014           0.5676   \n",
       "  8       0.011887           1.0000        0.000000           0.7334   \n",
       "  9       0.000000           1.0000        0.000000           0.8000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.052599                   0.1            0              0  \n",
       "  2         0.017286                   0.2            0              0  \n",
       "  3         0.037993                   0.3            0              0  \n",
       "  4         0.057208                   0.4            0              0  \n",
       "  5         0.045089                   0.5            0              0  \n",
       "  6         0.109070                   0.6            0              0  \n",
       "  7         0.070854                   0.7            0              0  \n",
       "  8         0.252741                   0.8            0              0  \n",
       "  9         0.447214                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8510      0.007246           0.8426   \n",
       "  2                  0.2         0.7694      0.009788           0.7636   \n",
       "  3                  0.3         0.6598      0.014940           0.6536   \n",
       "  4                  0.4         0.5528      0.011883           0.5510   \n",
       "  5                  0.5         0.4450      0.012708           0.4502   \n",
       "  6                  0.6         0.3434      0.014960           0.3494   \n",
       "  7                  0.7         0.2424      0.006189           0.2484   \n",
       "  8                  0.8         0.1352      0.006648           0.1406   \n",
       "  9                  0.9         0.0550      0.007517           0.0568   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008325           0.9936        0.014311           0.1490   \n",
       "  2         0.011415           0.8772        0.052917           0.2306   \n",
       "  3         0.018036           0.7614        0.053905           0.3402   \n",
       "  4         0.013134           0.5806        0.060401           0.4472   \n",
       "  5         0.013142           0.3550        0.022627           0.5550   \n",
       "  6         0.014293           0.2386        0.058462           0.6566   \n",
       "  7         0.007162           0.1420        0.053935           0.7576   \n",
       "  8         0.006066           0.0388        0.027253           0.8648   \n",
       "  9         0.009203           0.0258        0.027133           0.9450   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007246             0.1574  ...          0.039601         0.6890   \n",
       "  2         0.009788             0.2364  ...          0.082369         0.7200   \n",
       "  3         0.014940             0.3464  ...          0.036837         0.7488   \n",
       "  4         0.011883             0.4490  ...          0.062816         0.8164   \n",
       "  5         0.012708             0.5498  ...          0.018075         0.8906   \n",
       "  6         0.014960             0.6506  ...          0.057552         0.9542   \n",
       "  7         0.006189             0.7516  ...          0.053935         0.9858   \n",
       "  8         0.006648             0.8594  ...          0.027253         0.9950   \n",
       "  9         0.007517             0.9432  ...          0.027133         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.029917           0.6654        0.034631           0.9900   \n",
       "  2       0.018398           0.7114        0.022656           0.8610   \n",
       "  3       0.021359           0.7436        0.024317           0.8306   \n",
       "  4       0.019870           0.8148        0.023531           0.8428   \n",
       "  5       0.023575           0.8940        0.024536           0.8208   \n",
       "  6       0.016285           0.9542        0.014721           0.9466   \n",
       "  7       0.010085           0.9854        0.010621           1.0000   \n",
       "  8       0.006856           0.9948        0.007120           0.8000   \n",
       "  9       0.000000           1.0000        0.000000           0.6000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.022361                   0.1            0              0  \n",
       "  2         0.055826                   0.2            0              0  \n",
       "  3         0.032639                   0.3            0              0  \n",
       "  4         0.065542                   0.4            0              0  \n",
       "  5         0.040233                   0.5            0              0  \n",
       "  6         0.076862                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.447214                   0.8            0              0  \n",
       "  9         0.547723                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns]]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rmsd's for all endpoints over all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_original\n",
      "pred_score_original\n",
      "pred_test_original\n",
      "pred_score_scp\n",
      "pred_score_calupdate\n",
      "pred_score_calupdate2\n",
      "cv_trainupdate\n",
      "pred_score_trainupdate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv_original': [0.012,\n",
       "  0.022,\n",
       "  0.03,\n",
       "  0.019,\n",
       "  0.011,\n",
       "  0.012,\n",
       "  0.013,\n",
       "  0.016,\n",
       "  0.018,\n",
       "  0.015,\n",
       "  0.018,\n",
       "  0.015],\n",
       " 'pred_score_original': [0.06,\n",
       "  0.047,\n",
       "  0.041,\n",
       "  0.045,\n",
       "  0.034,\n",
       "  0.069,\n",
       "  0.029,\n",
       "  0.079,\n",
       "  0.039,\n",
       "  0.069,\n",
       "  0.056,\n",
       "  0.054],\n",
       " 'pred_test_original': [],\n",
       " 'pred_score_scp': [0.057,\n",
       "  0.024,\n",
       "  0.031,\n",
       "  0.04,\n",
       "  0.024,\n",
       "  0.063,\n",
       "  0.033,\n",
       "  0.067,\n",
       "  0.022,\n",
       "  0.064,\n",
       "  0.024,\n",
       "  0.034],\n",
       " 'pred_score_calupdate': [0.016,\n",
       "  0.059,\n",
       "  0.064,\n",
       "  0.058,\n",
       "  0.043,\n",
       "  0.067,\n",
       "  0.042,\n",
       "  0.036,\n",
       "  0.061,\n",
       "  0.064,\n",
       "  0.045,\n",
       "  0.026],\n",
       " 'pred_score_calupdate2': [0.015,\n",
       "  0.016,\n",
       "  0.027,\n",
       "  0.015,\n",
       "  0.013,\n",
       "  0.025,\n",
       "  0.023,\n",
       "  0.015,\n",
       "  0.019,\n",
       "  0.022,\n",
       "  0.021,\n",
       "  0.021],\n",
       " 'cv_trainupdate': [0.012,\n",
       "  0.023,\n",
       "  0.028,\n",
       "  0.022,\n",
       "  0.013,\n",
       "  0.015,\n",
       "  0.012,\n",
       "  0.017,\n",
       "  0.018,\n",
       "  0.018,\n",
       "  0.018,\n",
       "  0.013],\n",
       " 'pred_score_trainupdate': [0.065,\n",
       "  0.04,\n",
       "  0.033,\n",
       "  0.037,\n",
       "  0.023,\n",
       "  0.058,\n",
       "  0.027,\n",
       "  0.067,\n",
       "  0.033,\n",
       "  0.06,\n",
       "  0.039,\n",
       "  0.046]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsds = {}\n",
    "for k, v in evaluation_dfs.items():\n",
    "    print(k)\n",
    "    rmsds[k] = []\n",
    "    for df in v:\n",
    "        \n",
    "        rmsd = calculate_rmsd_from_df(df)\n",
    "        rmsds[k].append(rmsd)\n",
    "rmsds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rmsd_pos's for all endpoints over all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_original\n",
      "pred_score_original\n",
      "pred_test_original\n",
      "pred_score_scp\n",
      "pred_score_calupdate\n",
      "pred_score_calupdate2\n",
      "cv_trainupdate\n",
      "pred_score_trainupdate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv_original': [0.01,\n",
       "  0.019,\n",
       "  0.028,\n",
       "  0.014,\n",
       "  0.009,\n",
       "  0.008,\n",
       "  0.012,\n",
       "  0.013,\n",
       "  0.016,\n",
       "  0.011,\n",
       "  0.016,\n",
       "  0.013],\n",
       " 'pred_score_original': [0.06,\n",
       "  0.047,\n",
       "  0.041,\n",
       "  0.045,\n",
       "  0.034,\n",
       "  0.069,\n",
       "  0.029,\n",
       "  0.079,\n",
       "  0.039,\n",
       "  0.069,\n",
       "  0.056,\n",
       "  0.054],\n",
       " 'pred_test_original': [],\n",
       " 'pred_score_scp': [0.057,\n",
       "  0.024,\n",
       "  0.031,\n",
       "  0.04,\n",
       "  0.024,\n",
       "  0.063,\n",
       "  0.032,\n",
       "  0.067,\n",
       "  0.022,\n",
       "  0.064,\n",
       "  0.024,\n",
       "  0.034],\n",
       " 'pred_score_calupdate': [0.0,\n",
       "  0.008,\n",
       "  0.004,\n",
       "  0.052,\n",
       "  0.022,\n",
       "  0.0,\n",
       "  0.027,\n",
       "  0.026,\n",
       "  0.0,\n",
       "  0.009,\n",
       "  0.004,\n",
       "  0.003],\n",
       " 'pred_score_calupdate2': [0.013,\n",
       "  0.015,\n",
       "  0.02,\n",
       "  0.015,\n",
       "  0.003,\n",
       "  0.025,\n",
       "  0.023,\n",
       "  0.011,\n",
       "  0.018,\n",
       "  0.02,\n",
       "  0.017,\n",
       "  0.02],\n",
       " 'cv_trainupdate': [0.009,\n",
       "  0.018,\n",
       "  0.025,\n",
       "  0.017,\n",
       "  0.009,\n",
       "  0.008,\n",
       "  0.01,\n",
       "  0.013,\n",
       "  0.014,\n",
       "  0.011,\n",
       "  0.014,\n",
       "  0.011],\n",
       " 'pred_score_trainupdate': [0.065,\n",
       "  0.04,\n",
       "  0.032,\n",
       "  0.037,\n",
       "  0.023,\n",
       "  0.058,\n",
       "  0.027,\n",
       "  0.067,\n",
       "  0.033,\n",
       "  0.06,\n",
       "  0.039,\n",
       "  0.046]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsds_pos = {}\n",
    "for k, v in evaluation_dfs.items():\n",
    "    print(k)\n",
    "    rmsds_pos[k] = []\n",
    "    for df in v:\n",
    "        rmsd_pos = calculate_rmsd_pos_from_df(df)\n",
    "        rmsds_pos[k].append(rmsd_pos)\n",
    "rmsds_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\"cv_original\", \"pred_score_original\", \"pred_score_scp\",\n",
    "#               \"cv_trainupdate\",\n",
    "              \"pred_score_trainupdate\",\n",
    "              \"pred_score_calupdate\", \"pred_score_calupdate2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot_rmsd(rmsds, \"rmsd\", strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot_rmsd(rmsds_pos, \"rmsd_pos\", strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_rmsd(rmsds, rmsd_title, strategies=None):\n",
    "    if strategies is None:\n",
    "        strategies = [\"cv_original\", \"pred_score_original\", \"pred_score_trainupdate\",\n",
    "              \"pred_score_calupdate\", \"pred_score_calupdate2\"]\n",
    "    \"\"\"\n",
    "    Generate a boxplot with the rmsd values over multiple endpoints.\n",
    "    This function can be used to plot both rmsd or rmsd_pos values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    strategies : strategies or set-ups used when making the predictions (e.g. \"original_cv\")\n",
    "    rmsds : a dictionary with the strategies as keys and a list of rmsd values for all the\n",
    "        endpoints as values\n",
    "    rmsd_title : the naming for 'rmsd' which should be used in the plot title, e.g. \"rmsd\", \"rmsd_pos\"\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    for s in strategies:\n",
    "        plt.scatter([rmsds[k] for k in strategies], s)#, labels=strategies)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.title(f\"{rmsd_title} over all endpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot(rmsds, strategies, colours=None, markers=None):\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(10,20))\n",
    "    if colours is None:\n",
    "        colours = ['navy', 'royalblue', 'blueviolet', 'plum', 'mediumvioletred', 'red', 'coral', 'gold', 'yellowgreen', 'green', 'paleturquoise', 'slategrey']\n",
    "    if markers is None:\n",
    "        markers = ['3', '<', '>', 'x', 's', '+', 'd', 'h', '*', '1', 'o', 'D']\n",
    "    for i, ep in enumerate(endpoints):\n",
    "    \n",
    "        plt.plot(strategies, [rmsds[s][i] for s in strategies], color=colours[i], linewidth=0.5)#, marker='-o')\n",
    "        plt.scatter(strategies, [rmsds[s][i] for s in strategies], label=ep, color=colours[i], marker=markers[i], s=50)\n",
    "        plt.xticks(rotation='vertical')\n",
    "        plt.legend(endpoints, loc='upper right')#, bbox_to_anchor=(1, 0.5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_plot(rmsds, strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_plot(rmsds_pos, strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
