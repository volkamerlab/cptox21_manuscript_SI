{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook to perform experiments and evaluate all endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the supporting information to the manuscript entitled \"Conformal Prediction and \n",
    "Exchangeability in Toxicological In Vitro Datasets (title tbd)\". The script was developed by Andrea Morger in the \n",
    "In Silico Toxicology and Structural Biology Group of Prof. Dr. Andrea Volkamer at the Charité Universitätsmedizin \n",
    "Berlin, in collaboration with Fredrik Svensson, Ulf Norinder and Ola Spjuth. It was last updated in September 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, it is shown how the experiments for the CPTox21 manuscript (train model and make predictions with Tox21 data, update the training and/or calibration set) are run for multiple endpoints. Furthermore the evaluation over all enpoints in the form of boxplots is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook consists of three main parts.\n",
    "\n",
    "1. Preparation\n",
    "    - Used Python libraries are loades\n",
    "    - Paths and parameters are defined\n",
    "2. Conformal prediction experiments\n",
    "    - Prepare experiments\n",
    "    - Run experiments\n",
    "3. Evaluate conformal predictions\n",
    "    - Calibration plots\n",
    "    - Calculate rmsds\n",
    "    - Generate boxplots\n",
    "    - Line plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "1. [Preparation](#preparation) <br>\n",
    "    1.1. [Import libraries and modules](#import-libraries-and-modules)<br>\n",
    "    1.2. [Define paths and parameters](#define-paths-parameters)<br>\n",
    "2. [Conformal prediction experiments](#cp-experiments)<br>\n",
    "    2.1. [Build conformal predictors](#build-cps)<br>\n",
    "    2.2. [Perform experiments for all endpoints](#perform-exp)<br>\n",
    "3. [Evaluate conformal predictions](#evaluate-cp)<br>\n",
    "    3.1. [Calibration plots](#cal-plots)<br>\n",
    "    3.2. [rmsd's](#rmsds)<br>\n",
    "    3.3. [Boxplots](#boxplots)<br>\n",
    "    3.4. [Line plots](#line-plots)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation\n",
    "### 1.1. Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from nonconformist.nc import NcFactory, MarginErrFunc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cptox21 import (\n",
    "    define_path, load_signatures_files, InductiveConformalPredictor,\n",
    "    CPTox21AggregatedConformalPredictor, AggregatedConformalPredictor, \n",
    "    StratifiedRatioSampler, CrossValidationSampler, KnownIndicesSampler,\n",
    "    CPTox21CrossValidator, CPTox21TrainUpdateCrossValidator,\n",
    "    calculate_rmsd_from_df, calculate_rmsd_pos_from_df\n",
    ")\n",
    "from helper_functions import (load_data, cross_validate_compare_calibration_sets, \n",
    "                              cross_validate_with_updated_training_set, boxplot_rmsd,\n",
    "                             draw_calibration_plot_all_endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_signatures_path = \"../data/data_signatures/\"\n",
    "data_statistics_path = \"../data/data_statistics/\"  # Use data from this directory\n",
    "# data_statistics_path = \"../../../KT-ER/cptox21_pipeline/data/data_curta_200909/\"  # Use data created on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define if model fitting and predictions are required (set to True) or if data are already\n",
    "# available (set to False).\n",
    "run_experiment = True  # False  # True\n",
    "# If we do a test run (test_run is True, we can train with a much smaller training \n",
    "# set (n=500), which will result in faster calculations). Could be deleted for final notebook.\n",
    "test_run = True  # False\n",
    "set_random_state = None  # To make the data reproducible, a random state can be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_folds_acp = 3# 10\n",
    "n_cv = 2 # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = ['SR_ATAD5', 'NR_ER']\n",
    "# endpoints = [\n",
    "#     'SR_ATAD5', 'NR_ER', 'NR_AR', 'SR_HSE', 'SR_MMP', 'SR_p53', 'NR_Aromatase',\n",
    "#     'SR_ARE', 'NR_AR_LBD', 'NR_AhR', 'NR_ER_LBD', 'NR_PPAR_gamma'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conformal prediction experiments\n",
    "### 2.1. Build conformal predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ICP\n",
    "clf = SVC(kernel='rbf', C=50, gamma=0.002, probability=True, random_state=set_random_state)\n",
    "error_function = MarginErrFunc()\n",
    "normaliser_model = None\n",
    "nc = NcFactory.create_nc(clf, err_func=error_function)\n",
    "icp = InductiveConformalPredictor(\n",
    "    nc_function=nc, condition=(lambda instance: instance[1])\n",
    ")  # Mondrian as (default) condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ACP (uses original and updated calibration sets)\n",
    "acp = CPTox21AggregatedConformalPredictor(\n",
    "        predictor=icp, sampler=StratifiedRatioSampler(n_folds=n_folds_acp, random_state=set_random_state),\n",
    "        aggregation_func=np.median\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ACP (accepts only one calibration set, used with updated training set)\n",
    "train_update_acp = AggregatedConformalPredictor(\n",
    "        predictor=icp, sampler=StratifiedRatioSampler(n_folds=n_folds_acp, random_state=set_random_state),\n",
    "        aggregation_func=np.median\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Perform experiments for all endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR_ATAD5\n",
      "len score 295 295\n",
      "len score 295 295\n",
      "NR_ER\n",
      "len score 245 245\n"
     ]
    }
   ],
   "source": [
    "evaluation_dfs = {\"cv\": [],\n",
    "                  \"pred_score\": [],\n",
    "#                   \"pred_score_scp\": [],  # Uncomment if SCP results are available\n",
    "                 \"cal_update\": [], \"cal_update2\": [],\n",
    "                  \"cv_train_update\": [], \"pred_score_train_update\": []}\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint)\n",
    "    if run_experiment: # If we want to make calculations for all set-ups\n",
    "        \n",
    "        # Load data\n",
    "        X_train, y_train, X_test, y_test, X_score, y_score = load_data(\n",
    "            endpoint, data_signatures_path=data_signatures_path, short_train=True\n",
    "        )\n",
    "        \n",
    "        # Cross-validate with different calibration sets\n",
    "        cptox21_cross_validator = cross_validate_compare_calibration_sets(\n",
    "            endpoint, acp, X_train, y_train, X_test, y_test, X_score, y_score, n_cv=n_cv, \n",
    "            random_state=set_random_state\n",
    "        )\n",
    "        \n",
    "        # Store dataframes with evaluation measures per set-up\n",
    "        \n",
    "        for strategy in [\"cv\", \"pred_score\", \"cal_update\", \"cal_update2\"]:\n",
    "            evaluation_dfs[strategy].append(getattr(cptox21_cross_validator, f\"averaged_evaluation_df_{strategy}\"))\n",
    "                    \n",
    "        for strategy in [\"cv\", \"pred_score\", \"pred_test\", \"cal_update\", \"cal_update2\"]:\n",
    "            (getattr(cptox21_cross_validator, f\"averaged_evaluation_df_{strategy}\")).to_csv(\n",
    "                f\"{data_statistics_path}{endpoint}_averaged_eval_df_{strategy}.csv\"\n",
    "            )\n",
    "        \n",
    "        # Get train and test indices from cptox21_cross_validator, to use same indices for train_update\n",
    "        train_index, test_index = cptox21_cross_validator.train_indices, cptox21_cross_validator.test_indices\n",
    "        known_indices_sampler = KnownIndicesSampler(\n",
    "            known_train=train_index, known_test=test_index\n",
    "        )\n",
    "\n",
    "        # Cross-validate with updated training set\n",
    "        train_update_cross_validator = cross_validate_with_updated_training_set(\n",
    "            endpoint, train_update_acp, X_train, y_train, X_test, y_test, X_score, y_score, known_indices_sampler\n",
    "        )\n",
    "        \n",
    "        # Store dataframes with evaluation measures per set-up\n",
    "        for strategy in [\"cv\", \"pred_score\"]:\n",
    "            evaluation_dfs[f\"{strategy}_train_update\"].append(\n",
    "                getattr(train_update_cross_validator, f\"averaged_evaluation_df_{strategy}\")\n",
    "            )\n",
    "\n",
    "        for strategy in [\"cv\", \"pred_score\"]:\n",
    "            (getattr(train_update_cross_validator, f\"averaged_evaluation_df_{strategy}\")).to_csv(\n",
    "                f\"{data_statistics_path}{endpoint}_averaged_eval_df_{strategy}_train_update.csv\"\n",
    "            )\n",
    "            \n",
    "        \n",
    "    else: # If results are already available and dataframes can be loaded directly\n",
    "        \n",
    "        for strategy in [\"cv\", \"pred_score\", \"cal_update\", \"cal_update2\"]:  # , \"pred_score_scp\"]:  \n",
    "            # Uncomment if SCP data are available\n",
    "            evaluation_dfs[strategy].append(\n",
    "                pd.read_csv(f\"{data_statistics_path}{endpoint}_averaged_eval_df_{strategy}.csv\")\n",
    "            )\n",
    "        \n",
    "        for strategy in [\"cv\", \"pred_score\"]:\n",
    "            evaluation_dfs[f\"{strategy}_train_update\"].append(\n",
    "                pd.read_csv(f\"{data_statistics_path}{endpoint}_averaged_eval_df_{strategy}_train_update.csv\")\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate conformal predictions\n",
    "### 3.1. Calibration plots\n",
    "Using the function `draw_calibration_plot_all_endpoints`, one could see the calibration plots for all 12 endpoints. Change `strategy` to `cv`, `pred_score`, `pred_test`, `cal_update`, `train_update` etc. depending, on which conformal prediction set-up you would like to visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_calibration_plot_all_endpoints(endpoints=endpoints, strategy='cv', path=data_statistics_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. rmsd's\n",
    "#### Calculate rmsd's for all endpoints over all strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a value to compare the calibration plots (validity) over all experiments, we calculate the rmsd of the observed error rate to the expected error rate (for 10 significance levels). If we accept overconservative validity, we can also calculate rmsd<sub>pos</sub> (todo: change term/name?), only considering the deviation where the observed error rate is higher than the expected error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsds = {}\n",
    "for k, v in evaluation_dfs.items():\n",
    "    rmsds[k] = []\n",
    "    for df in v:\n",
    "        \n",
    "        rmsd = calculate_rmsd_from_df(df)\n",
    "        rmsds[k].append(rmsd)\n",
    "\n",
    "pd.DataFrame(rmsds, index=endpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate rmsd<sub>pos</sub> 's for all endpoints over all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsds_pos = {}\n",
    "for k, v in evaluation_dfs.items():\n",
    "    rmsds_pos[k] = []\n",
    "    for df in v:\n",
    "        rmsd_pos = calculate_rmsd_pos_from_df(df)\n",
    "        rmsds_pos[k].append(rmsd_pos)\n",
    "pd.DataFrame(rmsds_pos, index=endpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the rmsd's per endpoint, we can draw a boxplot over the rmsd values for all endpoints. This gives us a nice overview on how the rmsd's change among the different CP set-ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\"cv\", \n",
    "              \"pred_score\",\n",
    "#               \"pred_score_scp\",  # Uncomment, if SCP data are available\n",
    "              \"pred_score_train_update\",\n",
    "              \"cal_update\", \n",
    "              \"cal_update2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_rmsd(rmsds, \"rmsd\", strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: more description here, \n",
    "1) on what we see, and \n",
    "2) on why we also consider rmsd pos. \n",
    "\n",
    "Description/discussion will be added here, once the statements of the paper are clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_rmsd(rmsds_pos, \"rmsd_pos\", strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Line plots\n",
    "To see how the rmsds change for the individual endpoints and detect possible \"outlier endpoints\", we can look at the following line plots.\n",
    "\n",
    "Note, that these plots were initially used for internal investigation, e.g. which endpoints should be selected as example in the manuscript. If unnecessary, the plots can be deleted from this SI notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot_rmsd(rmsds, strategies, colours=None, markers=None, figsize=(5, 10)):\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if colours is None:\n",
    "        colours = ['navy', 'royalblue', 'blueviolet', 'plum', 'mediumvioletred', 'red', 'coral', 'gold', 'yellowgreen', 'green', 'paleturquoise', 'slategrey']\n",
    "    if markers is None:\n",
    "        markers = ['3', '<', '>', 'x', 's', '+', 'd', 'h', '*', '1', 'o', 'D']\n",
    "    for i, ep in enumerate(endpoints):\n",
    "    \n",
    "        plt.plot(strategies, [rmsds[s][i] for s in strategies], color=colours[i], linewidth=0.5)#, marker='-o')\n",
    "        plt.scatter(strategies, [rmsds[s][i] for s in strategies], label=ep, color=colours[i], marker=markers[i], s=50)\n",
    "        plt.xticks(rotation='vertical')\n",
    "        plt.legend(endpoints, loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_rmsd(rmsds, strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_plot_rmsd(rmsds_pos, strategies, figsize=(10, 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
