{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPTox21: Conformal prediction and exchangeability in in vitro toxicological datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, it is shown how the experiments for the CPTox21 manuscript (train model and make predictions with Tox21 data, update the training and/or calibration set) are run for multiple endpoints. Furthermore the evaluation over all enpoints in the form of boxplots is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from nonconformist.nc import NcFactory, MarginErrFunc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cptox21 import (\n",
    "    define_path, load_signatures_files, InductiveConformalPredictor,\n",
    "    CPTox21AggregatedConformalPredictor, AggregatedConformalPredictor, \n",
    "    StratifiedRatioSampler, CrossValidationSampler, KnownIndicesSampler,\n",
    "    CPTox21CrossValidator, CPTox21TrainUpdateCrossValidator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    filename='test_logger.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO)\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.ERROR)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_signatures_path = \"../data/data_signatures/\"\n",
    "data_statistics_path = \"../data/data_statistics/\"\n",
    "data_statistics_path = \"../../../KT-ER/cptox21_pipeline/data/data_curta_200904/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define if model fitting and predictions are required (set to True) or if data are already\n",
    "# available (set to False)\n",
    "run_experiment = False #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_folds_acp = 3# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = [\n",
    "    'SR_ATAD5', 'NR_ER', 'NR_AR', 'SR_HSE', 'SR_MMP', 'SR_p53', 'NR_Aromatase',\n",
    "    'SR_ARE', 'NR_AR_LBD', 'NR_AhR', 'NR_ER_LBD', 'NR_PPAR_gamma'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(endpoint):\n",
    "    \"\"\"\n",
    "    Load signature datasets per endpoint\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    endpoint : endpoint for which the data should be loaded\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train : (signature) descriptors for Tox21train set\n",
    "    y_train : labels for Tox21train set\n",
    "    X_test : (signature) descriptors for Tox21test set\n",
    "    y_test : labels for Tox21test set\n",
    "    X_score : (signature) descriptors for Tox21score set\n",
    "    y_score : labels for Tox21score set\n",
    "    \n",
    "    \"\"\"\n",
    "    datasets = [\"train\", \"test\", \"score\"]\n",
    "    train_path = define_path(endpoint=endpoint, data=datasets[0], signatures_path=data_signatures_path)\n",
    "    test_path = define_path(endpoint=endpoint, data=datasets[1], signatures_path=data_signatures_path)\n",
    "    score_path = define_path(endpoint=endpoint, data=datasets[2], signatures_path=data_signatures_path)\n",
    "\n",
    "    X_train, y_train, X_test, y_test, X_score, y_score = load_signatures_files(train_path, test_path, score_path)\n",
    "    X_train = X_train[:500]\n",
    "    y_train = y_train[:500]\n",
    "    return X_train, y_train, X_test, y_test, X_score, y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_compare_calibration_sets(\n",
    "    endpoint, X_train, y_train, X_test, y_test, X_score, y_score\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform a crossvalidation, including the following settings:\n",
    "    * use original training and calibration set (Tox21train): predict internal test set (Tox21train)\n",
    "    * use original training and calibration set: predict score set (Tox21score)\n",
    "    * use original training and calibration set: predict test set (Tox21test)\n",
    "    * update calibration set with Tox21test: predict score set\n",
    "    * update calibration set with part of Tox21score: predict (other) part of Tox21score\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    endpoint : endpoint for which the data should be loaded\n",
    "    \n",
    "    X_train : (signature) descriptors for Tox21train set\n",
    "    y_train : labels for Tox21train set\n",
    "    X_test : (signature) descriptors for Tox21test set\n",
    "    y_test : labels for Tox21test set\n",
    "    X_score : (signature) descriptors for Tox21score set\n",
    "    y_score : labels for Tox21score set\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cross_validator : cross_validator class with fitted and calibrated models and evaluation dfs\n",
    "    \"\"\"\n",
    "    cross_validator = CPTox21CrossValidator(\n",
    "            acp, cv_splitter=CrossValidationSampler(),\n",
    "            score_splitter=StratifiedRatioSampler(test_ratio=0.5)\n",
    "        )\n",
    "    cross_validation_dfs = cross_validator.cross_validate(\n",
    "            steps=10,\n",
    "            endpoint=endpoint,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_update=X_test,\n",
    "            y_update=y_test,\n",
    "            X_score=X_score,\n",
    "            y_score=y_score,\n",
    "        )\n",
    "    return cross_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_with_updated_training_set(\n",
    "    endpoint, X_train, y_train, X_test, y_test, X_score, y_score, known_indices_sampler\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform a crossvalidation, including the following settings:\n",
    "    * update original training set (Tox21train) with Tox21test: predict internal test set (Tox21train & Tox21test)\n",
    "    * update original training set (Tox21train) with Tox21test: predict score set (Tox21score)\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    endpoint : endpoint for which the data should be loaded\n",
    "    \n",
    "    X_train : (signature) descriptors for Tox21train set\n",
    "    y_train : labels for Tox21train set\n",
    "    X_test : (signature) descriptors for Tox21test set\n",
    "    y_test : labels for Tox21test set\n",
    "    X_score : (signature) descriptors for Tox21score set\n",
    "    y_score : labels for Tox21score set\n",
    "    \n",
    "    known_indices_sampler: Sampler to split X_train and y_train in the same train and test sets\n",
    "    as used (known) for the previous experiments\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cross_validator : cross_validator class with fitted and calibrated models and evaluation dfs\n",
    "    \"\"\"\n",
    "    train_update_cross_validator = CPTox21TrainUpdateCrossValidator(\n",
    "    train_update_acp, cv_splitter=known_indices_sampler\n",
    ")\n",
    "\n",
    "    train_update_cross_validation_dfs = train_update_cross_validator.cross_validate(steps=10,\n",
    "                                           endpoint=endpoint,\n",
    "                                           X_train=X_train,\n",
    "                                           y_train=y_train,\n",
    "                                           X_update=X_test,\n",
    "                                           y_update=y_test,\n",
    "                                           X_score=X_score,\n",
    "                                           y_score=y_score,\n",
    "                                           class_wise_evaluation=False)\n",
    "    return train_update_cross_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deviation_square(error, sl):\n",
    "    \"\"\"\n",
    "    Calculate the square deviation between a given error value and a significance level\n",
    "    Parameters\n",
    "    ----------\n",
    "    error : error\n",
    "    sl : significance level\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    square deviation\n",
    "    \n",
    "    \"\"\"\n",
    "    return (error-sl)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmsd_from_df(eval_df, cl=None):\n",
    "    \"\"\"\n",
    "    Calculate the rmsd (root mean square deviation) for all error-significance level pairs\n",
    "    in a dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_df : dataframe for which the rmsd should be calculated\n",
    "    cl : class of compounds for which the rmsd should be calculated, i.e. 0 or 1\n",
    "    if cl is None, the overall rmsd for all compounds will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe with an additional 'rmsd' column\n",
    "    \n",
    "    \"\"\"\n",
    "    if cl:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_deviation_square(\n",
    "            row[f\"error_rate_{cl} mean\"],   row[\"significance_level\"]), axis=1)\n",
    "    else:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_deviation_square(\n",
    "            row[\"error_rate mean\"], row[\"significance_level\"]), axis=1)\n",
    "    rmsd = np.round(math.sqrt(np.mean(eval_df[\"square\"])), 3)\n",
    "    \n",
    "    return rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_deviation_square(error, sl):\n",
    "    \"\"\"\n",
    "    Calculate the square deviation between a given error value and a significance level\n",
    "    if the deviation is positive (>0)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    error : error\n",
    "    sl : significance level\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    square deviation or 0\n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "    if error > sl:\n",
    "        return (error-sl)**2\n",
    "    else:\n",
    "\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmsd_pos_from_df(eval_df, cl=None):\n",
    "    # fixme: exchange 'rmsd_pos' with a more appropriate term\n",
    "    \"\"\"\n",
    "    Calculate the rmsd (root mean square deviation) for all error-significance level pairs\n",
    "    in a dataframe if the deviation (error - significance level) is larger than 0\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eval_df : dataframe for which the rmsd_pos should be calculated\n",
    "    cl : class of compounds for which the rmsd_pos should be calculated, i.e. 0 or 1\n",
    "        if cl is None, the overall rmsd_pos for all compounds will be calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe with an additional 'rmsd_pos' column\n",
    "    \n",
    "    \"\"\"\n",
    "    if cl:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_pos_deviation_square(\n",
    "            row[f\"error_rate_{cl} mean\"],   row[\"significance_level\"]), axis=1)\n",
    "    else:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_pos_deviation_square(\n",
    "            row[\"error_rate mean\"], row[\"significance_level\"]), axis=1)\n",
    "    rmsd_pos = np.round(math.sqrt(np.mean(eval_df[\"square\"])), 3)\n",
    "    \n",
    "    return rmsd_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_rmsd(rmsds, rmsd_title, strategies=None):\n",
    "    if strategies is None:\n",
    "        strategies = [\"cv_original\", \"pred_score_original\", \"pred_score_trainupdate\",\n",
    "              \"pred_score_calupdate\", \"pred_score_calupdate2\"]\n",
    "    \"\"\"\n",
    "    Generate a boxplot with the rmsd values over multiple endpoints.\n",
    "    This function can be used to plot both rmsd or rmsd_pos values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    strategies : strategies or set-ups used when making the predictions (e.g. \"original_cv\")\n",
    "    rmsds : a dictionary with the strategies as keys and a list of rmsd values for all the\n",
    "        endpoints as values\n",
    "    rmsd_title : the naming for 'rmsd' which should be used in the plot title, e.g. \"rmsd\", \"rmsd_pos\"\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    plt.boxplot([rmsds[k] for k in strategies], labels=strategies)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.title(f\"{rmsd_title} over all endpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build conformal predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ICP\n",
    "clf = SVC(kernel='rbf', C=50, gamma=0.002, probability=True)\n",
    "error_function = MarginErrFunc()\n",
    "normaliser_model = None\n",
    "nc = NcFactory.create_nc(clf, err_func=error_function)\n",
    "icp = InductiveConformalPredictor(\n",
    "    nc_function=nc, condition=(lambda instance: instance[1])\n",
    ")  # Mondrian as (default) condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ACP (uses original and updated calibration sets)\n",
    "acp = CPTox21AggregatedConformalPredictor(\n",
    "        predictor=icp, sampler=StratifiedRatioSampler(n_folds=n_folds_acp),\n",
    "        aggregation_func=np.median\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ACP (accepts only one calibration set, used with updated training set)\n",
    "train_update_acp = AggregatedConformalPredictor(\n",
    "        predictor=icp, sampler=StratifiedRatioSampler(n_folds=n_folds_acp),\n",
    "        aggregation_func=np.median\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR_ATAD5\n",
      "NR_ER\n",
      "NR_AR\n",
      "SR_HSE\n",
      "SR_MMP\n",
      "SR_p53\n",
      "NR_Aromatase\n",
      "SR_ARE\n",
      "NR_AR_LBD\n",
      "NR_AhR\n",
      "NR_ER_LBD\n",
      "NR_PPAR_gamma\n"
     ]
    }
   ],
   "source": [
    "# fixme: alternatively, if models/predictions already fitted/made, we could load datasets \n",
    "# (instead of fitting/predicting everything again)\n",
    "\n",
    "evaluation_dfs = {\"cv_original\": [], \"pred_score_original\": [], \"pred_test_original\": [],\n",
    "                 \"pred_score_calupdate\": [], \"pred_score_calupdate2\": [],\n",
    "                  \"cv_trainupdate\": [], \"pred_score_trainupdate\": []}\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint)\n",
    "    if run_experiment: # If we want to make calculations for all set-ups\n",
    "        \n",
    "        X_train, y_train, X_test, y_test, X_score, y_score = load_data(endpoint)\n",
    "        cptox21_cross_validator = cross_validate_compare_calibration_sets(\n",
    "            endpoint, X_train, y_train, X_test, y_test, X_score, y_score\n",
    "        )\n",
    "\n",
    "        evaluation_dfs[\"cv_original\"].append(cptox21_cross_validator.averaged_evaluation_df_cv)\n",
    "        evaluation_dfs[\"pred_score_original\"].append(\n",
    "            cptox21_cross_validator.averaged_evaluation_df_pred_score\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_calupdate\"].append(\n",
    "            cptox21_cross_validator.averaged_evaluation_df_pred_cal_update\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_calupdate2\"].append(\n",
    "            cptox21_cross_validator.averaged_evaluation_df_pred_cal_update2\n",
    "        )\n",
    "        \n",
    "        cptox21_cross_validator.averaged_evaluation_df_cv.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_cv_original.csv\"\n",
    "        )\n",
    "        cptox21_cross_validator.averaged_evaluation_df_pred_score.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_score_original.csv\"\n",
    "        )\n",
    "        cptox21_cross_validator.averaged_evaluation_df_pred_test.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_test_original.csv\"\n",
    "        )\n",
    "        cptox21_cross_validator.averaged_evaluation_df_pred_cal_update.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_score_calupdate.csv\"\n",
    "        )\n",
    "        cptox21_cross_validator.averaged_evaluation_df_pred_cal_update2.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_score_calupdate2.csv\"\n",
    "        )\n",
    "        \n",
    "        train_index, test_index = cptox21_cross_validator.train_indices, cptox21_cross_validator.test_indices\n",
    "        known_indices_sampler = KnownIndicesSampler(\n",
    "            known_train=train_index, known_test=test_index\n",
    "        )\n",
    "\n",
    "        train_update_cross_validator = cross_validate_with_updated_training_set(\n",
    "            endpoint, X_train, y_train, X_test, y_test, X_score, y_score, known_indices_sampler\n",
    "        )\n",
    "\n",
    "        evaluation_dfs[\"cv_trainupdate\"].append(train_update_cross_validator.averaged_evaluation_df_cv)\n",
    "        evaluation_dfs[\"pred_score_trainupdate\"].append(train_update_cross_validator.averaged_evaluation_df_pred_score)\n",
    "    \n",
    "        train_update_cross_validator.averaged_evaluation_df_cv.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_cv_trainupdate.csv\"\n",
    "        )\n",
    "        train_update_cross_validator.averaged_evaluation_df_pred_score.to_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_pred_score_trainupdate.csv\"\n",
    "        )\n",
    "#     else: # If results are already available and dataframes can be loaded directly\n",
    "#         cv_original_df = pd.read_csv(f\"{data_statistics_path}{endpoint}_cv_original.csv\")\n",
    "#         evaluation_dfs[\"cv_original\"].append(cv_original_df)\n",
    "#         pred_score_original_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_pred_score_original.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"pred_score_original\"].append(pred_score_original_df)\n",
    "#         pred_test_original_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_pred_test_original.csv\"\n",
    "#         )\n",
    "#         pred_score_calupdate_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_pred_score_calupdate.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"pred_score_calupdate\"].append(pred_score_calupdate_df)\n",
    "#         pred_score_calupdate2_df = pd.read_csv(\n",
    "#              f\"{data_statistics_path}{endpoint}_pred_score_calupdate2.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"pred_score_calupdate2\"].append(pred_score_calupdate2_df)\n",
    "#         cv_trainupdate_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_cv_trainupdate.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"cv_trainupdate\"].append(cv_trainupdate_df)\n",
    "#         pred_score_trainupdate_df = pd.read_csv(\n",
    "#             f\"{data_statistics_path}{endpoint}_pred_score_trainupdate.csv\"\n",
    "#         )\n",
    "#         evaluation_dfs[\"pred_score_trainupdate\"].append(pred_score_trainupdate_df)\n",
    "        \n",
    "    else: # If results are already available and dataframes can be loaded directly\n",
    "        cv_original_df = pd.read_csv(f\"{data_statistics_path}{endpoint}_averaged_eval_df_cv.csv\")\n",
    "        evaluation_dfs[\"cv_original\"].append(cv_original_df)\n",
    "        pred_score_original_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_pred_score.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_original\"].append(pred_score_original_df)\n",
    "        pred_test_original_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_pred_test.csv\"\n",
    "        )\n",
    "        pred_score_calupdate_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_cal_update.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_calupdate\"].append(pred_score_calupdate_df)\n",
    "        pred_score_calupdate2_df = pd.read_csv(\n",
    "             f\"{data_statistics_path}{endpoint}_averaged_eval_df_cal_update2.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_calupdate2\"].append(pred_score_calupdate2_df)\n",
    "        cv_trainupdate_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_cv_train_update.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"cv_trainupdate\"].append(cv_trainupdate_df)\n",
    "        pred_score_trainupdate_df = pd.read_csv(\n",
    "            f\"{data_statistics_path}{endpoint}_averaged_eval_df_pred_score_train_update.csv\"\n",
    "        )\n",
    "        evaluation_dfs[\"pred_score_trainupdate\"].append(pred_score_trainupdate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_original': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9152      0.007596           0.9146   \n",
       "  2                  0.2         0.8130      0.013266           0.8110   \n",
       "  3                  0.3         0.7092      0.006261           0.7076   \n",
       "  4                  0.4         0.5966      0.010502           0.5950   \n",
       "  5                  0.5         0.4838      0.002387           0.4814   \n",
       "  6                  0.6         0.3800      0.004243           0.3766   \n",
       "  7                  0.7         0.2742      0.008044           0.2714   \n",
       "  8                  0.8         0.1744      0.007829           0.1734   \n",
       "  9                  0.9         0.0852      0.004817           0.0868   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006465           0.9222        0.040400           0.0848   \n",
       "  2         0.012728           0.8632        0.037686           0.1870   \n",
       "  3         0.006841           0.7514        0.063062           0.2908   \n",
       "  4         0.009138           0.6428        0.086219           0.4034   \n",
       "  5         0.004037           0.5462        0.093227           0.5162   \n",
       "  6         0.005413           0.4690        0.105143           0.6200   \n",
       "  7         0.010164           0.3448        0.111102           0.7258   \n",
       "  8         0.008385           0.1988        0.086370           0.8256   \n",
       "  9         0.005357           0.0466        0.045791           0.9148   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007596             0.0854  ...        0.009039           0.9022   \n",
       "  2         0.013266             0.1890  ...        0.011916           0.8590   \n",
       "  3         0.006261             0.2924  ...        0.016802           0.8508   \n",
       "  4         0.010502             0.4050  ...        0.011100           0.8654   \n",
       "  5         0.002387             0.5186  ...        0.006025           0.8842   \n",
       "  6         0.004243             0.6234  ...        0.008050           0.9150   \n",
       "  7         0.008044             0.7286  ...        0.008468           0.9184   \n",
       "  8         0.007829             0.8266  ...        0.006465           0.9550   \n",
       "  9         0.004817             0.9132  ...        0.003050           0.9600   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              322.0   \n",
       "  1         0.045356                   0.1              322.0   \n",
       "  2         0.035721                   0.2              322.0   \n",
       "  3         0.048220                   0.3              322.0   \n",
       "  4         0.042700                   0.4              322.0   \n",
       "  5         0.072189                   0.5              322.0   \n",
       "  6         0.037623                   0.6              322.0   \n",
       "  7         0.035246                   0.7              322.0   \n",
       "  8         0.062249                   0.8              322.0   \n",
       "  9         0.089443                   0.9              322.0   \n",
       "  10        0.000000                   1.0              322.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8179.0                25.0                 240.0   \n",
       "  1                8179.0                25.0                 240.0   \n",
       "  2                8179.0                25.0                 240.0   \n",
       "  3                8179.0                25.0                 240.0   \n",
       "  4                8179.0                25.0                 240.0   \n",
       "  5                8179.0                25.0                 240.0   \n",
       "  6                8179.0                25.0                 240.0   \n",
       "  7                8179.0                25.0                 240.0   \n",
       "  8                8179.0                25.0                 240.0   \n",
       "  9                8179.0                25.0                 240.0   \n",
       "  10               8179.0                25.0                 240.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                554.0  \n",
       "  1                36.0                554.0  \n",
       "  2                36.0                554.0  \n",
       "  3                36.0                554.0  \n",
       "  4                36.0                554.0  \n",
       "  5                36.0                554.0  \n",
       "  6                36.0                554.0  \n",
       "  7                36.0                554.0  \n",
       "  8                36.0                554.0  \n",
       "  9                36.0                554.0  \n",
       "  10               36.0                554.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9198      0.004817           0.9188   \n",
       "  2                  0.2         0.8224      0.010900           0.8242   \n",
       "  3                  0.3         0.7262      0.007396           0.7320   \n",
       "  4                  0.4         0.5944      0.013428           0.5950   \n",
       "  5                  0.5         0.4840      0.016233           0.4804   \n",
       "  6                  0.6         0.3800      0.013038           0.3746   \n",
       "  7                  0.7         0.2732      0.007463           0.2676   \n",
       "  8                  0.8         0.1626      0.007403           0.1602   \n",
       "  9                  0.9         0.0748      0.006834           0.0712   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005020           0.9278        0.016589           0.0802   \n",
       "  2         0.012153           0.8088        0.031044           0.1776   \n",
       "  3         0.006595           0.6840        0.027541           0.2738   \n",
       "  4         0.010932           0.5914        0.039342           0.4056   \n",
       "  5         0.013557           0.5106        0.032700           0.5160   \n",
       "  6         0.013446           0.4194        0.015630           0.6200   \n",
       "  7         0.010015           0.3120        0.037483           0.7268   \n",
       "  8         0.006834           0.1798        0.042833           0.8374   \n",
       "  9         0.008319           0.1000        0.035937           0.9252   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004817             0.0812  ...        0.016362           0.8810   \n",
       "  2         0.010900             0.1758  ...        0.011323           0.7614   \n",
       "  3         0.007396             0.2680  ...        0.009576           0.6780   \n",
       "  4         0.013428             0.4050  ...        0.013957           0.6966   \n",
       "  5         0.016233             0.5196  ...        0.008849           0.7182   \n",
       "  6         0.013038             0.6254  ...        0.003435           0.7362   \n",
       "  7         0.007463             0.7324  ...        0.014601           0.7512   \n",
       "  8         0.007403             0.8398  ...        0.011014           0.7344   \n",
       "  9         0.006834             0.9288  ...        0.021112           0.7726   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              901.0   \n",
       "  1         0.026334                   0.1              901.0   \n",
       "  2         0.040673                   0.2              901.0   \n",
       "  3         0.028311                   0.3              901.0   \n",
       "  4         0.035571                   0.4              901.0   \n",
       "  5         0.046316                   0.5              901.0   \n",
       "  6         0.033559                   0.6              901.0   \n",
       "  7         0.054490                   0.7              901.0   \n",
       "  8         0.093342                   0.8              901.0   \n",
       "  9         0.121895                   0.9              901.0   \n",
       "  10        0.000000                   1.0              901.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6290.0                27.0                 231.0   \n",
       "  1                6290.0                27.0                 231.0   \n",
       "  2                6290.0                27.0                 231.0   \n",
       "  3                6290.0                27.0                 231.0   \n",
       "  4                6290.0                27.0                 231.0   \n",
       "  5                6290.0                27.0                 231.0   \n",
       "  6                6290.0                27.0                 231.0   \n",
       "  7                6290.0                27.0                 231.0   \n",
       "  8                6290.0                27.0                 231.0   \n",
       "  9                6290.0                27.0                 231.0   \n",
       "  10               6290.0                27.0                 231.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                49.0                441.0  \n",
       "  1                49.0                441.0  \n",
       "  2                49.0                441.0  \n",
       "  3                49.0                441.0  \n",
       "  4                49.0                441.0  \n",
       "  5                49.0                441.0  \n",
       "  6                49.0                441.0  \n",
       "  7                49.0                441.0  \n",
       "  8                49.0                441.0  \n",
       "  9                49.0                441.0  \n",
       "  10               49.0                441.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9248      0.007190           0.9256   \n",
       "  2                  0.2         0.8206      0.010455           0.8220   \n",
       "  3                  0.3         0.7186      0.011971           0.7196   \n",
       "  4                  0.4         0.5980      0.009301           0.5982   \n",
       "  5                  0.5         0.4840      0.008573           0.4828   \n",
       "  6                  0.6         0.3660      0.017734           0.3642   \n",
       "  7                  0.7         0.2534      0.017473           0.2516   \n",
       "  8                  0.8         0.1504      0.012095           0.1492   \n",
       "  9                  0.9         0.0642      0.005215           0.0634   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008444           0.9058        0.049877           0.0752   \n",
       "  2         0.011576           0.7936        0.042454           0.1794   \n",
       "  3         0.013576           0.6918        0.050236           0.2814   \n",
       "  4         0.010986           0.5900        0.056824           0.4020   \n",
       "  5         0.009011           0.5098        0.070123           0.5160   \n",
       "  6         0.017754           0.4132        0.085119           0.6340   \n",
       "  7         0.017344           0.2870        0.057502           0.7466   \n",
       "  8         0.011819           0.1798        0.041445           0.8496   \n",
       "  9         0.005459           0.0884        0.030279           0.9358   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007190             0.0744  ...        0.075377           0.8726   \n",
       "  2         0.010455             0.1780  ...        0.033774           0.7680   \n",
       "  3         0.011971             0.2804  ...        0.047812           0.7054   \n",
       "  4         0.009301             0.4018  ...        0.012826           0.7024   \n",
       "  5         0.008573             0.5172  ...        0.002775           0.7106   \n",
       "  6         0.017734             0.6358  ...        0.004087           0.7192   \n",
       "  7         0.017473             0.7484  ...        0.001342           0.7246   \n",
       "  8         0.012095             0.8508  ...        0.002191           0.7090   \n",
       "  9         0.005215             0.9366  ...        0.000000           0.7320   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              373.0   \n",
       "  1         0.058496                   0.1              373.0   \n",
       "  2         0.041946                   0.2              373.0   \n",
       "  3         0.035886                   0.3              373.0   \n",
       "  4         0.047805                   0.4              373.0   \n",
       "  5         0.033381                   0.5              373.0   \n",
       "  6         0.023763                   0.6              373.0   \n",
       "  7         0.031477                   0.7              373.0   \n",
       "  8         0.030480                   0.8              373.0   \n",
       "  9         0.114492                   0.9              373.0   \n",
       "  10        0.000000                   1.0              373.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8370.0                 3.0                 282.0   \n",
       "  1                8370.0                 3.0                 282.0   \n",
       "  2                8370.0                 3.0                 282.0   \n",
       "  3                8370.0                 3.0                 282.0   \n",
       "  4                8370.0                 3.0                 282.0   \n",
       "  5                8370.0                 3.0                 282.0   \n",
       "  6                8370.0                 3.0                 282.0   \n",
       "  7                8370.0                 3.0                 282.0   \n",
       "  8                8370.0                 3.0                 282.0   \n",
       "  9                8370.0                 3.0                 282.0   \n",
       "  10               8370.0                 3.0                 282.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                11.0                549.0  \n",
       "  1                11.0                549.0  \n",
       "  2                11.0                549.0  \n",
       "  3                11.0                549.0  \n",
       "  4                11.0                549.0  \n",
       "  5                11.0                549.0  \n",
       "  6                11.0                549.0  \n",
       "  7                11.0                549.0  \n",
       "  8                11.0                549.0  \n",
       "  9                11.0                549.0  \n",
       "  10               11.0                549.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9148      0.005586           0.9154   \n",
       "  2                  0.2         0.8320      0.007616           0.8334   \n",
       "  3                  0.3         0.7088      0.009859           0.7084   \n",
       "  4                  0.4         0.6020      0.007969           0.6018   \n",
       "  5                  0.5         0.4966      0.012621           0.4960   \n",
       "  6                  0.6         0.3880      0.017029           0.3860   \n",
       "  7                  0.7         0.2814      0.008325           0.2788   \n",
       "  8                  0.8         0.1722      0.010330           0.1696   \n",
       "  9                  0.9         0.0756      0.008473           0.0756   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007436           0.9042        0.048956           0.0852   \n",
       "  2         0.010310           0.8080        0.052555           0.1680   \n",
       "  3         0.012779           0.7198        0.085698           0.2912   \n",
       "  4         0.009391           0.6060        0.102042           0.3980   \n",
       "  5         0.012826           0.5126        0.086947           0.5034   \n",
       "  6         0.017464           0.4252        0.087211           0.6120   \n",
       "  7         0.007759           0.3370        0.058069           0.7186   \n",
       "  8         0.010237           0.2230        0.045039           0.8278   \n",
       "  9         0.008849           0.0804        0.044411           0.9244   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.005586             0.0846  ...        0.035591           0.8594   \n",
       "  2         0.007616             0.1666  ...        0.026898           0.7888   \n",
       "  3         0.009859             0.2916  ...        0.044807           0.7426   \n",
       "  4         0.007969             0.3982  ...        0.030589           0.7504   \n",
       "  5         0.012621             0.5040  ...        0.017210           0.7544   \n",
       "  6         0.017029             0.6140  ...        0.017838           0.7668   \n",
       "  7         0.008325             0.7212  ...        0.015991           0.7998   \n",
       "  8         0.010330             0.8304  ...        0.013229           0.8226   \n",
       "  9         0.008473             0.9244  ...        0.009471           0.8834   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              386.0   \n",
       "  1         0.079679                   0.1              386.0   \n",
       "  2         0.045235                   0.2              386.0   \n",
       "  3         0.078720                   0.3              386.0   \n",
       "  4         0.071978                   0.4              386.0   \n",
       "  5         0.074852                   0.5              386.0   \n",
       "  6         0.083625                   0.6              386.0   \n",
       "  7         0.087340                   0.7              386.0   \n",
       "  8         0.065095                   0.8              386.0   \n",
       "  9         0.136163                   0.9              386.0   \n",
       "  10        0.000000                   1.0              386.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7233.0                10.0                 250.0   \n",
       "  1                7233.0                10.0                 250.0   \n",
       "  2                7233.0                10.0                 250.0   \n",
       "  3                7233.0                10.0                 250.0   \n",
       "  4                7233.0                10.0                 250.0   \n",
       "  5                7233.0                10.0                 250.0   \n",
       "  6                7233.0                10.0                 250.0   \n",
       "  7                7233.0                10.0                 250.0   \n",
       "  8                7233.0                10.0                 250.0   \n",
       "  9                7233.0                10.0                 250.0   \n",
       "  10               7233.0                10.0                 250.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                19.0                558.0  \n",
       "  1                19.0                558.0  \n",
       "  2                19.0                558.0  \n",
       "  3                19.0                558.0  \n",
       "  4                19.0                558.0  \n",
       "  5                19.0                558.0  \n",
       "  6                19.0                558.0  \n",
       "  7                19.0                558.0  \n",
       "  8                19.0                558.0  \n",
       "  9                19.0                558.0  \n",
       "  10               19.0                558.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9104      0.003286           0.9124   \n",
       "  2                  0.2         0.8154      0.012837           0.8164   \n",
       "  3                  0.3         0.7004      0.014588           0.6990   \n",
       "  4                  0.4         0.5986      0.014859           0.5978   \n",
       "  5                  0.5         0.4980      0.024166           0.4954   \n",
       "  6                  0.6         0.3934      0.020562           0.3884   \n",
       "  7                  0.7         0.2814      0.016380           0.2812   \n",
       "  8                  0.8         0.1834      0.008325           0.1792   \n",
       "  9                  0.9         0.0876      0.009633           0.0852   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004450           0.9014        0.028254           0.0896   \n",
       "  2         0.015837           0.8116        0.011059           0.1846   \n",
       "  3         0.017263           0.7066        0.019178           0.2996   \n",
       "  4         0.018674           0.6034        0.017841           0.4014   \n",
       "  5         0.027015           0.5116        0.020157           0.5020   \n",
       "  6         0.023881           0.4206        0.032215           0.6066   \n",
       "  7         0.016991           0.2834        0.053500           0.7186   \n",
       "  8         0.012050           0.2066        0.051282           0.8166   \n",
       "  9         0.010354           0.1006        0.034897           0.9124   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.003286             0.0876  ...        0.006580           0.8930   \n",
       "  2         0.012837             0.1836  ...        0.008602           0.8890   \n",
       "  3         0.014588             0.3010  ...        0.003050           0.9076   \n",
       "  4         0.014859             0.4022  ...        0.004450           0.9364   \n",
       "  5         0.024166             0.5046  ...        0.004970           0.9482   \n",
       "  6         0.020562             0.6116  ...        0.005788           0.9592   \n",
       "  7         0.016380             0.7188  ...        0.006140           0.9648   \n",
       "  8         0.008325             0.8208  ...        0.013946           0.9696   \n",
       "  9         0.009633             0.9148  ...        0.021592           0.9718   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1094.0   \n",
       "  1         0.028293                   0.1             1094.0   \n",
       "  2         0.022249                   0.2             1094.0   \n",
       "  3         0.016009                   0.3             1094.0   \n",
       "  4         0.013088                   0.4             1094.0   \n",
       "  5         0.019136                   0.5             1094.0   \n",
       "  6         0.016814                   0.6             1094.0   \n",
       "  7         0.014043                   0.7             1094.0   \n",
       "  8         0.026406                   0.8             1094.0   \n",
       "  9         0.045675                   0.9             1094.0   \n",
       "  10        0.000000                   1.0             1094.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5719.0                38.0                 195.0   \n",
       "  1                5719.0                38.0                 195.0   \n",
       "  2                5719.0                38.0                 195.0   \n",
       "  3                5719.0                38.0                 195.0   \n",
       "  4                5719.0                38.0                 195.0   \n",
       "  5                5719.0                38.0                 195.0   \n",
       "  6                5719.0                38.0                 195.0   \n",
       "  7                5719.0                38.0                 195.0   \n",
       "  8                5719.0                38.0                 195.0   \n",
       "  9                5719.0                38.0                 195.0   \n",
       "  10               5719.0                38.0                 195.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                56.0                457.0  \n",
       "  1                56.0                457.0  \n",
       "  2                56.0                457.0  \n",
       "  3                56.0                457.0  \n",
       "  4                56.0                457.0  \n",
       "  5                56.0                457.0  \n",
       "  6                56.0                457.0  \n",
       "  7                56.0                457.0  \n",
       "  8                56.0                457.0  \n",
       "  9                56.0                457.0  \n",
       "  10               56.0                457.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9150      0.003082           0.9140   \n",
       "  2                  0.2         0.8184      0.009607           0.8164   \n",
       "  3                  0.3         0.7084      0.007603           0.7064   \n",
       "  4                  0.4         0.6090      0.005831           0.6064   \n",
       "  5                  0.5         0.5058      0.011300           0.5034   \n",
       "  6                  0.6         0.3966      0.010213           0.3930   \n",
       "  7                  0.7         0.2906      0.006066           0.2874   \n",
       "  8                  0.8         0.1828      0.005541           0.1806   \n",
       "  9                  0.9         0.0820      0.009487           0.0834   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.003742           0.9282        0.019942           0.0850   \n",
       "  2         0.011589           0.8446        0.019501           0.1816   \n",
       "  3         0.010407           0.7358        0.040015           0.2916   \n",
       "  4         0.007987           0.6430        0.040268           0.3910   \n",
       "  5         0.014276           0.5398        0.044885           0.4942   \n",
       "  6         0.012390           0.4486        0.049546           0.6034   \n",
       "  7         0.007861           0.3436        0.030171           0.7094   \n",
       "  8         0.006914           0.2174        0.056655           0.8172   \n",
       "  9         0.009685           0.0642        0.028857           0.9180   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.003082             0.0860  ...        0.012462           0.9132   \n",
       "  2         0.009607             0.1836  ...        0.024525           0.8504   \n",
       "  3         0.007603             0.2936  ...        0.008871           0.8770   \n",
       "  4         0.005831             0.3936  ...        0.012950           0.8974   \n",
       "  5         0.011300             0.4966  ...        0.007497           0.9140   \n",
       "  6         0.010213             0.6070  ...        0.007956           0.9440   \n",
       "  7         0.006066             0.7126  ...        0.002864           0.9514   \n",
       "  8         0.005541             0.8194  ...        0.004970           0.9578   \n",
       "  9         0.009487             0.9166  ...        0.008877           0.9334   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              515.0   \n",
       "  1         0.024530                   0.1              515.0   \n",
       "  2         0.016410                   0.2              515.0   \n",
       "  3         0.019468                   0.3              515.0   \n",
       "  4         0.015630                   0.4              515.0   \n",
       "  5         0.045260                   0.5              515.0   \n",
       "  6         0.023281                   0.6              515.0   \n",
       "  7         0.022656                   0.7              515.0   \n",
       "  8         0.055823                   0.8              515.0   \n",
       "  9         0.148922                   0.9              515.0   \n",
       "  10        0.000000                   1.0              515.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7542.0                28.0                 234.0   \n",
       "  1                7542.0                28.0                 234.0   \n",
       "  2                7542.0                28.0                 234.0   \n",
       "  3                7542.0                28.0                 234.0   \n",
       "  4                7542.0                28.0                 234.0   \n",
       "  5                7542.0                28.0                 234.0   \n",
       "  6                7542.0                28.0                 234.0   \n",
       "  7                7542.0                28.0                 234.0   \n",
       "  8                7542.0                28.0                 234.0   \n",
       "  9                7542.0                28.0                 234.0   \n",
       "  10               7542.0                28.0                 234.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                40.0                543.0  \n",
       "  1                40.0                543.0  \n",
       "  2                40.0                543.0  \n",
       "  3                40.0                543.0  \n",
       "  4                40.0                543.0  \n",
       "  5                40.0                543.0  \n",
       "  6                40.0                543.0  \n",
       "  7                40.0                543.0  \n",
       "  8                40.0                543.0  \n",
       "  9                40.0                543.0  \n",
       "  10               40.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9112      0.010733           0.9106   \n",
       "  2                  0.2         0.8032      0.019791           0.8016   \n",
       "  3                  0.3         0.7048      0.026781           0.7032   \n",
       "  4                  0.4         0.5946      0.027107           0.5930   \n",
       "  5                  0.5         0.4858      0.029836           0.4840   \n",
       "  6                  0.6         0.3818      0.026696           0.3798   \n",
       "  7                  0.7         0.2838      0.023942           0.2806   \n",
       "  8                  0.8         0.1816      0.023702           0.1800   \n",
       "  9                  0.9         0.0844      0.011371           0.0860   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010383           0.9258        0.027932           0.0888   \n",
       "  2         0.018743           0.8312        0.061824           0.1968   \n",
       "  3         0.024263           0.7302        0.087748           0.2952   \n",
       "  4         0.026533           0.6296        0.061223           0.4054   \n",
       "  5         0.027767           0.5204        0.081846           0.5142   \n",
       "  6         0.023669           0.4134        0.099364           0.6182   \n",
       "  7         0.021778           0.3458        0.089105           0.7162   \n",
       "  8         0.023033           0.2066        0.081923           0.8184   \n",
       "  9         0.010677           0.0564        0.049039           0.9156   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.010733             0.0894  ...        0.018061           0.9036   \n",
       "  2         0.019791             0.1984  ...        0.016131           0.8268   \n",
       "  3         0.026781             0.2968  ...        0.018674           0.8328   \n",
       "  4         0.027107             0.4070  ...        0.009230           0.8650   \n",
       "  5         0.029836             0.5160  ...        0.007956           0.8814   \n",
       "  6         0.026696             0.6202  ...        0.003899           0.9112   \n",
       "  7         0.023942             0.7194  ...        0.004025           0.9440   \n",
       "  8         0.023702             0.8200  ...        0.003564           0.9560   \n",
       "  9         0.011371             0.9140  ...        0.005310           0.9000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              338.0   \n",
       "  1         0.039329                   0.1              338.0   \n",
       "  2         0.059428                   0.2              338.0   \n",
       "  3         0.044924                   0.3              338.0   \n",
       "  4         0.043669                   0.4              338.0   \n",
       "  5         0.054853                   0.5              338.0   \n",
       "  6         0.050057                   0.6              338.0   \n",
       "  7         0.058382                   0.7              338.0   \n",
       "  8         0.064610                   0.8              338.0   \n",
       "  9         0.223607                   0.9              338.0   \n",
       "  10        0.000000                   1.0              338.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6362.0                18.0                 192.0   \n",
       "  1                6362.0                18.0                 192.0   \n",
       "  2                6362.0                18.0                 192.0   \n",
       "  3                6362.0                18.0                 192.0   \n",
       "  4                6362.0                18.0                 192.0   \n",
       "  5                6362.0                18.0                 192.0   \n",
       "  6                6362.0                18.0                 192.0   \n",
       "  7                6362.0                18.0                 192.0   \n",
       "  8                6362.0                18.0                 192.0   \n",
       "  9                6362.0                18.0                 192.0   \n",
       "  10               6362.0                18.0                 192.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                466.0  \n",
       "  1                36.0                466.0  \n",
       "  2                36.0                466.0  \n",
       "  3                36.0                466.0  \n",
       "  4                36.0                466.0  \n",
       "  5                36.0                466.0  \n",
       "  6                36.0                466.0  \n",
       "  7                36.0                466.0  \n",
       "  8                36.0                466.0  \n",
       "  9                36.0                466.0  \n",
       "  10               36.0                466.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9160      0.006285           0.9150   \n",
       "  2                  0.2         0.8178      0.011389           0.8166   \n",
       "  3                  0.3         0.7252      0.008643           0.7256   \n",
       "  4                  0.4         0.5972      0.008438           0.5930   \n",
       "  5                  0.5         0.4998      0.009365           0.4942   \n",
       "  6                  0.6         0.3946      0.004722           0.3878   \n",
       "  7                  0.7         0.2894      0.003435           0.2842   \n",
       "  8                  0.8         0.1838      0.007563           0.1812   \n",
       "  9                  0.9         0.0776      0.008792           0.0774   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009028           0.9214        0.013921           0.0840   \n",
       "  2         0.015630           0.8256        0.013334           0.1822   \n",
       "  3         0.013649           0.7228        0.027124           0.2748   \n",
       "  4         0.011554           0.6192        0.041124           0.4028   \n",
       "  5         0.007259           0.5298        0.037864           0.5002   \n",
       "  6         0.003701           0.4312        0.033878           0.6054   \n",
       "  7         0.005263           0.3198        0.028648           0.7106   \n",
       "  8         0.008167           0.1978        0.042664           0.8162   \n",
       "  9         0.011437           0.0784        0.012621           0.9224   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.006285             0.0850  ...        0.016861           0.8932   \n",
       "  2         0.011389             0.1834  ...        0.017479           0.8190   \n",
       "  3         0.008643             0.2744  ...        0.008349           0.8268   \n",
       "  4         0.008438             0.4070  ...        0.011424           0.8518   \n",
       "  5         0.009365             0.5058  ...        0.015010           0.8568   \n",
       "  6         0.004722             0.6122  ...        0.013103           0.8682   \n",
       "  7         0.003435             0.7158  ...        0.010208           0.8920   \n",
       "  8         0.007563             0.8188  ...        0.010060           0.9010   \n",
       "  9         0.008792             0.9226  ...        0.020924           0.8886   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1032.0   \n",
       "  1         0.018006                   0.1             1032.0   \n",
       "  2         0.013820                   0.2             1032.0   \n",
       "  3         0.014377                   0.3             1032.0   \n",
       "  4         0.014957                   0.4             1032.0   \n",
       "  5         0.018620                   0.5             1032.0   \n",
       "  6         0.019575                   0.6             1032.0   \n",
       "  7         0.023770                   0.7             1032.0   \n",
       "  8         0.031788                   0.8             1032.0   \n",
       "  9         0.053617                   0.9             1032.0   \n",
       "  10        0.000000                   1.0             1032.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5653.0                47.0                 181.0   \n",
       "  1                5653.0                47.0                 181.0   \n",
       "  2                5653.0                47.0                 181.0   \n",
       "  3                5653.0                47.0                 181.0   \n",
       "  4                5653.0                47.0                 181.0   \n",
       "  5                5653.0                47.0                 181.0   \n",
       "  6                5653.0                47.0                 181.0   \n",
       "  7                5653.0                47.0                 181.0   \n",
       "  8                5653.0                47.0                 181.0   \n",
       "  9                5653.0                47.0                 181.0   \n",
       "  10               5653.0                47.0                 181.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                89.0                433.0  \n",
       "  1                89.0                433.0  \n",
       "  2                89.0                433.0  \n",
       "  3                89.0                433.0  \n",
       "  4                89.0                433.0  \n",
       "  5                89.0                433.0  \n",
       "  6                89.0                433.0  \n",
       "  7                89.0                433.0  \n",
       "  8                89.0                433.0  \n",
       "  9                89.0                433.0  \n",
       "  10               89.0                433.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9282      0.004764           0.9286   \n",
       "  2                  0.2         0.8144      0.011327           0.8144   \n",
       "  3                  0.3         0.7086      0.011675           0.7084   \n",
       "  4                  0.4         0.5970      0.006164           0.5972   \n",
       "  5                  0.5         0.4942      0.007259           0.4954   \n",
       "  6                  0.6         0.3818      0.014096           0.3840   \n",
       "  7                  0.7         0.2722      0.020241           0.2726   \n",
       "  8                  0.8         0.1690      0.010368           0.1692   \n",
       "  9                  0.9         0.0816      0.006768           0.0814   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005367           0.9184        0.027934           0.0718   \n",
       "  2         0.010550           0.8102        0.045207           0.1856   \n",
       "  3         0.012219           0.7086        0.055608           0.2914   \n",
       "  4         0.008136           0.5898        0.108776           0.4030   \n",
       "  5         0.006693           0.4678        0.083305           0.5058   \n",
       "  6         0.013096           0.3356        0.065179           0.6182   \n",
       "  7         0.018743           0.2574        0.067359           0.7278   \n",
       "  8         0.009284           0.1730        0.055104           0.8310   \n",
       "  9         0.005727           0.0884        0.040587           0.9184   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004764             0.0714  ...        0.017228           0.9066   \n",
       "  2         0.011327             0.1856  ...        0.057159           0.8184   \n",
       "  3         0.011675             0.2916  ...        0.005215           0.8364   \n",
       "  4         0.006164             0.4028  ...        0.002449           0.8492   \n",
       "  5         0.007259             0.5046  ...        0.000447           0.8636   \n",
       "  6         0.014096             0.6160  ...        0.001342           0.8612   \n",
       "  7         0.020241             0.7274  ...        0.001789           0.8806   \n",
       "  8         0.010368             0.8308  ...        0.000000           0.9122   \n",
       "  9         0.006768             0.9186  ...        0.000000           0.9514   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              295.0   \n",
       "  1         0.028979                   0.1              295.0   \n",
       "  2         0.040327                   0.2              295.0   \n",
       "  3         0.029678                   0.3              295.0   \n",
       "  4         0.014498                   0.4              295.0   \n",
       "  5         0.029947                   0.5              295.0   \n",
       "  6         0.046067                   0.6              295.0   \n",
       "  7         0.050491                   0.7              295.0   \n",
       "  8         0.072851                   0.8              295.0   \n",
       "  9         0.068263                   0.9              295.0   \n",
       "  10        0.000000                   1.0              295.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7742.0                 4.0                 242.0   \n",
       "  1                7742.0                 4.0                 242.0   \n",
       "  2                7742.0                 4.0                 242.0   \n",
       "  3                7742.0                 4.0                 242.0   \n",
       "  4                7742.0                 4.0                 242.0   \n",
       "  5                7742.0                 4.0                 242.0   \n",
       "  6                7742.0                 4.0                 242.0   \n",
       "  7                7742.0                 4.0                 242.0   \n",
       "  8                7742.0                 4.0                 242.0   \n",
       "  9                7742.0                 4.0                 242.0   \n",
       "  10               7742.0                 4.0                 242.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                 8.0                543.0  \n",
       "  1                 8.0                543.0  \n",
       "  2                 8.0                543.0  \n",
       "  3                 8.0                543.0  \n",
       "  4                 8.0                543.0  \n",
       "  5                 8.0                543.0  \n",
       "  6                 8.0                543.0  \n",
       "  7                 8.0                543.0  \n",
       "  8                 8.0                543.0  \n",
       "  9                 8.0                543.0  \n",
       "  10                8.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9152      0.004817           0.9146   \n",
       "  2                  0.2         0.8278      0.010663           0.8286   \n",
       "  3                  0.3         0.7136      0.015027           0.7108   \n",
       "  4                  0.4         0.6082      0.013084           0.6040   \n",
       "  5                  0.5         0.5044      0.011632           0.4994   \n",
       "  6                  0.6         0.3936      0.013069           0.3890   \n",
       "  7                  0.7         0.2826      0.010015           0.2766   \n",
       "  8                  0.8         0.1728      0.011454           0.1722   \n",
       "  9                  0.9         0.0816      0.005177           0.0814   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004827           0.9206        0.013465           0.0848   \n",
       "  2         0.011415           0.8232        0.016514           0.1722   \n",
       "  3         0.018847           0.7342        0.025626           0.2864   \n",
       "  4         0.017000           0.6388        0.040776           0.3918   \n",
       "  5         0.010854           0.5380        0.027722           0.4956   \n",
       "  6         0.012268           0.4264        0.030476           0.6064   \n",
       "  7         0.013885           0.3246        0.028745           0.7174   \n",
       "  8         0.015156           0.1782        0.029338           0.8272   \n",
       "  9         0.007403           0.0848        0.019779           0.9184   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004817             0.0854  ...        0.006656           0.9108   \n",
       "  2         0.010663             0.1714  ...        0.007162           0.8664   \n",
       "  3         0.015027             0.2892  ...        0.004278           0.9060   \n",
       "  4         0.013084             0.3960  ...        0.004393           0.9120   \n",
       "  5         0.011632             0.5006  ...        0.006907           0.9262   \n",
       "  6         0.013069             0.6110  ...        0.005745           0.9274   \n",
       "  7         0.010015             0.7234  ...        0.008307           0.9316   \n",
       "  8         0.011454             0.8278  ...        0.008803           0.9190   \n",
       "  9         0.005177             0.9186  ...        0.017804           0.9178   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              933.0   \n",
       "  1         0.013791                   0.1              933.0   \n",
       "  2         0.014293                   0.2              933.0   \n",
       "  3         0.011424                   0.3              933.0   \n",
       "  4         0.014248                   0.4              933.0   \n",
       "  5         0.013142                   0.5              933.0   \n",
       "  6         0.008325                   0.6              933.0   \n",
       "  7         0.013576                   0.7              933.0   \n",
       "  8         0.019837                   0.8              933.0   \n",
       "  9         0.028960                   0.9              933.0   \n",
       "  10        0.000000                   1.0              933.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6687.0                29.0                 236.0   \n",
       "  1                6687.0                29.0                 236.0   \n",
       "  2                6687.0                29.0                 236.0   \n",
       "  3                6687.0                29.0                 236.0   \n",
       "  4                6687.0                29.0                 236.0   \n",
       "  5                6687.0                29.0                 236.0   \n",
       "  6                6687.0                29.0                 236.0   \n",
       "  7                6687.0                29.0                 236.0   \n",
       "  8                6687.0                29.0                 236.0   \n",
       "  9                6687.0                29.0                 236.0   \n",
       "  10               6687.0                29.0                 236.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                71.0                506.0  \n",
       "  1                71.0                506.0  \n",
       "  2                71.0                506.0  \n",
       "  3                71.0                506.0  \n",
       "  4                71.0                506.0  \n",
       "  5                71.0                506.0  \n",
       "  6                71.0                506.0  \n",
       "  7                71.0                506.0  \n",
       "  8                71.0                506.0  \n",
       "  9                71.0                506.0  \n",
       "  10               71.0                506.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9236      0.007765           0.9236   \n",
       "  2                  0.2         0.8154      0.010621           0.8142   \n",
       "  3                  0.3         0.7090      0.008216           0.7090   \n",
       "  4                  0.4         0.6050      0.018708           0.6044   \n",
       "  5                  0.5         0.4912      0.019524           0.4902   \n",
       "  6                  0.6         0.3834      0.013813           0.3802   \n",
       "  7                  0.7         0.2740      0.009055           0.2716   \n",
       "  8                  0.8         0.1692      0.007694           0.1688   \n",
       "  9                  0.9         0.0756      0.003362           0.0752   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009017           0.9166        0.022052           0.0764   \n",
       "  2         0.011345           0.8398        0.011100           0.1846   \n",
       "  3         0.007483           0.7112        0.025193           0.2910   \n",
       "  4         0.016652           0.6186        0.061272           0.3950   \n",
       "  5         0.017341           0.5108        0.067005           0.5088   \n",
       "  6         0.012677           0.4418        0.051553           0.6166   \n",
       "  7         0.008735           0.3174        0.036253           0.7260   \n",
       "  8         0.007430           0.1766        0.030204           0.8308   \n",
       "  9         0.003194           0.0858        0.040727           0.9244   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007765             0.0764  ...        0.021135           0.8940   \n",
       "  2         0.010621             0.1858  ...        0.014440           0.8274   \n",
       "  3         0.008216             0.2910  ...        0.016837           0.7948   \n",
       "  4         0.018708             0.3956  ...        0.009083           0.7958   \n",
       "  5         0.019524             0.5098  ...        0.004266           0.8076   \n",
       "  6         0.013813             0.6198  ...        0.004278           0.8194   \n",
       "  7         0.009055             0.7284  ...        0.006877           0.8136   \n",
       "  8         0.007694             0.8312  ...        0.005215           0.7944   \n",
       "  9         0.003362             0.9248  ...        0.004025           0.7542   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              419.0   \n",
       "  1         0.026898                   0.1              419.0   \n",
       "  2         0.008961                   0.2              419.0   \n",
       "  3         0.014167                   0.3              419.0   \n",
       "  4         0.022152                   0.4              419.0   \n",
       "  5         0.026387                   0.5              419.0   \n",
       "  6         0.030713                   0.6              419.0   \n",
       "  7         0.067125                   0.7              419.0   \n",
       "  8         0.057830                   0.8              419.0   \n",
       "  9         0.091048                   0.9              419.0   \n",
       "  10        0.000000                   1.0              419.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7763.0                10.0                 270.0   \n",
       "  1                7763.0                10.0                 270.0   \n",
       "  2                7763.0                10.0                 270.0   \n",
       "  3                7763.0                10.0                 270.0   \n",
       "  4                7763.0                10.0                 270.0   \n",
       "  5                7763.0                10.0                 270.0   \n",
       "  6                7763.0                10.0                 270.0   \n",
       "  7                7763.0                10.0                 270.0   \n",
       "  8                7763.0                10.0                 270.0   \n",
       "  9                7763.0                10.0                 270.0   \n",
       "  10               7763.0                10.0                 270.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                20.0                548.0  \n",
       "  1                20.0                548.0  \n",
       "  2                20.0                548.0  \n",
       "  3                20.0                548.0  \n",
       "  4                20.0                548.0  \n",
       "  5                20.0                548.0  \n",
       "  6                20.0                548.0  \n",
       "  7                20.0                548.0  \n",
       "  8                20.0                548.0  \n",
       "  9                20.0                548.0  \n",
       "  10               20.0                548.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9190      0.006403           0.9194   \n",
       "  2                  0.2         0.8146      0.008414           0.8142   \n",
       "  3                  0.3         0.7100      0.011380           0.7092   \n",
       "  4                  0.4         0.6012      0.016254           0.6002   \n",
       "  5                  0.5         0.4904      0.017827           0.4896   \n",
       "  6                  0.6         0.3806      0.013539           0.3796   \n",
       "  7                  0.7         0.2784      0.010164           0.2778   \n",
       "  8                  0.8         0.1758      0.008075           0.1750   \n",
       "  9                  0.9         0.0770      0.010607           0.0778   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005727           0.9018        0.075440           0.0810   \n",
       "  2         0.009418           0.8334        0.086624           0.1854   \n",
       "  3         0.011520           0.7404        0.057782           0.2900   \n",
       "  4         0.015802           0.6328        0.080831           0.3988   \n",
       "  5         0.017827           0.5200        0.080753           0.5096   \n",
       "  6         0.014153           0.4218        0.043436           0.6194   \n",
       "  7         0.009960           0.3090        0.076332           0.7216   \n",
       "  8         0.007714           0.2160        0.049046           0.8242   \n",
       "  9         0.010330           0.0590        0.028732           0.9230   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.006403             0.0806  ...        0.010440           0.8750   \n",
       "  2         0.008414             0.1858  ...        0.012578           0.8238   \n",
       "  3         0.011380             0.2908  ...        0.015748           0.7920   \n",
       "  4         0.016254             0.3998  ...        0.017743           0.8066   \n",
       "  5         0.017827             0.5104  ...        0.018730           0.8094   \n",
       "  6         0.013539             0.6204  ...        0.014543           0.8236   \n",
       "  7         0.010164             0.7222  ...        0.011203           0.7760   \n",
       "  8         0.008075             0.8250  ...        0.006058           0.8472   \n",
       "  9         0.010607             0.9222  ...        0.000000           0.8834   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              204.0   \n",
       "  1         0.091214                   0.1              204.0   \n",
       "  2         0.081904                   0.2              204.0   \n",
       "  3         0.071144                   0.3              204.0   \n",
       "  4         0.091106                   0.4              204.0   \n",
       "  5         0.110258                   0.5              204.0   \n",
       "  6         0.106338                   0.6              204.0   \n",
       "  7         0.137222                   0.7              204.0   \n",
       "  8         0.101927                   0.8              204.0   \n",
       "  9         0.162335                   0.9              204.0   \n",
       "  10        0.000000                   1.0              204.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7414.0                15.0                 245.0   \n",
       "  1                7414.0                15.0                 245.0   \n",
       "  2                7414.0                15.0                 245.0   \n",
       "  3                7414.0                15.0                 245.0   \n",
       "  4                7414.0                15.0                 245.0   \n",
       "  5                7414.0                15.0                 245.0   \n",
       "  6                7414.0                15.0                 245.0   \n",
       "  7                7414.0                15.0                 245.0   \n",
       "  8                7414.0                15.0                 245.0   \n",
       "  9                7414.0                15.0                 245.0   \n",
       "  10               7414.0                15.0                 245.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                31.0                543.0  \n",
       "  1                31.0                543.0  \n",
       "  2                31.0                543.0  \n",
       "  3                31.0                543.0  \n",
       "  4                31.0                543.0  \n",
       "  5                31.0                543.0  \n",
       "  6                31.0                543.0  \n",
       "  7                31.0                543.0  \n",
       "  8                31.0                543.0  \n",
       "  9                31.0                543.0  \n",
       "  10               31.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns]],\n",
       " 'pred_score_original': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8474      0.010668           0.8484   \n",
       "  2                  0.2         0.7594      0.014328           0.7700   \n",
       "  3                  0.3         0.6468      0.012478           0.6562   \n",
       "  4                  0.4         0.5200      0.016401           0.5326   \n",
       "  5                  0.5         0.4084      0.016742           0.4240   \n",
       "  6                  0.6         0.3084      0.013465           0.3220   \n",
       "  7                  0.7         0.2182      0.008497           0.2316   \n",
       "  8                  0.8         0.1302      0.007981           0.1386   \n",
       "  9                  0.9         0.0618      0.005762           0.0656   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.013107           0.8276        0.063433           0.1526   \n",
       "  2         0.017000           0.6000        0.042202           0.2406   \n",
       "  3         0.014940           0.5054        0.053496           0.3532   \n",
       "  4         0.019165           0.3280        0.036049           0.4800   \n",
       "  5         0.017393           0.1724        0.045583           0.5916   \n",
       "  6         0.014933           0.1000        0.042036           0.6916   \n",
       "  7         0.010139           0.0112        0.025044           0.7818   \n",
       "  8         0.008735           0.0000        0.000000           0.8698   \n",
       "  9         0.005941           0.0000        0.000000           0.9382   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.010668             0.1516  ...        0.025245           0.7400   \n",
       "  2         0.014328             0.2300  ...        0.022061           0.5840   \n",
       "  3         0.012478             0.3438  ...        0.030822           0.5816   \n",
       "  4         0.016401             0.4674  ...        0.021767           0.5828   \n",
       "  5         0.016742             0.5760  ...        0.019499           0.5322   \n",
       "  6         0.013465             0.6780  ...        0.011606           0.4896   \n",
       "  7         0.008497             0.7684  ...        0.004980           0.0800   \n",
       "  8         0.007981             0.8614  ...        0.006856           0.0000   \n",
       "  9         0.005762             0.9344  ...        0.012522           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              322.0   \n",
       "  1         0.065065                   0.1              322.0   \n",
       "  2         0.038432                   0.2              322.0   \n",
       "  3         0.060335                   0.3              322.0   \n",
       "  4         0.084233                   0.4              322.0   \n",
       "  5         0.070436                   0.5              322.0   \n",
       "  6         0.137092                   0.6              322.0   \n",
       "  7         0.178885                   0.7              322.0   \n",
       "  8         0.000000                   0.8              322.0   \n",
       "  9         0.000000                   0.9              322.0   \n",
       "  10        0.000000                   1.0              322.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8179.0                25.0                 240.0   \n",
       "  1                8179.0                25.0                 240.0   \n",
       "  2                8179.0                25.0                 240.0   \n",
       "  3                8179.0                25.0                 240.0   \n",
       "  4                8179.0                25.0                 240.0   \n",
       "  5                8179.0                25.0                 240.0   \n",
       "  6                8179.0                25.0                 240.0   \n",
       "  7                8179.0                25.0                 240.0   \n",
       "  8                8179.0                25.0                 240.0   \n",
       "  9                8179.0                25.0                 240.0   \n",
       "  10               8179.0                25.0                 240.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                554.0  \n",
       "  1                36.0                554.0  \n",
       "  2                36.0                554.0  \n",
       "  3                36.0                554.0  \n",
       "  4                36.0                554.0  \n",
       "  5                36.0                554.0  \n",
       "  6                36.0                554.0  \n",
       "  7                36.0                554.0  \n",
       "  8                36.0                554.0  \n",
       "  9                36.0                554.0  \n",
       "  10               36.0                554.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8856      0.005367           0.8762   \n",
       "  2                  0.2         0.7632      0.016589           0.7572   \n",
       "  3                  0.3         0.6458      0.008319           0.6372   \n",
       "  4                  0.4         0.5678      0.011432           0.5674   \n",
       "  5                  0.5         0.4710      0.014018           0.4726   \n",
       "  6                  0.6         0.3476      0.018623           0.3588   \n",
       "  7                  0.7         0.2270      0.024829           0.2406   \n",
       "  8                  0.8         0.1240      0.017734           0.1274   \n",
       "  9                  0.9         0.0402      0.005933           0.0396   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006648           0.9674        0.011502           0.1144   \n",
       "  2         0.016544           0.8164        0.032098           0.2368   \n",
       "  3         0.008927           0.7224        0.011502           0.3542   \n",
       "  4         0.012116           0.5712        0.038219           0.4322   \n",
       "  5         0.014082           0.4572        0.055111           0.5290   \n",
       "  6         0.024253           0.2488        0.044421           0.6524   \n",
       "  7         0.026754           0.1060        0.008944           0.7730   \n",
       "  8         0.019655           0.0940        0.010954           0.8760   \n",
       "  9         0.004775           0.0448        0.017094           0.9598   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.005367             0.1238  ...        0.050574           0.9364   \n",
       "  2         0.016589             0.2428  ...        0.018371           0.7714   \n",
       "  3         0.008319             0.3628  ...        0.013590           0.7270   \n",
       "  4         0.011432             0.4326  ...        0.020416           0.6930   \n",
       "  5         0.014018             0.5274  ...        0.019537           0.7056   \n",
       "  6         0.018623             0.6412  ...        0.009607           0.6644   \n",
       "  7         0.024829             0.7594  ...        0.010257           0.6690   \n",
       "  8         0.017734             0.8726  ...        0.013864           0.8456   \n",
       "  9         0.005933             0.9604  ...        0.000000           0.9500   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              901.0   \n",
       "  1         0.022568                   0.1              901.0   \n",
       "  2         0.029754                   0.2              901.0   \n",
       "  3         0.017277                   0.3              901.0   \n",
       "  4         0.024083                   0.4              901.0   \n",
       "  5         0.036991                   0.5              901.0   \n",
       "  6         0.078888                   0.6              901.0   \n",
       "  7         0.044514                   0.7              901.0   \n",
       "  8         0.145254                   0.8              901.0   \n",
       "  9         0.111803                   0.9              901.0   \n",
       "  10        0.000000                   1.0              901.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6290.0                27.0                 231.0   \n",
       "  1                6290.0                27.0                 231.0   \n",
       "  2                6290.0                27.0                 231.0   \n",
       "  3                6290.0                27.0                 231.0   \n",
       "  4                6290.0                27.0                 231.0   \n",
       "  5                6290.0                27.0                 231.0   \n",
       "  6                6290.0                27.0                 231.0   \n",
       "  7                6290.0                27.0                 231.0   \n",
       "  8                6290.0                27.0                 231.0   \n",
       "  9                6290.0                27.0                 231.0   \n",
       "  10               6290.0                27.0                 231.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                49.0                441.0  \n",
       "  1                49.0                441.0  \n",
       "  2                49.0                441.0  \n",
       "  3                49.0                441.0  \n",
       "  4                49.0                441.0  \n",
       "  5                49.0                441.0  \n",
       "  6                49.0                441.0  \n",
       "  7                49.0                441.0  \n",
       "  8                49.0                441.0  \n",
       "  9                49.0                441.0  \n",
       "  10               49.0                441.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8856      0.012973           0.8844   \n",
       "  2                  0.2         0.8122      0.016223           0.8106   \n",
       "  3                  0.3         0.7068      0.016270           0.7072   \n",
       "  4                  0.4         0.5872      0.015802           0.5938   \n",
       "  5                  0.5         0.4564      0.022700           0.4656   \n",
       "  6                  0.6         0.3374      0.035543           0.3442   \n",
       "  7                  0.7         0.2194      0.015947           0.2238   \n",
       "  8                  0.8         0.1278      0.014822           0.1302   \n",
       "  9                  0.9         0.0550      0.005050           0.0560   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.014046           0.9454        0.049843           0.1144   \n",
       "  2         0.017097           0.8908        0.040696           0.1878   \n",
       "  3         0.016709           0.6724        0.049843           0.2932   \n",
       "  4         0.015675           0.2548        0.118649           0.4128   \n",
       "  5         0.023469           0.0000        0.000000           0.5436   \n",
       "  6         0.036300           0.0000        0.000000           0.6626   \n",
       "  7         0.016100           0.0000        0.000000           0.7806   \n",
       "  8         0.015023           0.0000        0.000000           0.8722   \n",
       "  9         0.005050           0.0000        0.000000           0.9450   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.012973             0.1156  ...        0.073836           0.9214   \n",
       "  2         0.016223             0.1894  ...        0.037493           0.8592   \n",
       "  3         0.016270             0.2928  ...        0.045395           0.7264   \n",
       "  4         0.015802             0.4062  ...        0.014977           0.6576   \n",
       "  5         0.022700             0.5344  ...        0.002828           0.0000   \n",
       "  6         0.035543             0.6558  ...        0.002236           0.0000   \n",
       "  7         0.015947             0.7762  ...        0.000000           0.0000   \n",
       "  8         0.014822             0.8698  ...        0.000000           0.0000   \n",
       "  9         0.005050             0.9440  ...        0.000000           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              373.0   \n",
       "  1         0.072127                   0.1              373.0   \n",
       "  2         0.034989                   0.2              373.0   \n",
       "  3         0.031848                   0.3              373.0   \n",
       "  4         0.123735                   0.4              373.0   \n",
       "  5         0.000000                   0.5              373.0   \n",
       "  6         0.000000                   0.6              373.0   \n",
       "  7         0.000000                   0.7              373.0   \n",
       "  8         0.000000                   0.8              373.0   \n",
       "  9         0.000000                   0.9              373.0   \n",
       "  10        0.000000                   1.0              373.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8370.0                 3.0                 282.0   \n",
       "  1                8370.0                 3.0                 282.0   \n",
       "  2                8370.0                 3.0                 282.0   \n",
       "  3                8370.0                 3.0                 282.0   \n",
       "  4                8370.0                 3.0                 282.0   \n",
       "  5                8370.0                 3.0                 282.0   \n",
       "  6                8370.0                 3.0                 282.0   \n",
       "  7                8370.0                 3.0                 282.0   \n",
       "  8                8370.0                 3.0                 282.0   \n",
       "  9                8370.0                 3.0                 282.0   \n",
       "  10               8370.0                 3.0                 282.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                11.0                549.0  \n",
       "  1                11.0                549.0  \n",
       "  2                11.0                549.0  \n",
       "  3                11.0                549.0  \n",
       "  4                11.0                549.0  \n",
       "  5                11.0                549.0  \n",
       "  6                11.0                549.0  \n",
       "  7                11.0                549.0  \n",
       "  8                11.0                549.0  \n",
       "  9                11.0                549.0  \n",
       "  10               11.0                549.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8352      0.016514           0.8334   \n",
       "  2                  0.2         0.7324      0.022300           0.7282   \n",
       "  3                  0.3         0.6594      0.020244           0.6568   \n",
       "  4                  0.4         0.5680      0.011225           0.5662   \n",
       "  5                  0.5         0.4554      0.010738           0.4548   \n",
       "  6                  0.6         0.3444      0.019269           0.3452   \n",
       "  7                  0.7         0.2436      0.011866           0.2436   \n",
       "  8                  0.8         0.1518      0.016962           0.1550   \n",
       "  9                  0.9         0.0852      0.010498           0.0866   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.018270           0.8948        0.037124           0.1648   \n",
       "  2         0.024530           0.8526        0.044343           0.2676   \n",
       "  3         0.020693           0.7368        0.037124           0.3406   \n",
       "  4         0.011212           0.6106        0.079983           0.4320   \n",
       "  5         0.012677           0.4632        0.057786           0.5446   \n",
       "  6         0.021417           0.3264        0.077803           0.6556   \n",
       "  7         0.013202           0.2422        0.028482           0.7564   \n",
       "  8         0.017678           0.0530        0.000000           0.8482   \n",
       "  9         0.011082           0.0424        0.023702           0.9148   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.016514             0.1666  ...        0.055094           0.8504   \n",
       "  2         0.022300             0.2718  ...        0.038739           0.8318   \n",
       "  3         0.020244             0.3432  ...        0.040224           0.7526   \n",
       "  4         0.011225             0.4338  ...        0.035592           0.8040   \n",
       "  5         0.010738             0.5452  ...        0.032105           0.7892   \n",
       "  6         0.019269             0.6548  ...        0.021698           0.7538   \n",
       "  7         0.011866             0.7564  ...        0.018366           0.7218   \n",
       "  8         0.016962             0.8450  ...        0.011756           0.4666   \n",
       "  9         0.010498             0.9134  ...        0.000000           0.4000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              386.0   \n",
       "  1         0.045286                   0.1              386.0   \n",
       "  2         0.044902                   0.2              386.0   \n",
       "  3         0.029126                   0.3              386.0   \n",
       "  4         0.060083                   0.4              386.0   \n",
       "  5         0.045466                   0.5              386.0   \n",
       "  6         0.084319                   0.6              386.0   \n",
       "  7         0.048220                   0.7              386.0   \n",
       "  8         0.074685                   0.8              386.0   \n",
       "  9         0.223607                   0.9              386.0   \n",
       "  10        0.000000                   1.0              386.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7233.0                10.0                 250.0   \n",
       "  1                7233.0                10.0                 250.0   \n",
       "  2                7233.0                10.0                 250.0   \n",
       "  3                7233.0                10.0                 250.0   \n",
       "  4                7233.0                10.0                 250.0   \n",
       "  5                7233.0                10.0                 250.0   \n",
       "  6                7233.0                10.0                 250.0   \n",
       "  7                7233.0                10.0                 250.0   \n",
       "  8                7233.0                10.0                 250.0   \n",
       "  9                7233.0                10.0                 250.0   \n",
       "  10               7233.0                10.0                 250.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                19.0                558.0  \n",
       "  1                19.0                558.0  \n",
       "  2                19.0                558.0  \n",
       "  3                19.0                558.0  \n",
       "  4                19.0                558.0  \n",
       "  5                19.0                558.0  \n",
       "  6                19.0                558.0  \n",
       "  7                19.0                558.0  \n",
       "  8                19.0                558.0  \n",
       "  9                19.0                558.0  \n",
       "  10               19.0                558.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8610      0.009618           0.8520   \n",
       "  2                  0.2         0.7192      0.010545           0.7168   \n",
       "  3                  0.3         0.6530      0.005477           0.6654   \n",
       "  4                  0.4         0.5658      0.005762           0.5830   \n",
       "  5                  0.5         0.4790      0.013565           0.4966   \n",
       "  6                  0.6         0.3816      0.004775           0.4018   \n",
       "  7                  0.7         0.2900      0.009083           0.3054   \n",
       "  8                  0.8         0.1866      0.010139           0.1948   \n",
       "  9                  0.9         0.0886      0.009317           0.0928   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.011068           0.9360        0.026870           0.1390   \n",
       "  2         0.013480           0.7392        0.041439           0.2808   \n",
       "  3         0.005857           0.5502        0.026329           0.3470   \n",
       "  4         0.005385           0.4288        0.025104           0.4342   \n",
       "  5         0.013088           0.3320        0.032342           0.5210   \n",
       "  6         0.004658           0.2180        0.047891           0.6184   \n",
       "  7         0.007403           0.1644        0.026397           0.7100   \n",
       "  8         0.009149           0.1214        0.039023           0.8134   \n",
       "  9         0.011122           0.0538        0.012377           0.9114   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.009618             0.1480  ...        0.014328           0.9254   \n",
       "  2         0.010545             0.2832  ...        0.012911           0.9284   \n",
       "  3         0.005477             0.3346  ...        0.011610           0.9396   \n",
       "  4         0.005762             0.4170  ...        0.012050           0.9452   \n",
       "  5         0.013565             0.5034  ...        0.007396           0.9794   \n",
       "  6         0.004775             0.5982  ...        0.006986           0.9882   \n",
       "  7         0.009083             0.6946  ...        0.004183           1.0000   \n",
       "  8         0.010139             0.8052  ...        0.009497           1.0000   \n",
       "  9         0.009317             0.9072  ...        0.028190           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1094.0   \n",
       "  1         0.030916                   0.1             1094.0   \n",
       "  2         0.017516                   0.2             1094.0   \n",
       "  3         0.029305                   0.3             1094.0   \n",
       "  4         0.020376                   0.4             1094.0   \n",
       "  5         0.028228                   0.5             1094.0   \n",
       "  6         0.026386                   0.6             1094.0   \n",
       "  7         0.000000                   0.7             1094.0   \n",
       "  8         0.000000                   0.8             1094.0   \n",
       "  9         0.000000                   0.9             1094.0   \n",
       "  10        0.000000                   1.0             1094.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5719.0                38.0                 195.0   \n",
       "  1                5719.0                38.0                 195.0   \n",
       "  2                5719.0                38.0                 195.0   \n",
       "  3                5719.0                38.0                 195.0   \n",
       "  4                5719.0                38.0                 195.0   \n",
       "  5                5719.0                38.0                 195.0   \n",
       "  6                5719.0                38.0                 195.0   \n",
       "  7                5719.0                38.0                 195.0   \n",
       "  8                5719.0                38.0                 195.0   \n",
       "  9                5719.0                38.0                 195.0   \n",
       "  10               5719.0                38.0                 195.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                56.0                457.0  \n",
       "  1                56.0                457.0  \n",
       "  2                56.0                457.0  \n",
       "  3                56.0                457.0  \n",
       "  4                56.0                457.0  \n",
       "  5                56.0                457.0  \n",
       "  6                56.0                457.0  \n",
       "  7                56.0                457.0  \n",
       "  8                56.0                457.0  \n",
       "  9                56.0                457.0  \n",
       "  10               56.0                457.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8238      0.009497           0.8250   \n",
       "  2                  0.2         0.7082      0.011234           0.7146   \n",
       "  3                  0.3         0.6300      0.010296           0.6434   \n",
       "  4                  0.4         0.5328      0.007362           0.5498   \n",
       "  5                  0.5         0.4364      0.010262           0.4544   \n",
       "  6                  0.6         0.3346      0.011824           0.3518   \n",
       "  7                  0.7         0.2242      0.012736           0.2380   \n",
       "  8                  0.8         0.1274      0.017038           0.1352   \n",
       "  9                  0.9         0.0522      0.006686           0.0550   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.007382            0.810        0.057554           0.1762   \n",
       "  2         0.010968            0.615        0.037914           0.2918   \n",
       "  3         0.010262            0.445        0.054199           0.3700   \n",
       "  4         0.009757            0.300        0.058630           0.4672   \n",
       "  5         0.013315            0.190        0.051841           0.5636   \n",
       "  6         0.013330            0.095        0.020917           0.6654   \n",
       "  7         0.013601            0.040        0.013693           0.7758   \n",
       "  8         0.018526            0.025        0.017678           0.8726   \n",
       "  9         0.007778            0.015        0.013693           0.9478   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.009497             0.1750  ...        0.015515           0.7202   \n",
       "  2         0.011234             0.2854  ...        0.016208           0.6174   \n",
       "  3         0.010296             0.3566  ...        0.012837           0.6002   \n",
       "  4         0.007362             0.4502  ...        0.019680           0.5810   \n",
       "  5         0.010262             0.5456  ...        0.010262           0.5706   \n",
       "  6         0.011824             0.6482  ...        0.009935           0.6016   \n",
       "  7         0.012736             0.7620  ...        0.014300           0.4868   \n",
       "  8         0.017038             0.8648  ...        0.020741           0.6666   \n",
       "  9         0.006686             0.9450  ...        0.020861           0.6000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              515.0   \n",
       "  1         0.064115                   0.1              515.0   \n",
       "  2         0.038201                   0.2              515.0   \n",
       "  3         0.044218                   0.3              515.0   \n",
       "  4         0.055218                   0.4              515.0   \n",
       "  5         0.104832                   0.5              515.0   \n",
       "  6         0.190001                   0.6              515.0   \n",
       "  7         0.196791                   0.7              515.0   \n",
       "  8         0.471463                   0.8              515.0   \n",
       "  9         0.547723                   0.9              515.0   \n",
       "  10        0.000000                   1.0              515.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7542.0                28.0                 234.0   \n",
       "  1                7542.0                28.0                 234.0   \n",
       "  2                7542.0                28.0                 234.0   \n",
       "  3                7542.0                28.0                 234.0   \n",
       "  4                7542.0                28.0                 234.0   \n",
       "  5                7542.0                28.0                 234.0   \n",
       "  6                7542.0                28.0                 234.0   \n",
       "  7                7542.0                28.0                 234.0   \n",
       "  8                7542.0                28.0                 234.0   \n",
       "  9                7542.0                28.0                 234.0   \n",
       "  10               7542.0                28.0                 234.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                40.0                543.0  \n",
       "  1                40.0                543.0  \n",
       "  2                40.0                543.0  \n",
       "  3                40.0                543.0  \n",
       "  4                40.0                543.0  \n",
       "  5                40.0                543.0  \n",
       "  6                40.0                543.0  \n",
       "  7                40.0                543.0  \n",
       "  8                40.0                543.0  \n",
       "  9                40.0                543.0  \n",
       "  10               40.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8710      0.004243           0.8694   \n",
       "  2                  0.2         0.7654      0.010334           0.7716   \n",
       "  3                  0.3         0.6726      0.016456           0.6810   \n",
       "  4                  0.4         0.5752      0.015912           0.5898   \n",
       "  5                  0.5         0.4688      0.014805           0.4868   \n",
       "  6                  0.6         0.3600      0.020149           0.3786   \n",
       "  7                  0.7         0.2690      0.010100           0.2862   \n",
       "  8                  0.8         0.1790      0.012961           0.1908   \n",
       "  9                  0.9         0.0932      0.006723           0.0978   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.002608           0.8834        0.036508           0.1290   \n",
       "  2         0.010065           0.6834        0.037045           0.2346   \n",
       "  3         0.014595           0.5666        0.054095           0.3274   \n",
       "  4         0.013103           0.3834        0.053210           0.4248   \n",
       "  5         0.014412           0.2388        0.050865           0.5312   \n",
       "  6         0.017743           0.1168        0.060334           0.6400   \n",
       "  7         0.010257           0.0448        0.015336           0.7310   \n",
       "  8         0.013554           0.0336        0.012522           0.8210   \n",
       "  9         0.007190           0.0280        0.000000           0.9068   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004243             0.1306  ...        0.006042           0.8074   \n",
       "  2         0.010334             0.2284  ...        0.007403           0.6740   \n",
       "  3         0.016456             0.3190  ...        0.018229           0.6700   \n",
       "  4         0.015912             0.4102  ...        0.016637           0.6980   \n",
       "  5         0.014805             0.5132  ...        0.019486           0.6934   \n",
       "  6         0.020149             0.6214  ...        0.008792           0.5312   \n",
       "  7         0.010100             0.7138  ...        0.003834           0.3900   \n",
       "  8         0.012961             0.8092  ...        0.006025           0.6000   \n",
       "  9         0.006723             0.9022  ...        0.000000           0.9000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              338.0   \n",
       "  1         0.060587                   0.1              338.0   \n",
       "  2         0.040847                   0.2              338.0   \n",
       "  3         0.065464                   0.3              338.0   \n",
       "  4         0.047096                   0.4              338.0   \n",
       "  5         0.027610                   0.5              338.0   \n",
       "  6         0.126537                   0.6              338.0   \n",
       "  7         0.089443                   0.7              338.0   \n",
       "  8         0.252872                   0.8              338.0   \n",
       "  9         0.223607                   0.9              338.0   \n",
       "  10        0.000000                   1.0              338.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6362.0                18.0                 192.0   \n",
       "  1                6362.0                18.0                 192.0   \n",
       "  2                6362.0                18.0                 192.0   \n",
       "  3                6362.0                18.0                 192.0   \n",
       "  4                6362.0                18.0                 192.0   \n",
       "  5                6362.0                18.0                 192.0   \n",
       "  6                6362.0                18.0                 192.0   \n",
       "  7                6362.0                18.0                 192.0   \n",
       "  8                6362.0                18.0                 192.0   \n",
       "  9                6362.0                18.0                 192.0   \n",
       "  10               6362.0                18.0                 192.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                466.0  \n",
       "  1                36.0                466.0  \n",
       "  2                36.0                466.0  \n",
       "  3                36.0                466.0  \n",
       "  4                36.0                466.0  \n",
       "  5                36.0                466.0  \n",
       "  6                36.0                466.0  \n",
       "  7                36.0                466.0  \n",
       "  8                36.0                466.0  \n",
       "  9                36.0                466.0  \n",
       "  10               36.0                466.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8466      0.016920           0.8262   \n",
       "  2                  0.2         0.6966      0.013126           0.6740   \n",
       "  3                  0.3         0.5720      0.009274           0.5520   \n",
       "  4                  0.4         0.4988      0.016022           0.4952   \n",
       "  5                  0.5         0.4246      0.014741           0.4342   \n",
       "  6                  0.6         0.3354      0.017573           0.3502   \n",
       "  7                  0.7         0.2204      0.011589           0.2380   \n",
       "  8                  0.8         0.1260      0.009513           0.1340   \n",
       "  9                  0.9         0.0580      0.010863           0.0564   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.016022           0.9462        0.024427           0.1534   \n",
       "  2         0.012329           0.8064        0.029014           0.3034   \n",
       "  3         0.010344           0.6698        0.032507           0.4280   \n",
       "  4         0.019817           0.5168        0.026224           0.5012   \n",
       "  5         0.016362           0.3776        0.006025           0.5754   \n",
       "  6         0.023210           0.2628        0.023317           0.6646   \n",
       "  7         0.014440           0.1346        0.026331           0.7796   \n",
       "  8         0.007280           0.0876        0.026661           0.8740   \n",
       "  9         0.009659           0.0672        0.023690           0.9420   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.016920             0.1738  ...        0.021698           0.9132   \n",
       "  2         0.013126             0.3260  ...        0.010738           0.8002   \n",
       "  3         0.009274             0.4480  ...        0.017225           0.8208   \n",
       "  4         0.016022             0.5048  ...        0.023868           0.8370   \n",
       "  5         0.014741             0.5658  ...        0.008927           0.8594   \n",
       "  6         0.017573             0.6498  ...        0.006804           0.8756   \n",
       "  7         0.011589             0.7620  ...        0.019583           0.8512   \n",
       "  8         0.009513             0.8660  ...        0.017799           0.9550   \n",
       "  9         0.010863             0.9436  ...        0.031807           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1032.0   \n",
       "  1         0.037218                   0.1             1032.0   \n",
       "  2         0.031284                   0.2             1032.0   \n",
       "  3         0.032484                   0.3             1032.0   \n",
       "  4         0.031512                   0.4             1032.0   \n",
       "  5         0.049642                   0.5             1032.0   \n",
       "  6         0.057055                   0.6             1032.0   \n",
       "  7         0.087047                   0.7             1032.0   \n",
       "  8         0.062249                   0.8             1032.0   \n",
       "  9         0.000000                   0.9             1032.0   \n",
       "  10        0.000000                   1.0             1032.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5653.0                47.0                 181.0   \n",
       "  1                5653.0                47.0                 181.0   \n",
       "  2                5653.0                47.0                 181.0   \n",
       "  3                5653.0                47.0                 181.0   \n",
       "  4                5653.0                47.0                 181.0   \n",
       "  5                5653.0                47.0                 181.0   \n",
       "  6                5653.0                47.0                 181.0   \n",
       "  7                5653.0                47.0                 181.0   \n",
       "  8                5653.0                47.0                 181.0   \n",
       "  9                5653.0                47.0                 181.0   \n",
       "  10               5653.0                47.0                 181.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                89.0                433.0  \n",
       "  1                89.0                433.0  \n",
       "  2                89.0                433.0  \n",
       "  3                89.0                433.0  \n",
       "  4                89.0                433.0  \n",
       "  5                89.0                433.0  \n",
       "  6                89.0                433.0  \n",
       "  7                89.0                433.0  \n",
       "  8                89.0                433.0  \n",
       "  9                89.0                433.0  \n",
       "  10               89.0                433.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8934      0.011238           0.8962   \n",
       "  2                  0.2         0.8016      0.012300           0.8084   \n",
       "  3                  0.3         0.6892      0.021324           0.6994   \n",
       "  4                  0.4         0.5662      0.027743           0.5746   \n",
       "  5                  0.5         0.4432      0.023889           0.4498   \n",
       "  6                  0.6         0.3452      0.014114           0.3502   \n",
       "  7                  0.7         0.2366      0.008019           0.2402   \n",
       "  8                  0.8         0.1518      0.008758           0.1540   \n",
       "  9                  0.9         0.0748      0.002950           0.0762   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.011256            0.700        0.142522           0.1066   \n",
       "  2         0.012095            0.325        0.142522           0.1984   \n",
       "  3         0.021606            0.000        0.000000           0.3108   \n",
       "  4         0.028201            0.000        0.000000           0.4338   \n",
       "  5         0.024366            0.000        0.000000           0.5568   \n",
       "  6         0.014114            0.000        0.000000           0.6548   \n",
       "  7         0.007950            0.000        0.000000           0.7634   \n",
       "  8         0.009083            0.000        0.000000           0.8482   \n",
       "  9         0.002864            0.000        0.000000           0.9252   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.011238             0.1038  ...        0.023860           0.3858   \n",
       "  2         0.012300             0.1916  ...        0.048900           0.3424   \n",
       "  3         0.021324             0.3006  ...        0.006269           0.0000   \n",
       "  4         0.027743             0.4254  ...        0.001949           0.0000   \n",
       "  5         0.023889             0.5502  ...        0.002191           0.0000   \n",
       "  6         0.014114             0.6498  ...        0.002739           0.0000   \n",
       "  7         0.008019             0.7598  ...        0.003130           0.0000   \n",
       "  8         0.008758             0.8460  ...        0.000000           0.0000   \n",
       "  9         0.002950             0.9238  ...        0.000000           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              295.0   \n",
       "  1         0.247796                   0.1              295.0   \n",
       "  2         0.086590                   0.2              295.0   \n",
       "  3         0.000000                   0.3              295.0   \n",
       "  4         0.000000                   0.4              295.0   \n",
       "  5         0.000000                   0.5              295.0   \n",
       "  6         0.000000                   0.6              295.0   \n",
       "  7         0.000000                   0.7              295.0   \n",
       "  8         0.000000                   0.8              295.0   \n",
       "  9         0.000000                   0.9              295.0   \n",
       "  10        0.000000                   1.0              295.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7742.0                 4.0                 242.0   \n",
       "  1                7742.0                 4.0                 242.0   \n",
       "  2                7742.0                 4.0                 242.0   \n",
       "  3                7742.0                 4.0                 242.0   \n",
       "  4                7742.0                 4.0                 242.0   \n",
       "  5                7742.0                 4.0                 242.0   \n",
       "  6                7742.0                 4.0                 242.0   \n",
       "  7                7742.0                 4.0                 242.0   \n",
       "  8                7742.0                 4.0                 242.0   \n",
       "  9                7742.0                 4.0                 242.0   \n",
       "  10               7742.0                 4.0                 242.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                 8.0                543.0  \n",
       "  1                 8.0                543.0  \n",
       "  2                 8.0                543.0  \n",
       "  3                 8.0                543.0  \n",
       "  4                 8.0                543.0  \n",
       "  5                 8.0                543.0  \n",
       "  6                 8.0                543.0  \n",
       "  7                 8.0                543.0  \n",
       "  8                 8.0                543.0  \n",
       "  9                 8.0                543.0  \n",
       "  10                8.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8334      0.006877           0.8160   \n",
       "  2                  0.2         0.7036      0.009397           0.6800   \n",
       "  3                  0.3         0.6240      0.008093           0.6094   \n",
       "  4                  0.4         0.5234      0.007503           0.5144   \n",
       "  5                  0.5         0.4122      0.009039           0.4190   \n",
       "  6                  0.6         0.3146      0.016087           0.3296   \n",
       "  7                  0.7         0.2288      0.007120           0.2414   \n",
       "  8                  0.8         0.1410      0.007969           0.1448   \n",
       "  9                  0.9         0.0634      0.005367           0.0614   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009274           0.9552        0.011713           0.1666   \n",
       "  2         0.010677           0.8730        0.009899           0.2964   \n",
       "  3         0.007925           0.7296        0.036760           0.3760   \n",
       "  4         0.007127           0.5888        0.021206           0.4766   \n",
       "  5         0.011136           0.3632        0.033425           0.5878   \n",
       "  6         0.016577           0.2082        0.025044           0.6854   \n",
       "  7         0.008877           0.1382        0.006261           0.7712   \n",
       "  8         0.009859           0.1102        0.011713           0.8590   \n",
       "  9         0.004775           0.0762        0.013027           0.9366   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.006877             0.1840  ...        0.012677           0.9500   \n",
       "  2         0.009397             0.3200  ...        0.014983           0.9280   \n",
       "  3         0.008093             0.3906  ...        0.008426           0.9346   \n",
       "  4         0.007503             0.4856  ...        0.009354           0.9544   \n",
       "  5         0.009039             0.5810  ...        0.010794           0.9352   \n",
       "  6         0.016087             0.6704  ...        0.012542           0.9138   \n",
       "  7         0.007120             0.7586  ...        0.010607           0.9254   \n",
       "  8         0.007969             0.8552  ...        0.017556           0.9800   \n",
       "  9         0.005367             0.9386  ...        0.031769           0.9714   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              933.0   \n",
       "  1         0.012865                   0.1              933.0   \n",
       "  2         0.011068                   0.2              933.0   \n",
       "  3         0.016682                   0.3              933.0   \n",
       "  4         0.001949                   0.4              933.0   \n",
       "  5         0.013461                   0.5              933.0   \n",
       "  6         0.030351                   0.6              933.0   \n",
       "  7         0.041884                   0.7              933.0   \n",
       "  8         0.044721                   0.8              933.0   \n",
       "  9         0.063952                   0.9              933.0   \n",
       "  10        0.000000                   1.0              933.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6687.0                29.0                 236.0   \n",
       "  1                6687.0                29.0                 236.0   \n",
       "  2                6687.0                29.0                 236.0   \n",
       "  3                6687.0                29.0                 236.0   \n",
       "  4                6687.0                29.0                 236.0   \n",
       "  5                6687.0                29.0                 236.0   \n",
       "  6                6687.0                29.0                 236.0   \n",
       "  7                6687.0                29.0                 236.0   \n",
       "  8                6687.0                29.0                 236.0   \n",
       "  9                6687.0                29.0                 236.0   \n",
       "  10               6687.0                29.0                 236.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                71.0                506.0  \n",
       "  1                71.0                506.0  \n",
       "  2                71.0                506.0  \n",
       "  3                71.0                506.0  \n",
       "  4                71.0                506.0  \n",
       "  5                71.0                506.0  \n",
       "  6                71.0                506.0  \n",
       "  7                71.0                506.0  \n",
       "  8                71.0                506.0  \n",
       "  9                71.0                506.0  \n",
       "  10               71.0                506.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8506      0.010090           0.8496   \n",
       "  2                  0.2         0.7608      0.016769           0.7656   \n",
       "  3                  0.3         0.6398      0.010986           0.6442   \n",
       "  4                  0.4         0.5332      0.008289           0.5410   \n",
       "  5                  0.5         0.4298      0.012296           0.4386   \n",
       "  6                  0.6         0.3310      0.014816           0.3364   \n",
       "  7                  0.7         0.2294      0.011371           0.2330   \n",
       "  8                  0.8         0.1388      0.007629           0.1406   \n",
       "  9                  0.9         0.0564      0.007503           0.0572   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.008933             0.88        0.057009           0.1494   \n",
       "  2         0.017729             0.63        0.044721           0.2392   \n",
       "  3         0.010895             0.52        0.027386           0.3602   \n",
       "  4         0.007450             0.31        0.065192           0.4668   \n",
       "  5         0.012178             0.19        0.022361           0.5702   \n",
       "  6         0.014943             0.18        0.044721           0.6690   \n",
       "  7         0.012689             0.14        0.041833           0.7706   \n",
       "  8         0.007537             0.10        0.035355           0.8612   \n",
       "  9         0.008167             0.04        0.022361           0.9436   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.010090             0.1504  ...        0.018743           0.8176   \n",
       "  2         0.016769             0.2344  ...        0.018700           0.5944   \n",
       "  3         0.010986             0.3558  ...        0.015758           0.5652   \n",
       "  4         0.008289             0.4590  ...        0.014412           0.4610   \n",
       "  5         0.012296             0.5614  ...        0.004494           0.4776   \n",
       "  6         0.014816             0.6636  ...        0.008307           0.5092   \n",
       "  7         0.011371             0.7670  ...        0.009263           0.6142   \n",
       "  8         0.007629             0.8594  ...        0.000000           0.7500   \n",
       "  9         0.007503             0.9428  ...        0.000000           0.8000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              419.0   \n",
       "  1         0.072679                   0.1              419.0   \n",
       "  2         0.035324                   0.2              419.0   \n",
       "  3         0.012598                   0.3              419.0   \n",
       "  4         0.077308                   0.4              419.0   \n",
       "  5         0.058833                   0.5              419.0   \n",
       "  6         0.103185                   0.6              419.0   \n",
       "  7         0.229038                   0.7              419.0   \n",
       "  8         0.276486                   0.8              419.0   \n",
       "  9         0.447214                   0.9              419.0   \n",
       "  10        0.000000                   1.0              419.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7763.0                10.0                 270.0   \n",
       "  1                7763.0                10.0                 270.0   \n",
       "  2                7763.0                10.0                 270.0   \n",
       "  3                7763.0                10.0                 270.0   \n",
       "  4                7763.0                10.0                 270.0   \n",
       "  5                7763.0                10.0                 270.0   \n",
       "  6                7763.0                10.0                 270.0   \n",
       "  7                7763.0                10.0                 270.0   \n",
       "  8                7763.0                10.0                 270.0   \n",
       "  9                7763.0                10.0                 270.0   \n",
       "  10               7763.0                10.0                 270.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                20.0                548.0  \n",
       "  1                20.0                548.0  \n",
       "  2                20.0                548.0  \n",
       "  3                20.0                548.0  \n",
       "  4                20.0                548.0  \n",
       "  5                20.0                548.0  \n",
       "  6                20.0                548.0  \n",
       "  7                20.0                548.0  \n",
       "  8                20.0                548.0  \n",
       "  9                20.0                548.0  \n",
       "  10               20.0                548.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8614      0.008532           0.8570   \n",
       "  2                  0.2         0.7746      0.009864           0.7742   \n",
       "  3                  0.3         0.6506      0.011546           0.6564   \n",
       "  4                  0.4         0.5428      0.017527           0.5498   \n",
       "  5                  0.5         0.4328      0.014061           0.4418   \n",
       "  6                  0.6         0.3254      0.016041           0.3322   \n",
       "  7                  0.7         0.2190      0.010223           0.2250   \n",
       "  8                  0.8         0.1224      0.009889           0.1270   \n",
       "  9                  0.9         0.0518      0.007662           0.0534   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007246           0.9354        0.039602           0.1386   \n",
       "  2         0.011100           0.7804        0.026773           0.2254   \n",
       "  3         0.013813           0.5484        0.064500           0.3494   \n",
       "  4         0.017152           0.4194        0.088093           0.4572   \n",
       "  5         0.016724           0.2774        0.074039           0.5672   \n",
       "  6         0.019537           0.2066        0.048926           0.6746   \n",
       "  7         0.014543           0.1096        0.062816           0.7810   \n",
       "  8         0.012000           0.0452        0.036969           0.8776   \n",
       "  9         0.007537           0.0192        0.017527           0.9482   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.008532             0.1430  ...        0.024924           0.8808   \n",
       "  2         0.009864             0.2258  ...        0.015090           0.7200   \n",
       "  3         0.011546             0.3436  ...        0.027181           0.6724   \n",
       "  4         0.017527             0.4502  ...        0.034319           0.6876   \n",
       "  5         0.014061             0.5582  ...        0.042526           0.7100   \n",
       "  6         0.016041             0.6678  ...        0.023965           0.7264   \n",
       "  7         0.010223             0.7750  ...        0.007259           0.5866   \n",
       "  8         0.009889             0.8730  ...        0.008012           0.4834   \n",
       "  9         0.007662             0.9466  ...        0.012522           0.6000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              204.0   \n",
       "  1         0.064755                   0.1              204.0   \n",
       "  2         0.043388                   0.2              204.0   \n",
       "  3         0.093149                   0.3              204.0   \n",
       "  4         0.066029                   0.4              204.0   \n",
       "  5         0.099872                   0.5              204.0   \n",
       "  6         0.122859                   0.6              204.0   \n",
       "  7         0.354750                   0.7              204.0   \n",
       "  8         0.291123                   0.8              204.0   \n",
       "  9         0.547723                   0.9              204.0   \n",
       "  10        0.000000                   1.0              204.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7414.0                15.0                 245.0   \n",
       "  1                7414.0                15.0                 245.0   \n",
       "  2                7414.0                15.0                 245.0   \n",
       "  3                7414.0                15.0                 245.0   \n",
       "  4                7414.0                15.0                 245.0   \n",
       "  5                7414.0                15.0                 245.0   \n",
       "  6                7414.0                15.0                 245.0   \n",
       "  7                7414.0                15.0                 245.0   \n",
       "  8                7414.0                15.0                 245.0   \n",
       "  9                7414.0                15.0                 245.0   \n",
       "  10               7414.0                15.0                 245.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                31.0                543.0  \n",
       "  1                31.0                543.0  \n",
       "  2                31.0                543.0  \n",
       "  3                31.0                543.0  \n",
       "  4                31.0                543.0  \n",
       "  5                31.0                543.0  \n",
       "  6                31.0                543.0  \n",
       "  7                31.0                543.0  \n",
       "  8                31.0                543.0  \n",
       "  9                31.0                543.0  \n",
       "  10               31.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns]],\n",
       " 'pred_test_original': [],\n",
       " 'pred_score_calupdate': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9164      0.006804           0.9178   \n",
       "  2                  0.2         0.8314      0.010644           0.8362   \n",
       "  3                  0.3         0.7218      0.012637           0.7264   \n",
       "  4                  0.4         0.6086      0.012720           0.6106   \n",
       "  5                  0.5         0.5104      0.019139           0.5118   \n",
       "  6                  0.6         0.4124      0.015192           0.4174   \n",
       "  7                  0.7         0.3132      0.014394           0.3190   \n",
       "  8                  0.8         0.2306      0.018968           0.2362   \n",
       "  9                  0.9         0.1252      0.013554           0.1286   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005891           0.8888        0.033885           0.0836   \n",
       "  2         0.010849           0.7556        0.071898           0.1686   \n",
       "  3         0.013390           0.6500        0.031575           0.2782   \n",
       "  4         0.013740           0.5724        0.037045           0.3914   \n",
       "  5         0.020340           0.4832        0.031925           0.4896   \n",
       "  6         0.014046           0.3390        0.063368           0.5876   \n",
       "  7         0.015604           0.2220        0.019799           0.6868   \n",
       "  8         0.019097           0.1444        0.036164           0.7694   \n",
       "  9         0.014311           0.0778        0.022950           0.8748   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.006804             0.0822  ...        0.020144           0.7188   \n",
       "  2         0.010644             0.1638  ...        0.028705           0.6766   \n",
       "  3         0.012637             0.2736  ...        0.021314           0.6294   \n",
       "  4         0.012720             0.3894  ...        0.030279           0.6368   \n",
       "  5         0.019139             0.4882  ...        0.032190           0.6850   \n",
       "  6         0.015192             0.5826  ...        0.020756           0.7010   \n",
       "  7         0.014394             0.6810  ...        0.027216           0.7026   \n",
       "  8         0.018968             0.7638  ...        0.023854           0.6524   \n",
       "  9         0.013554             0.8714  ...        0.017936           0.6334   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              322.0   \n",
       "  1         0.086661                   0.1              322.0   \n",
       "  2         0.055626                   0.2              322.0   \n",
       "  3         0.030113                   0.3              322.0   \n",
       "  4         0.050415                   0.4              322.0   \n",
       "  5         0.059034                   0.5              322.0   \n",
       "  6         0.055362                   0.6              322.0   \n",
       "  7         0.025383                   0.7              322.0   \n",
       "  8         0.020367                   0.8              322.0   \n",
       "  9         0.126403                   0.9              322.0   \n",
       "  10        0.000000                   1.0              322.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8179.0                25.0                 240.0   \n",
       "  1                8179.0                25.0                 240.0   \n",
       "  2                8179.0                25.0                 240.0   \n",
       "  3                8179.0                25.0                 240.0   \n",
       "  4                8179.0                25.0                 240.0   \n",
       "  5                8179.0                25.0                 240.0   \n",
       "  6                8179.0                25.0                 240.0   \n",
       "  7                8179.0                25.0                 240.0   \n",
       "  8                8179.0                25.0                 240.0   \n",
       "  9                8179.0                25.0                 240.0   \n",
       "  10               8179.0                25.0                 240.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                554.0  \n",
       "  1                36.0                554.0  \n",
       "  2                36.0                554.0  \n",
       "  3                36.0                554.0  \n",
       "  4                36.0                554.0  \n",
       "  5                36.0                554.0  \n",
       "  6                36.0                554.0  \n",
       "  7                36.0                554.0  \n",
       "  8                36.0                554.0  \n",
       "  9                36.0                554.0  \n",
       "  10               36.0                554.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9410      0.003162           0.9376   \n",
       "  2                  0.2         0.8754      0.003715           0.8760   \n",
       "  3                  0.3         0.7984      0.010714           0.8032   \n",
       "  4                  0.4         0.7004      0.015388           0.7078   \n",
       "  5                  0.5         0.5734      0.023985           0.5796   \n",
       "  6                  0.6         0.4552      0.015007           0.4532   \n",
       "  7                  0.7         0.3318      0.015611           0.3298   \n",
       "  8                  0.8         0.1978      0.016346           0.1928   \n",
       "  9                  0.9         0.0768      0.018754           0.0698   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.003715           0.9716        0.030859           0.0590   \n",
       "  2         0.003808           0.8694        0.030794           0.1246   \n",
       "  3         0.011498           0.7550        0.059682           0.2016   \n",
       "  4         0.022061           0.6326        0.059168           0.2996   \n",
       "  5         0.024724           0.5184        0.033946           0.4266   \n",
       "  6         0.015482           0.4734        0.026576           0.5448   \n",
       "  7         0.018417           0.3512        0.048566           0.6682   \n",
       "  8         0.014184           0.2448        0.071984           0.8022   \n",
       "  9         0.019318           0.1386        0.017213           0.9232   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.003162             0.0624  ...        0.062248           0.9284   \n",
       "  2         0.003715             0.1240  ...        0.032670           0.7880   \n",
       "  3         0.010714             0.1968  ...        0.022590           0.6982   \n",
       "  4         0.015388             0.2922  ...        0.044089           0.6504   \n",
       "  5         0.023985             0.4204  ...        0.033399           0.6726   \n",
       "  6         0.015007             0.5468  ...        0.031901           0.7314   \n",
       "  7         0.015611             0.6702  ...        0.027465           0.7740   \n",
       "  8         0.016346             0.8072  ...        0.032504           0.8686   \n",
       "  9         0.018754             0.9302  ...        0.046728           0.9464   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              901.0   \n",
       "  1         0.079071                   0.1              901.0   \n",
       "  2         0.042208                   0.2              901.0   \n",
       "  3         0.048685                   0.3              901.0   \n",
       "  4         0.032929                   0.4              901.0   \n",
       "  5         0.024735                   0.5              901.0   \n",
       "  6         0.031246                   0.6              901.0   \n",
       "  7         0.041322                   0.7              901.0   \n",
       "  8         0.059936                   0.8              901.0   \n",
       "  9         0.073670                   0.9              901.0   \n",
       "  10        0.000000                   1.0              901.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6290.0                27.0                 231.0   \n",
       "  1                6290.0                27.0                 231.0   \n",
       "  2                6290.0                27.0                 231.0   \n",
       "  3                6290.0                27.0                 231.0   \n",
       "  4                6290.0                27.0                 231.0   \n",
       "  5                6290.0                27.0                 231.0   \n",
       "  6                6290.0                27.0                 231.0   \n",
       "  7                6290.0                27.0                 231.0   \n",
       "  8                6290.0                27.0                 231.0   \n",
       "  9                6290.0                27.0                 231.0   \n",
       "  10               6290.0                27.0                 231.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                49.0                441.0  \n",
       "  1                49.0                441.0  \n",
       "  2                49.0                441.0  \n",
       "  3                49.0                441.0  \n",
       "  4                49.0                441.0  \n",
       "  5                49.0                441.0  \n",
       "  6                49.0                441.0  \n",
       "  7                49.0                441.0  \n",
       "  8                49.0                441.0  \n",
       "  9                49.0                441.0  \n",
       "  10               49.0                441.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9568      0.007396           0.9562   \n",
       "  2                  0.2         0.8868      0.005630           0.8850   \n",
       "  3                  0.3         0.8090      0.012708           0.8062   \n",
       "  4                  0.4         0.7218      0.015238           0.7174   \n",
       "  5                  0.5         0.6134      0.010807           0.6076   \n",
       "  6                  0.6         0.4872      0.032337           0.4788   \n",
       "  7                  0.7         0.3522      0.028578           0.3422   \n",
       "  8                  0.8         0.2092      0.014755           0.2032   \n",
       "  9                  0.9         0.0882      0.009365           0.0884   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007759           1.0000        0.000000           0.0432   \n",
       "  2         0.005148           0.9818        0.040696           0.1132   \n",
       "  3         0.012478           0.9454        0.049843           0.1910   \n",
       "  4         0.015931           0.9454        0.049843           0.2782   \n",
       "  5         0.010784           0.9090        0.000000           0.3866   \n",
       "  6         0.033656           0.8908        0.040696           0.5128   \n",
       "  7         0.029269           0.8362        0.099686           0.6478   \n",
       "  8         0.015515           0.4910        0.049295           0.7908   \n",
       "  9         0.009370           0.0728        0.040696           0.9118   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007396             0.0438  ...        0.156778           1.0000   \n",
       "  2         0.005630             0.1150  ...        0.136625           0.9666   \n",
       "  3         0.012708             0.1938  ...        0.105912           0.9306   \n",
       "  4         0.015238             0.2826  ...        0.056742           0.9306   \n",
       "  5         0.010807             0.3924  ...        0.036217           0.9014   \n",
       "  6         0.032337             0.5212  ...        0.025036           0.8908   \n",
       "  7         0.028578             0.6578  ...        0.045921           0.9236   \n",
       "  8         0.014755             0.7968  ...        0.084771           0.9046   \n",
       "  9         0.009365             0.9116  ...        0.104634           0.7000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              373.0   \n",
       "  1         0.000000                   0.1              373.0   \n",
       "  2         0.074685                   0.2              373.0   \n",
       "  3         0.063611                   0.3              373.0   \n",
       "  4         0.063611                   0.4              373.0   \n",
       "  5         0.008264                   0.5              373.0   \n",
       "  6         0.040696                   0.6              373.0   \n",
       "  7         0.082730                   0.7              373.0   \n",
       "  8         0.087637                   0.8              373.0   \n",
       "  9         0.447214                   0.9              373.0   \n",
       "  10        0.000000                   1.0              373.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8370.0                 3.0                 282.0   \n",
       "  1                8370.0                 3.0                 282.0   \n",
       "  2                8370.0                 3.0                 282.0   \n",
       "  3                8370.0                 3.0                 282.0   \n",
       "  4                8370.0                 3.0                 282.0   \n",
       "  5                8370.0                 3.0                 282.0   \n",
       "  6                8370.0                 3.0                 282.0   \n",
       "  7                8370.0                 3.0                 282.0   \n",
       "  8                8370.0                 3.0                 282.0   \n",
       "  9                8370.0                 3.0                 282.0   \n",
       "  10               8370.0                 3.0                 282.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                11.0                549.0  \n",
       "  1                11.0                549.0  \n",
       "  2                11.0                549.0  \n",
       "  3                11.0                549.0  \n",
       "  4                11.0                549.0  \n",
       "  5                11.0                549.0  \n",
       "  6                11.0                549.0  \n",
       "  7                11.0                549.0  \n",
       "  8                11.0                549.0  \n",
       "  9                11.0                549.0  \n",
       "  10               11.0                549.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9316      0.003209           0.9316   \n",
       "  2                  0.2         0.8522      0.008289           0.8510   \n",
       "  3                  0.3         0.7436      0.010784           0.7434   \n",
       "  4                  0.4         0.6196      0.016319           0.6200   \n",
       "  5                  0.5         0.4780      0.036132           0.4780   \n",
       "  6                  0.6         0.3314      0.030196           0.3296   \n",
       "  7                  0.7         0.1966      0.015915           0.1942   \n",
       "  8                  0.8         0.1158      0.007823           0.1120   \n",
       "  9                  0.9         0.0392      0.004764           0.0370   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.003209           0.9366        0.023255           0.0684   \n",
       "  2         0.008246           0.8948        0.037124           0.1478   \n",
       "  3         0.010831           0.7472        0.068222           0.2564   \n",
       "  4         0.017903           0.6106        0.088328           0.3804   \n",
       "  5         0.038710           0.4736        0.064504           0.5220   \n",
       "  6         0.033110           0.3896        0.095756           0.6686   \n",
       "  7         0.017123           0.2632        0.037124           0.8034   \n",
       "  8         0.008093           0.2214        0.023255           0.8842   \n",
       "  9         0.006042           0.0948        0.043866           0.9608   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.003209             0.0684  ...        0.159287           0.8688   \n",
       "  2         0.008289             0.1490  ...        0.052785           0.8414   \n",
       "  3         0.010784             0.2566  ...        0.019494           0.7450   \n",
       "  4         0.016319             0.3800  ...        0.018180           0.7316   \n",
       "  5         0.036132             0.5220  ...        0.030681           0.7786   \n",
       "  6         0.030196             0.6704  ...        0.031480           0.8038   \n",
       "  7         0.015915             0.8058  ...        0.038990           0.7570   \n",
       "  8         0.007823             0.8880  ...        0.034307           0.8066   \n",
       "  9         0.004764             0.9630  ...        0.081269           0.7334   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              386.0   \n",
       "  1         0.054651                   0.1              386.0   \n",
       "  2         0.035161                   0.2              386.0   \n",
       "  3         0.046707                   0.3              386.0   \n",
       "  4         0.066259                   0.4              386.0   \n",
       "  5         0.048742                   0.5              386.0   \n",
       "  6         0.032268                   0.6              386.0   \n",
       "  7         0.083027                   0.7              386.0   \n",
       "  8         0.014758                   0.8              386.0   \n",
       "  9         0.252741                   0.9              386.0   \n",
       "  10        0.000000                   1.0              386.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7233.0                10.0                 250.0   \n",
       "  1                7233.0                10.0                 250.0   \n",
       "  2                7233.0                10.0                 250.0   \n",
       "  3                7233.0                10.0                 250.0   \n",
       "  4                7233.0                10.0                 250.0   \n",
       "  5                7233.0                10.0                 250.0   \n",
       "  6                7233.0                10.0                 250.0   \n",
       "  7                7233.0                10.0                 250.0   \n",
       "  8                7233.0                10.0                 250.0   \n",
       "  9                7233.0                10.0                 250.0   \n",
       "  10               7233.0                10.0                 250.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                19.0                558.0  \n",
       "  1                19.0                558.0  \n",
       "  2                19.0                558.0  \n",
       "  3                19.0                558.0  \n",
       "  4                19.0                558.0  \n",
       "  5                19.0                558.0  \n",
       "  6                19.0                558.0  \n",
       "  7                19.0                558.0  \n",
       "  8                19.0                558.0  \n",
       "  9                19.0                558.0  \n",
       "  10               19.0                558.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9244      0.010334           0.9284   \n",
       "  2                  0.2         0.8610      0.009055           0.8726   \n",
       "  3                  0.3         0.7886      0.015598           0.8060   \n",
       "  4                  0.4         0.6768      0.023167           0.6904   \n",
       "  5                  0.5         0.5490      0.013964           0.5578   \n",
       "  6                  0.6         0.4128      0.030178           0.4160   \n",
       "  7                  0.7         0.2818      0.013664           0.2810   \n",
       "  8                  0.8         0.1532      0.009011           0.1528   \n",
       "  9                  0.9         0.0588      0.009731           0.0560   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010188           0.8930        0.042214           0.0756   \n",
       "  2         0.008877           0.7642        0.057159           0.1390   \n",
       "  3         0.013657           0.6464        0.047946           0.2114   \n",
       "  4         0.023671           0.5642        0.029643           0.3232   \n",
       "  5         0.017254           0.4748        0.035088           0.4510   \n",
       "  6         0.033978           0.3858        0.039436           0.5872   \n",
       "  7         0.017706           0.2894        0.077041           0.7182   \n",
       "  8         0.004147           0.1570        0.058468           0.8468   \n",
       "  9         0.009247           0.0822        0.044863           0.9412   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.010334             0.0716  ...        0.010986           0.8420   \n",
       "  2         0.009055             0.1274  ...        0.008093           0.7584   \n",
       "  3         0.015598             0.1940  ...        0.006504           0.8188   \n",
       "  4         0.023167             0.3096  ...        0.004336           0.9244   \n",
       "  5         0.013964             0.4422  ...        0.007314           0.9634   \n",
       "  6         0.030178             0.5840  ...        0.007823           0.9904   \n",
       "  7         0.013664             0.7190  ...        0.012677           1.0000   \n",
       "  8         0.009011             0.8472  ...        0.013554           1.0000   \n",
       "  9         0.009731             0.9440  ...        0.057660           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1094.0   \n",
       "  1         0.056196                   0.1             1094.0   \n",
       "  2         0.048896                   0.2             1094.0   \n",
       "  3         0.040598                   0.3             1094.0   \n",
       "  4         0.031746                   0.4             1094.0   \n",
       "  5         0.025126                   0.5             1094.0   \n",
       "  6         0.021466                   0.6             1094.0   \n",
       "  7         0.000000                   0.7             1094.0   \n",
       "  8         0.000000                   0.8             1094.0   \n",
       "  9         0.000000                   0.9             1094.0   \n",
       "  10        0.000000                   1.0             1094.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5719.0                38.0                 195.0   \n",
       "  1                5719.0                38.0                 195.0   \n",
       "  2                5719.0                38.0                 195.0   \n",
       "  3                5719.0                38.0                 195.0   \n",
       "  4                5719.0                38.0                 195.0   \n",
       "  5                5719.0                38.0                 195.0   \n",
       "  6                5719.0                38.0                 195.0   \n",
       "  7                5719.0                38.0                 195.0   \n",
       "  8                5719.0                38.0                 195.0   \n",
       "  9                5719.0                38.0                 195.0   \n",
       "  10               5719.0                38.0                 195.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                56.0                457.0  \n",
       "  1                56.0                457.0  \n",
       "  2                56.0                457.0  \n",
       "  3                56.0                457.0  \n",
       "  4                56.0                457.0  \n",
       "  5                56.0                457.0  \n",
       "  6                56.0                457.0  \n",
       "  7                56.0                457.0  \n",
       "  8                56.0                457.0  \n",
       "  9                56.0                457.0  \n",
       "  10               56.0                457.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9546      0.004561           0.9556   \n",
       "  2                  0.2         0.8756      0.009154           0.8788   \n",
       "  3                  0.3         0.7870      0.018748           0.7928   \n",
       "  4                  0.4         0.6896      0.017401           0.6978   \n",
       "  5                  0.5         0.5928      0.017978           0.6036   \n",
       "  6                  0.6         0.4798      0.011300           0.4912   \n",
       "  7                  0.7         0.3660      0.014748           0.3764   \n",
       "  8                  0.8         0.2342      0.013682           0.2416   \n",
       "  9                  0.9         0.1078      0.018254           0.1104   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.004930            0.945        0.020917           0.0454   \n",
       "  2         0.009039            0.830        0.041079           0.1244   \n",
       "  3         0.017908            0.710        0.045415           0.2130   \n",
       "  4         0.018089            0.580        0.020917           0.3104   \n",
       "  5         0.020611            0.445        0.032596           0.4072   \n",
       "  6         0.016316            0.320        0.069372           0.5202   \n",
       "  7         0.017082            0.225        0.030619           0.6340   \n",
       "  8         0.013722            0.135        0.013693           0.7658   \n",
       "  9         0.021256            0.070        0.032596           0.8922   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.004561             0.0444  ...        0.027794           0.8164   \n",
       "  2         0.009154             0.1212  ...        0.013759           0.7090   \n",
       "  3         0.018748             0.2072  ...        0.023223           0.6410   \n",
       "  4         0.017401             0.3022  ...        0.028164           0.6286   \n",
       "  5         0.017978             0.3964  ...        0.026948           0.6264   \n",
       "  6         0.011300             0.5088  ...        0.024829           0.6528   \n",
       "  7         0.014748             0.6236  ...        0.012349           0.7210   \n",
       "  8         0.013682             0.7584  ...        0.013442           0.8008   \n",
       "  9         0.018254             0.8896  ...        0.018593           0.8000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              515.0   \n",
       "  1         0.058024                   0.1              515.0   \n",
       "  2         0.058275                   0.2              515.0   \n",
       "  3         0.037570                   0.3              515.0   \n",
       "  4         0.013975                   0.4              515.0   \n",
       "  5         0.026922                   0.5              515.0   \n",
       "  6         0.046746                   0.6              515.0   \n",
       "  7         0.080598                   0.7              515.0   \n",
       "  8         0.151435                   0.8              515.0   \n",
       "  9         0.273861                   0.9              515.0   \n",
       "  10        0.000000                   1.0              515.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7542.0                28.0                 234.0   \n",
       "  1                7542.0                28.0                 234.0   \n",
       "  2                7542.0                28.0                 234.0   \n",
       "  3                7542.0                28.0                 234.0   \n",
       "  4                7542.0                28.0                 234.0   \n",
       "  5                7542.0                28.0                 234.0   \n",
       "  6                7542.0                28.0                 234.0   \n",
       "  7                7542.0                28.0                 234.0   \n",
       "  8                7542.0                28.0                 234.0   \n",
       "  9                7542.0                28.0                 234.0   \n",
       "  10               7542.0                28.0                 234.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                40.0                543.0  \n",
       "  1                40.0                543.0  \n",
       "  2                40.0                543.0  \n",
       "  3                40.0                543.0  \n",
       "  4                40.0                543.0  \n",
       "  5                40.0                543.0  \n",
       "  6                40.0                543.0  \n",
       "  7                40.0                543.0  \n",
       "  8                40.0                543.0  \n",
       "  9                40.0                543.0  \n",
       "  10               40.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9268      0.008899           0.9304   \n",
       "  2                  0.2         0.8662      0.014412           0.8716   \n",
       "  3                  0.3         0.7626      0.025195           0.7756   \n",
       "  4                  0.4         0.6470      0.020736           0.6632   \n",
       "  5                  0.5         0.5284      0.025706           0.5406   \n",
       "  6                  0.6         0.3860      0.029572           0.3944   \n",
       "  7                  0.7         0.2610      0.015556           0.2636   \n",
       "  8                  0.8         0.1384      0.018078           0.1360   \n",
       "  9                  0.9         0.0524      0.011171           0.0494   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009127           0.8836        0.045583           0.0732   \n",
       "  2         0.013795           0.7944        0.106887           0.1338   \n",
       "  3         0.024100           0.5944        0.111968           0.2374   \n",
       "  4         0.024273           0.4444        0.098147           0.3530   \n",
       "  5         0.024399           0.3666        0.104517           0.4716   \n",
       "  6         0.033975           0.2778        0.059044           0.6140   \n",
       "  7         0.018569           0.2278        0.060450           0.7390   \n",
       "  8         0.019235           0.1724        0.045583           0.8616   \n",
       "  9         0.010431           0.0890        0.036049           0.9476   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.008899             0.0696  ...        0.037667           0.7432   \n",
       "  2         0.014412             0.1284  ...        0.041968           0.7154   \n",
       "  3         0.025195             0.2244  ...        0.045687           0.6280   \n",
       "  4         0.020736             0.3368  ...        0.039910           0.6516   \n",
       "  5         0.025706             0.4594  ...        0.033816           0.7308   \n",
       "  6         0.029572             0.6056  ...        0.041813           0.7318   \n",
       "  7         0.015556             0.7364  ...        0.050483           0.8028   \n",
       "  8         0.018078             0.8640  ...        0.098024           0.9514   \n",
       "  9         0.011171             0.9506  ...        0.064472           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              338.0   \n",
       "  1         0.071963                   0.1              338.0   \n",
       "  2         0.119705                   0.2              338.0   \n",
       "  3         0.079155                   0.3              338.0   \n",
       "  4         0.067058                   0.4              338.0   \n",
       "  5         0.105526                   0.5              338.0   \n",
       "  6         0.046311                   0.6              338.0   \n",
       "  7         0.064998                   0.7              338.0   \n",
       "  8         0.068263                   0.8              338.0   \n",
       "  9         0.000000                   0.9              338.0   \n",
       "  10        0.000000                   1.0              338.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6362.0                18.0                 192.0   \n",
       "  1                6362.0                18.0                 192.0   \n",
       "  2                6362.0                18.0                 192.0   \n",
       "  3                6362.0                18.0                 192.0   \n",
       "  4                6362.0                18.0                 192.0   \n",
       "  5                6362.0                18.0                 192.0   \n",
       "  6                6362.0                18.0                 192.0   \n",
       "  7                6362.0                18.0                 192.0   \n",
       "  8                6362.0                18.0                 192.0   \n",
       "  9                6362.0                18.0                 192.0   \n",
       "  10               6362.0                18.0                 192.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                466.0  \n",
       "  1                36.0                466.0  \n",
       "  2                36.0                466.0  \n",
       "  3                36.0                466.0  \n",
       "  4                36.0                466.0  \n",
       "  5                36.0                466.0  \n",
       "  6                36.0                466.0  \n",
       "  7                36.0                466.0  \n",
       "  8                36.0                466.0  \n",
       "  9                36.0                466.0  \n",
       "  10               36.0                466.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9312      0.010109           0.9396   \n",
       "  2                  0.2         0.8444      0.006542           0.8602   \n",
       "  3                  0.3         0.7392      0.016300           0.7548   \n",
       "  4                  0.4         0.6214      0.017344           0.6404   \n",
       "  5                  0.5         0.5016      0.022457           0.5216   \n",
       "  6                  0.6         0.3882      0.019280           0.4014   \n",
       "  7                  0.7         0.2666      0.012137           0.2702   \n",
       "  8                  0.8         0.1366      0.010991           0.1332   \n",
       "  9                  0.9         0.0492      0.003033           0.0454   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008532           0.8896        0.037680           0.0688   \n",
       "  2         0.015222           0.7686        0.052771           0.1556   \n",
       "  3         0.022152           0.6628        0.042676           0.2608   \n",
       "  4         0.018730           0.5302        0.021811           0.3786   \n",
       "  5         0.026015           0.4042        0.015912           0.4984   \n",
       "  6         0.019629           0.3236        0.025501           0.6118   \n",
       "  7         0.013989           0.2494        0.016622           0.7334   \n",
       "  8         0.009311           0.1506        0.021778           0.8634   \n",
       "  9         0.003435           0.0674        0.017869           0.9508   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.010109             0.0604  ...        0.012029           0.7402   \n",
       "  2         0.006542             0.1398  ...        0.018660           0.6824   \n",
       "  3         0.016300             0.2452  ...        0.023435           0.6784   \n",
       "  4         0.017344             0.3596  ...        0.017219           0.7138   \n",
       "  5         0.022457             0.4784  ...        0.006686           0.7732   \n",
       "  6         0.019280             0.5986  ...        0.011713           0.8648   \n",
       "  7         0.012137             0.7298  ...        0.009311           0.9046   \n",
       "  8         0.010991             0.8668  ...        0.026272           0.9680   \n",
       "  9         0.003033             0.9546  ...        0.076176           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1032.0   \n",
       "  1         0.072744                   0.1             1032.0   \n",
       "  2         0.062748                   0.2             1032.0   \n",
       "  3         0.050777                   0.3             1032.0   \n",
       "  4         0.042629                   0.4             1032.0   \n",
       "  5         0.058632                   0.5             1032.0   \n",
       "  6         0.057872                   0.6             1032.0   \n",
       "  7         0.030138                   0.7             1032.0   \n",
       "  8         0.043869                   0.8             1032.0   \n",
       "  9         0.000000                   0.9             1032.0   \n",
       "  10        0.000000                   1.0             1032.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5653.0                47.0                 181.0   \n",
       "  1                5653.0                47.0                 181.0   \n",
       "  2                5653.0                47.0                 181.0   \n",
       "  3                5653.0                47.0                 181.0   \n",
       "  4                5653.0                47.0                 181.0   \n",
       "  5                5653.0                47.0                 181.0   \n",
       "  6                5653.0                47.0                 181.0   \n",
       "  7                5653.0                47.0                 181.0   \n",
       "  8                5653.0                47.0                 181.0   \n",
       "  9                5653.0                47.0                 181.0   \n",
       "  10               5653.0                47.0                 181.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                89.0                433.0  \n",
       "  1                89.0                433.0  \n",
       "  2                89.0                433.0  \n",
       "  3                89.0                433.0  \n",
       "  4                89.0                433.0  \n",
       "  5                89.0                433.0  \n",
       "  6                89.0                433.0  \n",
       "  7                89.0                433.0  \n",
       "  8                89.0                433.0  \n",
       "  9                89.0                433.0  \n",
       "  10               89.0                433.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9404      0.015339           0.9398   \n",
       "  2                  0.2         0.8656      0.017155           0.8642   \n",
       "  3                  0.3         0.7782      0.025253           0.7784   \n",
       "  4                  0.4         0.6960      0.021806           0.6974   \n",
       "  5                  0.5         0.5824      0.029305           0.5870   \n",
       "  6                  0.6         0.4714      0.024966           0.4772   \n",
       "  7                  0.7         0.3722      0.016858           0.3768   \n",
       "  8                  0.8         0.2570      0.016703           0.2606   \n",
       "  9                  0.9         0.1480      0.019887           0.1502   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.015738            1.000        0.000000           0.0596   \n",
       "  2         0.016843            0.950        0.068465           0.1344   \n",
       "  3         0.027328            0.750        0.176777           0.2218   \n",
       "  4         0.023298            0.625        0.088388           0.3040   \n",
       "  5         0.029198            0.275        0.162980           0.4176   \n",
       "  6         0.024753            0.075        0.111803           0.5286   \n",
       "  7         0.015912            0.050        0.111803           0.6278   \n",
       "  8         0.017141            0.000        0.000000           0.7430   \n",
       "  9         0.020192            0.000        0.000000           0.8520   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.015339             0.0602  ...        0.172690           0.8000   \n",
       "  2         0.017155             0.1358  ...        0.136530           0.8834   \n",
       "  3         0.025253             0.2216  ...        0.061443           0.6592   \n",
       "  4         0.021806             0.3026  ...        0.037567           0.5926   \n",
       "  5         0.029305             0.4130  ...        0.027555           0.3990   \n",
       "  6         0.024966             0.5228  ...        0.023776           0.1466   \n",
       "  7         0.016858             0.6232  ...        0.006595           0.1000   \n",
       "  8         0.016703             0.7394  ...        0.005541           0.0000   \n",
       "  9         0.019887             0.8498  ...        0.011925           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              295.0   \n",
       "  1         0.447214                   0.1              295.0   \n",
       "  2         0.162335                   0.2              295.0   \n",
       "  3         0.209885                   0.3              295.0   \n",
       "  4         0.093206                   0.4              295.0   \n",
       "  5         0.070381                   0.5              295.0   \n",
       "  6         0.202133                   0.6              295.0   \n",
       "  7         0.223607                   0.7              295.0   \n",
       "  8         0.000000                   0.8              295.0   \n",
       "  9         0.000000                   0.9              295.0   \n",
       "  10        0.000000                   1.0              295.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7742.0                 4.0                 242.0   \n",
       "  1                7742.0                 4.0                 242.0   \n",
       "  2                7742.0                 4.0                 242.0   \n",
       "  3                7742.0                 4.0                 242.0   \n",
       "  4                7742.0                 4.0                 242.0   \n",
       "  5                7742.0                 4.0                 242.0   \n",
       "  6                7742.0                 4.0                 242.0   \n",
       "  7                7742.0                 4.0                 242.0   \n",
       "  8                7742.0                 4.0                 242.0   \n",
       "  9                7742.0                 4.0                 242.0   \n",
       "  10               7742.0                 4.0                 242.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                 8.0                543.0  \n",
       "  1                 8.0                543.0  \n",
       "  2                 8.0                543.0  \n",
       "  3                 8.0                543.0  \n",
       "  4                 8.0                543.0  \n",
       "  5                 8.0                543.0  \n",
       "  6                 8.0                543.0  \n",
       "  7                 8.0                543.0  \n",
       "  8                 8.0                543.0  \n",
       "  9                 8.0                543.0  \n",
       "  10                8.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9558      0.008075           0.9582   \n",
       "  2                  0.2         0.8892      0.007791           0.9014   \n",
       "  3                  0.3         0.8154      0.007436           0.8372   \n",
       "  4                  0.4         0.7048      0.003962           0.7386   \n",
       "  5                  0.5         0.5928      0.014990           0.6284   \n",
       "  6                  0.6         0.4470      0.013910           0.4776   \n",
       "  7                  0.7         0.3142      0.009149           0.3360   \n",
       "  8                  0.8         0.1990      0.015000           0.2116   \n",
       "  9                  0.9         0.0890      0.013766           0.0902   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008815           0.9380        0.029538           0.0442   \n",
       "  2         0.003847           0.8000        0.055902           0.1108   \n",
       "  3         0.005404           0.6592        0.026930           0.1846   \n",
       "  4         0.006066           0.4620        0.037921           0.2952   \n",
       "  5         0.015307           0.3380        0.014000           0.4072   \n",
       "  6         0.013885           0.2280        0.027166           0.5530   \n",
       "  7         0.011136           0.1606        0.035140           0.6858   \n",
       "  8         0.016532           0.1102        0.011713           0.8010   \n",
       "  9         0.015466           0.0820        0.015748           0.9110   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.008075             0.0418  ...        0.023469           0.8710   \n",
       "  2         0.007791             0.0986  ...        0.004561           0.7784   \n",
       "  3         0.007436             0.1628  ...        0.006025           0.7988   \n",
       "  4         0.003962             0.2614  ...        0.009737           0.8194   \n",
       "  5         0.014990             0.3716  ...        0.010237           0.8580   \n",
       "  6         0.013910             0.5224  ...        0.009628           0.8892   \n",
       "  7         0.009149             0.6640  ...        0.013027           0.8708   \n",
       "  8         0.015000             0.7884  ...        0.015189           0.9056   \n",
       "  9         0.013766             0.9098  ...        0.016471           0.9714   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              933.0   \n",
       "  1         0.053193                   0.1              933.0   \n",
       "  2         0.045698                   0.2              933.0   \n",
       "  3         0.018620                   0.3              933.0   \n",
       "  4         0.025413                   0.4              933.0   \n",
       "  5         0.030414                   0.5              933.0   \n",
       "  6         0.013008                   0.6              933.0   \n",
       "  7         0.061092                   0.7              933.0   \n",
       "  8         0.053233                   0.8              933.0   \n",
       "  9         0.063952                   0.9              933.0   \n",
       "  10        0.000000                   1.0              933.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6687.0                29.0                 236.0   \n",
       "  1                6687.0                29.0                 236.0   \n",
       "  2                6687.0                29.0                 236.0   \n",
       "  3                6687.0                29.0                 236.0   \n",
       "  4                6687.0                29.0                 236.0   \n",
       "  5                6687.0                29.0                 236.0   \n",
       "  6                6687.0                29.0                 236.0   \n",
       "  7                6687.0                29.0                 236.0   \n",
       "  8                6687.0                29.0                 236.0   \n",
       "  9                6687.0                29.0                 236.0   \n",
       "  10               6687.0                29.0                 236.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                71.0                506.0  \n",
       "  1                71.0                506.0  \n",
       "  2                71.0                506.0  \n",
       "  3                71.0                506.0  \n",
       "  4                71.0                506.0  \n",
       "  5                71.0                506.0  \n",
       "  6                71.0                506.0  \n",
       "  7                71.0                506.0  \n",
       "  8                71.0                506.0  \n",
       "  9                71.0                506.0  \n",
       "  10               71.0                506.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9472      0.007563           0.9478   \n",
       "  2                  0.2         0.8778      0.007694           0.8796   \n",
       "  3                  0.3         0.7710      0.015732           0.7722   \n",
       "  4                  0.4         0.6498      0.014167           0.6512   \n",
       "  5                  0.5         0.5428      0.018295           0.5402   \n",
       "  6                  0.6         0.4312      0.009230           0.4272   \n",
       "  7                  0.7         0.3068      0.016115           0.3066   \n",
       "  8                  0.8         0.1874      0.010738           0.1880   \n",
       "  9                  0.9         0.0906      0.006504           0.0886   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.007727             0.93        0.067082           0.0528   \n",
       "  2         0.006618             0.83        0.044721           0.1222   \n",
       "  3         0.017035             0.73        0.057009           0.2290   \n",
       "  4         0.015498             0.61        0.022361           0.3502   \n",
       "  5         0.019422             0.60        0.035355           0.4572   \n",
       "  6         0.010035             0.54        0.022361           0.5688   \n",
       "  7         0.015868             0.32        0.044721           0.6932   \n",
       "  8         0.010488             0.18        0.044721           0.8126   \n",
       "  9         0.006877             0.14        0.054772           0.9094   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.007563             0.0522  ...        0.140654           0.8512   \n",
       "  2         0.007694             0.1204  ...        0.043646           0.7496   \n",
       "  3         0.015732             0.2278  ...        0.035320           0.6688   \n",
       "  4         0.014167             0.3488  ...        0.024203           0.5980   \n",
       "  5         0.018295             0.4598  ...        0.028513           0.6336   \n",
       "  6         0.009230             0.5728  ...        0.049739           0.7304   \n",
       "  7         0.016115             0.6934  ...        0.027253           0.6674   \n",
       "  8         0.010738             0.8120  ...        0.012450           0.7468   \n",
       "  9         0.006504             0.9114  ...        0.026015           0.9600   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              419.0   \n",
       "  1         0.139518                   0.1              419.0   \n",
       "  2         0.044343                   0.2              419.0   \n",
       "  3         0.054458                   0.3              419.0   \n",
       "  4         0.021714                   0.4              419.0   \n",
       "  5         0.059517                   0.5              419.0   \n",
       "  6         0.042223                   0.6              419.0   \n",
       "  7         0.081687                   0.7              419.0   \n",
       "  8         0.255552                   0.8              419.0   \n",
       "  9         0.089443                   0.9              419.0   \n",
       "  10        0.000000                   1.0              419.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7763.0                10.0                 270.0   \n",
       "  1                7763.0                10.0                 270.0   \n",
       "  2                7763.0                10.0                 270.0   \n",
       "  3                7763.0                10.0                 270.0   \n",
       "  4                7763.0                10.0                 270.0   \n",
       "  5                7763.0                10.0                 270.0   \n",
       "  6                7763.0                10.0                 270.0   \n",
       "  7                7763.0                10.0                 270.0   \n",
       "  8                7763.0                10.0                 270.0   \n",
       "  9                7763.0                10.0                 270.0   \n",
       "  10               7763.0                10.0                 270.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                20.0                548.0  \n",
       "  1                20.0                548.0  \n",
       "  2                20.0                548.0  \n",
       "  3                20.0                548.0  \n",
       "  4                20.0                548.0  \n",
       "  5                20.0                548.0  \n",
       "  6                20.0                548.0  \n",
       "  7                20.0                548.0  \n",
       "  8                20.0                548.0  \n",
       "  9                20.0                548.0  \n",
       "  10               20.0                548.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9328      0.003564           0.9326   \n",
       "  2                  0.2         0.8516      0.013722           0.8494   \n",
       "  3                  0.3         0.7558      0.014061           0.7544   \n",
       "  4                  0.4         0.6348      0.012911           0.6350   \n",
       "  5                  0.5         0.5230      0.015362           0.5220   \n",
       "  6                  0.6         0.4010      0.015953           0.3984   \n",
       "  7                  0.7         0.2892      0.014290           0.2858   \n",
       "  8                  0.8         0.1808      0.022242           0.1784   \n",
       "  9                  0.9         0.0974      0.011971           0.0944   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004219           0.9354        0.032501           0.0672   \n",
       "  2         0.012562           0.8904        0.048926           0.1484   \n",
       "  3         0.014117           0.7806        0.057635           0.2442   \n",
       "  4         0.016447           0.6324        0.062816           0.3652   \n",
       "  5         0.015764           0.5354        0.029014           0.4770   \n",
       "  6         0.018160           0.4452        0.042222           0.5990   \n",
       "  7         0.015770           0.3486        0.026773           0.7108   \n",
       "  8         0.022356           0.2260        0.032000           0.8192   \n",
       "  9         0.011238           0.1486        0.048993           0.9026   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.003564             0.0674  ...        0.042910           0.8432   \n",
       "  2         0.013722             0.1506  ...        0.032718           0.8192   \n",
       "  3         0.014061             0.2456  ...        0.035457           0.7360   \n",
       "  4         0.012911             0.3650  ...        0.054801           0.7218   \n",
       "  5         0.015362             0.4780  ...        0.046141           0.7636   \n",
       "  6         0.015953             0.6016  ...        0.053616           0.8436   \n",
       "  7         0.014290             0.7142  ...        0.051563           0.8500   \n",
       "  8         0.022242             0.8216  ...        0.040407           0.8556   \n",
       "  9         0.011971             0.9056  ...        0.010114           0.9666   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              204.0   \n",
       "  1         0.056962                   0.1              204.0   \n",
       "  2         0.066247                   0.2              204.0   \n",
       "  3         0.039453                   0.3              204.0   \n",
       "  4         0.049631                   0.4              204.0   \n",
       "  5         0.045280                   0.5              204.0   \n",
       "  6         0.060674                   0.6              204.0   \n",
       "  7         0.069921                   0.7              204.0   \n",
       "  8         0.033864                   0.8              204.0   \n",
       "  9         0.074685                   0.9              204.0   \n",
       "  10        0.000000                   1.0              204.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7414.0                15.0                 245.0   \n",
       "  1                7414.0                15.0                 245.0   \n",
       "  2                7414.0                15.0                 245.0   \n",
       "  3                7414.0                15.0                 245.0   \n",
       "  4                7414.0                15.0                 245.0   \n",
       "  5                7414.0                15.0                 245.0   \n",
       "  6                7414.0                15.0                 245.0   \n",
       "  7                7414.0                15.0                 245.0   \n",
       "  8                7414.0                15.0                 245.0   \n",
       "  9                7414.0                15.0                 245.0   \n",
       "  10               7414.0                15.0                 245.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                31.0                543.0  \n",
       "  1                31.0                543.0  \n",
       "  2                31.0                543.0  \n",
       "  3                31.0                543.0  \n",
       "  4                31.0                543.0  \n",
       "  5                31.0                543.0  \n",
       "  6                31.0                543.0  \n",
       "  7                31.0                543.0  \n",
       "  8                31.0                543.0  \n",
       "  9                31.0                543.0  \n",
       "  10               31.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns]],\n",
       " 'pred_score_calupdate2': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8942      0.024743           0.8932   \n",
       "  2                  0.2         0.8060      0.040694           0.8034   \n",
       "  3                  0.3         0.6894      0.046961           0.6854   \n",
       "  4                  0.4         0.5762      0.045329           0.5720   \n",
       "  5                  0.5         0.4692      0.042681           0.4598   \n",
       "  6                  0.6         0.3744      0.038436           0.3690   \n",
       "  7                  0.7         0.2732      0.031515           0.2720   \n",
       "  8                  0.8         0.1660      0.015476           0.1640   \n",
       "  9                  0.9         0.0786      0.012280           0.0786   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.023679           0.9108        0.049585           0.1058   \n",
       "  2         0.039049           0.8444        0.072210           0.1940   \n",
       "  3         0.046811           0.7556        0.101041           0.3106   \n",
       "  4         0.045591           0.6446        0.101041           0.4238   \n",
       "  5         0.042985           0.6110        0.078489           0.5308   \n",
       "  6         0.033279           0.4554        0.197800           0.6256   \n",
       "  7         0.030895           0.2888        0.190044           0.7268   \n",
       "  8         0.015395           0.2000        0.149805           0.8340   \n",
       "  9         0.018091           0.0778        0.092840           0.9214   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.024743             0.1068  ...        0.089052           0.7942   \n",
       "  2         0.040694             0.1966  ...        0.032562           0.7920   \n",
       "  3         0.046961             0.3146  ...        0.029499           0.7230   \n",
       "  4         0.045329             0.4280  ...        0.041940           0.6814   \n",
       "  5         0.042681             0.5402  ...        0.052927           0.7524   \n",
       "  6         0.038436             0.6310  ...        0.061435           0.7424   \n",
       "  7         0.031515             0.7280  ...        0.088348           0.6676   \n",
       "  8         0.015476             0.8360  ...        0.120691           0.6946   \n",
       "  9         0.012280             0.9214  ...        0.132982           0.4600   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              322.0   \n",
       "  1         0.087288                   0.1              322.0   \n",
       "  2         0.089336                   0.2              322.0   \n",
       "  3         0.111519                   0.3              322.0   \n",
       "  4         0.091999                   0.4              322.0   \n",
       "  5         0.040129                   0.5              322.0   \n",
       "  6         0.144528                   0.6              322.0   \n",
       "  7         0.175201                   0.7              322.0   \n",
       "  8         0.141645                   0.8              322.0   \n",
       "  9         0.456070                   0.9              322.0   \n",
       "  10        0.000000                   1.0              322.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8179.0                25.0                 240.0   \n",
       "  1                8179.0                25.0                 240.0   \n",
       "  2                8179.0                25.0                 240.0   \n",
       "  3                8179.0                25.0                 240.0   \n",
       "  4                8179.0                25.0                 240.0   \n",
       "  5                8179.0                25.0                 240.0   \n",
       "  6                8179.0                25.0                 240.0   \n",
       "  7                8179.0                25.0                 240.0   \n",
       "  8                8179.0                25.0                 240.0   \n",
       "  9                8179.0                25.0                 240.0   \n",
       "  10               8179.0                25.0                 240.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                554.0  \n",
       "  1                36.0                554.0  \n",
       "  2                36.0                554.0  \n",
       "  3                36.0                554.0  \n",
       "  4                36.0                554.0  \n",
       "  5                36.0                554.0  \n",
       "  6                36.0                554.0  \n",
       "  7                36.0                554.0  \n",
       "  8                36.0                554.0  \n",
       "  9                36.0                554.0  \n",
       "  10               36.0                554.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9216      0.025696           0.9158   \n",
       "  2                  0.2         0.8170      0.035763           0.8180   \n",
       "  3                  0.3         0.7202      0.042252           0.7182   \n",
       "  4                  0.4         0.6048      0.058457           0.6042   \n",
       "  5                  0.5         0.4824      0.059542           0.4816   \n",
       "  6                  0.6         0.3764      0.063963           0.3734   \n",
       "  7                  0.7         0.2586      0.053799           0.2636   \n",
       "  8                  0.8         0.1592      0.036888           0.1632   \n",
       "  9                  0.9         0.0646      0.024704           0.0634   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.025821           0.9750        0.037175           0.0784   \n",
       "  2         0.030290           0.8090        0.117181           0.1830   \n",
       "  3         0.036894           0.7346        0.110206           0.2798   \n",
       "  4         0.057877           0.6110        0.066464           0.3952   \n",
       "  5         0.057370           0.4866        0.081381           0.5176   \n",
       "  6         0.060430           0.4036        0.118509           0.6236   \n",
       "  7         0.049757           0.2136        0.102490           0.7414   \n",
       "  8         0.036813           0.1234        0.063303           0.8408   \n",
       "  9         0.026520           0.0738        0.066183           0.9354   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.025696             0.0842  ...        0.062780           0.9400   \n",
       "  2         0.035763             0.1820  ...        0.044494           0.7566   \n",
       "  3         0.042252             0.2818  ...        0.026790           0.7174   \n",
       "  4         0.058457             0.3958  ...        0.019900           0.7038   \n",
       "  5         0.059542             0.5184  ...        0.036774           0.7020   \n",
       "  6         0.063963             0.6266  ...        0.038284           0.7532   \n",
       "  7         0.053799             0.7364  ...        0.035064           0.8942   \n",
       "  8         0.036888             0.8368  ...        0.050907           0.8534   \n",
       "  9         0.024704             0.9366  ...        0.000000           0.8000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              901.0   \n",
       "  1         0.089443                   0.1              901.0   \n",
       "  2         0.113061                   0.2              901.0   \n",
       "  3         0.094991                   0.3              901.0   \n",
       "  4         0.067596                   0.4              901.0   \n",
       "  5         0.086833                   0.5              901.0   \n",
       "  6         0.104044                   0.6              901.0   \n",
       "  7         0.118614                   0.7              901.0   \n",
       "  8         0.202133                   0.8              901.0   \n",
       "  9         0.447214                   0.9              901.0   \n",
       "  10        0.000000                   1.0              901.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6290.0                27.0                 231.0   \n",
       "  1                6290.0                27.0                 231.0   \n",
       "  2                6290.0                27.0                 231.0   \n",
       "  3                6290.0                27.0                 231.0   \n",
       "  4                6290.0                27.0                 231.0   \n",
       "  5                6290.0                27.0                 231.0   \n",
       "  6                6290.0                27.0                 231.0   \n",
       "  7                6290.0                27.0                 231.0   \n",
       "  8                6290.0                27.0                 231.0   \n",
       "  9                6290.0                27.0                 231.0   \n",
       "  10               6290.0                27.0                 231.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                49.0                441.0  \n",
       "  1                49.0                441.0  \n",
       "  2                49.0                441.0  \n",
       "  3                49.0                441.0  \n",
       "  4                49.0                441.0  \n",
       "  5                49.0                441.0  \n",
       "  6                49.0                441.0  \n",
       "  7                49.0                441.0  \n",
       "  8                49.0                441.0  \n",
       "  9                49.0                441.0  \n",
       "  10               49.0                441.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9114      0.020489           0.9102   \n",
       "  2                  0.2         0.8094      0.030279           0.8082   \n",
       "  3                  0.3         0.6998      0.027707           0.6996   \n",
       "  4                  0.4         0.5972      0.024934           0.5958   \n",
       "  5                  0.5         0.4808      0.015515           0.4816   \n",
       "  6                  0.6         0.3664      0.014605           0.3678   \n",
       "  7                  0.7         0.2544      0.027574           0.2540   \n",
       "  8                  0.8         0.1606      0.025472           0.1620   \n",
       "  9                  0.9         0.0742      0.019396           0.0758   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.021856           0.9666        0.074685           0.0886   \n",
       "  2         0.030833           0.8466        0.259919           0.1906   \n",
       "  3         0.028536           0.7066        0.306696           0.3002   \n",
       "  4         0.026234           0.6400        0.308536           0.4028   \n",
       "  5         0.021939           0.4400        0.339403           0.5192   \n",
       "  6         0.018458           0.3066        0.212645           0.6336   \n",
       "  7         0.031089           0.2734        0.220313           0.7456   \n",
       "  8         0.024900           0.1000        0.148978           0.8394   \n",
       "  9         0.019842           0.0000        0.000000           0.9258   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.020489             0.0898  ...        0.290306           0.9334   \n",
       "  2         0.030279             0.1918  ...        0.213260           0.8100   \n",
       "  3         0.027707             0.3004  ...        0.139308           0.7600   \n",
       "  4         0.024934             0.4042  ...        0.121525           0.7500   \n",
       "  5         0.015515             0.5184  ...        0.088397           0.7100   \n",
       "  6         0.014605             0.6322  ...        0.066919           0.7334   \n",
       "  7         0.027574             0.7460  ...        0.070009           0.7000   \n",
       "  8         0.025472             0.8380  ...        0.050509           0.3000   \n",
       "  9         0.019396             0.9242  ...        0.045224           0.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              373.0   \n",
       "  1         0.148922                   0.1              373.0   \n",
       "  2         0.324808                   0.2              373.0   \n",
       "  3         0.187602                   0.3              373.0   \n",
       "  4         0.186265                   0.4              373.0   \n",
       "  5         0.412916                   0.5              373.0   \n",
       "  6         0.434601                   0.6              373.0   \n",
       "  7         0.447214                   0.7              373.0   \n",
       "  8         0.447214                   0.8              373.0   \n",
       "  9         0.000000                   0.9              373.0   \n",
       "  10        0.000000                   1.0              373.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                8370.0                 3.0                 282.0   \n",
       "  1                8370.0                 3.0                 282.0   \n",
       "  2                8370.0                 3.0                 282.0   \n",
       "  3                8370.0                 3.0                 282.0   \n",
       "  4                8370.0                 3.0                 282.0   \n",
       "  5                8370.0                 3.0                 282.0   \n",
       "  6                8370.0                 3.0                 282.0   \n",
       "  7                8370.0                 3.0                 282.0   \n",
       "  8                8370.0                 3.0                 282.0   \n",
       "  9                8370.0                 3.0                 282.0   \n",
       "  10               8370.0                 3.0                 282.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                11.0                549.0  \n",
       "  1                11.0                549.0  \n",
       "  2                11.0                549.0  \n",
       "  3                11.0                549.0  \n",
       "  4                11.0                549.0  \n",
       "  5                11.0                549.0  \n",
       "  6                11.0                549.0  \n",
       "  7                11.0                549.0  \n",
       "  8                11.0                549.0  \n",
       "  9                11.0                549.0  \n",
       "  10               11.0                549.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9092      0.016858           0.9124   \n",
       "  2                  0.2         0.8000      0.026580           0.8034   \n",
       "  3                  0.3         0.6972      0.023573           0.6966   \n",
       "  4                  0.4         0.6078      0.039366           0.6056   \n",
       "  5                  0.5         0.5002      0.037937           0.4970   \n",
       "  6                  0.6         0.3806      0.040894           0.3784   \n",
       "  7                  0.7         0.2526      0.022876           0.2500   \n",
       "  8                  0.8         0.1480      0.024668           0.1442   \n",
       "  9                  0.9         0.0704      0.016712           0.0682   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.019165             0.82        0.204939           0.0908   \n",
       "  2         0.029031             0.70        0.200000           0.2000   \n",
       "  3         0.026996             0.70        0.200000           0.3028   \n",
       "  4         0.042951             0.66        0.250998           0.3922   \n",
       "  5         0.043272             0.60        0.244949           0.4998   \n",
       "  6         0.046307             0.44        0.181659           0.6194   \n",
       "  7         0.023377             0.32        0.148324           0.7474   \n",
       "  8         0.026461             0.26        0.151658           0.8520   \n",
       "  9         0.014772             0.14        0.207364           0.9296   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.016858             0.0876  ...        0.406523           0.7378   \n",
       "  2         0.026580             0.1966  ...        0.075802           0.6772   \n",
       "  3         0.023573             0.3034  ...        0.081552           0.7088   \n",
       "  4         0.039366             0.3944  ...        0.086254           0.6970   \n",
       "  5         0.037937             0.5030  ...        0.086794           0.7446   \n",
       "  6         0.040894             0.6216  ...        0.089871           0.6842   \n",
       "  7         0.022876             0.7500  ...        0.062340           0.6700   \n",
       "  8         0.024668             0.8558  ...        0.090695           0.7500   \n",
       "  9         0.016712             0.9318  ...        0.176559           0.5000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              386.0   \n",
       "  1         0.268643                   0.1              386.0   \n",
       "  2         0.217255                   0.2              386.0   \n",
       "  3         0.183813                   0.3              386.0   \n",
       "  4         0.196298                   0.4              386.0   \n",
       "  5         0.115446                   0.5              386.0   \n",
       "  6         0.137928                   0.6              386.0   \n",
       "  7         0.129207                   0.7              386.0   \n",
       "  8         0.250000                   0.8              386.0   \n",
       "  9         0.500000                   0.9              386.0   \n",
       "  10        0.000000                   1.0              386.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7233.0                10.0                 250.0   \n",
       "  1                7233.0                10.0                 250.0   \n",
       "  2                7233.0                10.0                 250.0   \n",
       "  3                7233.0                10.0                 250.0   \n",
       "  4                7233.0                10.0                 250.0   \n",
       "  5                7233.0                10.0                 250.0   \n",
       "  6                7233.0                10.0                 250.0   \n",
       "  7                7233.0                10.0                 250.0   \n",
       "  8                7233.0                10.0                 250.0   \n",
       "  9                7233.0                10.0                 250.0   \n",
       "  10               7233.0                10.0                 250.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                19.0                558.0  \n",
       "  1                19.0                558.0  \n",
       "  2                19.0                558.0  \n",
       "  3                19.0                558.0  \n",
       "  4                19.0                558.0  \n",
       "  5                19.0                558.0  \n",
       "  6                19.0                558.0  \n",
       "  7                19.0                558.0  \n",
       "  8                19.0                558.0  \n",
       "  9                19.0                558.0  \n",
       "  10               19.0                558.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9106      0.010502           0.9074   \n",
       "  2                  0.2         0.8022      0.012276           0.8042   \n",
       "  3                  0.3         0.6858      0.042026           0.6936   \n",
       "  4                  0.4         0.5782      0.044274           0.5792   \n",
       "  5                  0.5         0.4886      0.051140           0.4874   \n",
       "  6                  0.6         0.3758      0.053186           0.3720   \n",
       "  7                  0.7         0.2708      0.037030           0.2708   \n",
       "  8                  0.8         0.1594      0.027465           0.1572   \n",
       "  9                  0.9         0.0706      0.020599           0.0664   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.013390           0.9356        0.068806           0.0894   \n",
       "  2         0.014584           0.7856        0.091292           0.1978   \n",
       "  3         0.031222           0.6214        0.144168           0.3142   \n",
       "  4         0.037891           0.5714        0.142875           0.4218   \n",
       "  5         0.043855           0.5000        0.165523           0.5114   \n",
       "  6         0.044744           0.4072        0.130014           0.6242   \n",
       "  7         0.029107           0.2712        0.130412           0.7292   \n",
       "  8         0.027554           0.1784        0.097769           0.8406   \n",
       "  9         0.018942           0.1072        0.056606           0.9294   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.010502             0.0926  ...        0.016072           0.9092   \n",
       "  2         0.012276             0.1958  ...        0.026650           0.8528   \n",
       "  3         0.042026             0.3064  ...        0.025985           0.9440   \n",
       "  4         0.044274             0.4208  ...        0.033730           0.9632   \n",
       "  5         0.051140             0.5126  ...        0.034492           0.9644   \n",
       "  6         0.053186             0.6280  ...        0.023675           1.0000   \n",
       "  7         0.037030             0.7292  ...        0.026425           1.0000   \n",
       "  8         0.027465             0.8428  ...        0.051145           1.0000   \n",
       "  9         0.020599             0.9336  ...        0.093278           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1094.0   \n",
       "  1         0.083673                   0.1             1094.0   \n",
       "  2         0.068277                   0.2             1094.0   \n",
       "  3         0.037463                   0.3             1094.0   \n",
       "  4         0.036328                   0.4             1094.0   \n",
       "  5         0.051169                   0.5             1094.0   \n",
       "  6         0.000000                   0.6             1094.0   \n",
       "  7         0.000000                   0.7             1094.0   \n",
       "  8         0.000000                   0.8             1094.0   \n",
       "  9         0.000000                   0.9             1094.0   \n",
       "  10        0.000000                   1.0             1094.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5719.0                38.0                 195.0   \n",
       "  1                5719.0                38.0                 195.0   \n",
       "  2                5719.0                38.0                 195.0   \n",
       "  3                5719.0                38.0                 195.0   \n",
       "  4                5719.0                38.0                 195.0   \n",
       "  5                5719.0                38.0                 195.0   \n",
       "  6                5719.0                38.0                 195.0   \n",
       "  7                5719.0                38.0                 195.0   \n",
       "  8                5719.0                38.0                 195.0   \n",
       "  9                5719.0                38.0                 195.0   \n",
       "  10               5719.0                38.0                 195.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                56.0                457.0  \n",
       "  1                56.0                457.0  \n",
       "  2                56.0                457.0  \n",
       "  3                56.0                457.0  \n",
       "  4                56.0                457.0  \n",
       "  5                56.0                457.0  \n",
       "  6                56.0                457.0  \n",
       "  7                56.0                457.0  \n",
       "  8                56.0                457.0  \n",
       "  9                56.0                457.0  \n",
       "  10               56.0                457.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9104      0.027328           0.9066   \n",
       "  2                  0.2         0.8170      0.038685           0.8130   \n",
       "  3                  0.3         0.7082      0.034716           0.7000   \n",
       "  4                  0.4         0.6116      0.043873           0.6052   \n",
       "  5                  0.5         0.4998      0.041620           0.4926   \n",
       "  6                  0.6         0.3814      0.047009           0.3742   \n",
       "  7                  0.7         0.2754      0.039985           0.2706   \n",
       "  8                  0.8         0.1762      0.020523           0.1690   \n",
       "  9                  0.9         0.0740      0.012550           0.0676   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.028745             0.96        0.041833           0.0896   \n",
       "  2         0.036606             0.87        0.120416           0.1830   \n",
       "  3         0.030773             0.82        0.130384           0.2918   \n",
       "  4         0.034694             0.70        0.196850           0.3884   \n",
       "  5         0.033141             0.60        0.212132           0.5002   \n",
       "  6         0.040283             0.48        0.201866           0.6186   \n",
       "  7         0.036198             0.34        0.147479           0.7246   \n",
       "  8         0.016477             0.27        0.125499           0.8238   \n",
       "  9         0.012818             0.16        0.114018           0.9260   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.027328             0.0934  ...        0.118024           0.9178   \n",
       "  2         0.038685             0.1870  ...        0.036438           0.8094   \n",
       "  3         0.034716             0.3000  ...        0.017479           0.7930   \n",
       "  4         0.043873             0.3948  ...        0.026670           0.7778   \n",
       "  5         0.041620             0.5074  ...        0.057230           0.7874   \n",
       "  6         0.047009             0.6258  ...        0.080131           0.8228   \n",
       "  7         0.039985             0.7294  ...        0.074099           0.8534   \n",
       "  8         0.020523             0.8310  ...        0.077727           0.9278   \n",
       "  9         0.012550             0.9324  ...        0.086607           0.8000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              515.0   \n",
       "  1         0.084464                   0.1              515.0   \n",
       "  2         0.162188                   0.2              515.0   \n",
       "  3         0.146171                   0.3              515.0   \n",
       "  4         0.154694                   0.4              515.0   \n",
       "  5         0.151743                   0.5              515.0   \n",
       "  6         0.135623                   0.6              515.0   \n",
       "  7         0.092395                   0.7              515.0   \n",
       "  8         0.110405                   0.8              515.0   \n",
       "  9         0.447214                   0.9              515.0   \n",
       "  10        0.000000                   1.0              515.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7542.0                28.0                 234.0   \n",
       "  1                7542.0                28.0                 234.0   \n",
       "  2                7542.0                28.0                 234.0   \n",
       "  3                7542.0                28.0                 234.0   \n",
       "  4                7542.0                28.0                 234.0   \n",
       "  5                7542.0                28.0                 234.0   \n",
       "  6                7542.0                28.0                 234.0   \n",
       "  7                7542.0                28.0                 234.0   \n",
       "  8                7542.0                28.0                 234.0   \n",
       "  9                7542.0                28.0                 234.0   \n",
       "  10               7542.0                28.0                 234.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                40.0                543.0  \n",
       "  1                40.0                543.0  \n",
       "  2                40.0                543.0  \n",
       "  3                40.0                543.0  \n",
       "  4                40.0                543.0  \n",
       "  5                40.0                543.0  \n",
       "  6                40.0                543.0  \n",
       "  7                40.0                543.0  \n",
       "  8                40.0                543.0  \n",
       "  9                40.0                543.0  \n",
       "  10               40.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9096      0.023766           0.9090   \n",
       "  2                  0.2         0.8074      0.032199           0.8058   \n",
       "  3                  0.3         0.6922      0.022698           0.6894   \n",
       "  4                  0.4         0.5954      0.032555           0.5898   \n",
       "  5                  0.5         0.4756      0.041241           0.4696   \n",
       "  6                  0.6         0.3636      0.041567           0.3560   \n",
       "  7                  0.7         0.2670      0.034409           0.2610   \n",
       "  8                  0.8         0.1720      0.033511           0.1664   \n",
       "  9                  0.9         0.0808      0.028341           0.0798   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.022113           0.9220        0.063368           0.0904   \n",
       "  2         0.035626           0.8222        0.106601           0.1926   \n",
       "  3         0.019655           0.7334        0.106653           0.3078   \n",
       "  4         0.029141           0.6670        0.111000           0.4046   \n",
       "  5         0.043259           0.5558        0.103965           0.5244   \n",
       "  6         0.041400           0.4556        0.106887           0.6364   \n",
       "  7         0.030911           0.3442        0.126713           0.7330   \n",
       "  8         0.030072           0.2444        0.115160           0.8280   \n",
       "  9         0.026042           0.0890        0.139244           0.9192   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.023766             0.0910  ...        0.063014           0.8498   \n",
       "  2         0.032199             0.1942  ...        0.044314           0.7804   \n",
       "  3         0.022698             0.3106  ...        0.027197           0.7278   \n",
       "  4         0.032555             0.4102  ...        0.046944           0.7770   \n",
       "  5         0.041241             0.5304  ...        0.063581           0.8178   \n",
       "  6         0.041567             0.6440  ...        0.078525           0.7836   \n",
       "  7         0.034409             0.7390  ...        0.048298           0.8012   \n",
       "  8         0.033511             0.8336  ...        0.101481           0.8434   \n",
       "  9         0.028341             0.9202  ...        0.134301           0.6000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              338.0   \n",
       "  1         0.102395                   0.1              338.0   \n",
       "  2         0.113914                   0.2              338.0   \n",
       "  3         0.104438                   0.3              338.0   \n",
       "  4         0.078591                   0.4              338.0   \n",
       "  5         0.063786                   0.5              338.0   \n",
       "  6         0.080755                   0.6              338.0   \n",
       "  7         0.097600                   0.7              338.0   \n",
       "  8         0.150641                   0.8              338.0   \n",
       "  9         0.547723                   0.9              338.0   \n",
       "  10        0.000000                   1.0              338.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6362.0                18.0                 192.0   \n",
       "  1                6362.0                18.0                 192.0   \n",
       "  2                6362.0                18.0                 192.0   \n",
       "  3                6362.0                18.0                 192.0   \n",
       "  4                6362.0                18.0                 192.0   \n",
       "  5                6362.0                18.0                 192.0   \n",
       "  6                6362.0                18.0                 192.0   \n",
       "  7                6362.0                18.0                 192.0   \n",
       "  8                6362.0                18.0                 192.0   \n",
       "  9                6362.0                18.0                 192.0   \n",
       "  10               6362.0                18.0                 192.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                36.0                466.0  \n",
       "  1                36.0                466.0  \n",
       "  2                36.0                466.0  \n",
       "  3                36.0                466.0  \n",
       "  4                36.0                466.0  \n",
       "  5                36.0                466.0  \n",
       "  6                36.0                466.0  \n",
       "  7                36.0                466.0  \n",
       "  8                36.0                466.0  \n",
       "  9                36.0                466.0  \n",
       "  10               36.0                466.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9242      0.017584           0.9236   \n",
       "  2                  0.2         0.8408      0.032244           0.8420   \n",
       "  3                  0.3         0.7242      0.021568           0.7208   \n",
       "  4                  0.4         0.6076      0.012402           0.6016   \n",
       "  5                  0.5         0.4928      0.013809           0.4804   \n",
       "  6                  0.6         0.3936      0.020330           0.3816   \n",
       "  7                  0.7         0.2814      0.020416           0.2718   \n",
       "  8                  0.8         0.1694      0.015060           0.1572   \n",
       "  9                  0.9         0.0766      0.017644           0.0694   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.015678           0.9280        0.067302           0.0758   \n",
       "  2         0.028469           0.8338        0.083143           0.1592   \n",
       "  3         0.015675           0.7396        0.098353           0.2758   \n",
       "  4         0.016697           0.6366        0.100443           0.3924   \n",
       "  5         0.024172           0.5512        0.065289           0.5072   \n",
       "  6         0.030908           0.4526        0.061232           0.6064   \n",
       "  7         0.023910           0.3270        0.058664           0.7186   \n",
       "  8         0.028978           0.2282        0.071869           0.8306   \n",
       "  9         0.025774           0.1118        0.051703           0.9234   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.017584             0.0764  ...        0.028702           0.8570   \n",
       "  2         0.032244             0.1580  ...        0.028609           0.7808   \n",
       "  3         0.021568             0.2792  ...        0.026661           0.7510   \n",
       "  4         0.012402             0.3984  ...        0.036114           0.7822   \n",
       "  5         0.013809             0.5196  ...        0.034946           0.8540   \n",
       "  6         0.020330             0.6184  ...        0.033162           0.8994   \n",
       "  7         0.020416             0.7282  ...        0.061693           0.9272   \n",
       "  8         0.015060             0.8428  ...        0.069446           0.9534   \n",
       "  9         0.017644             0.9306  ...        0.127052           1.0000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0             1032.0   \n",
       "  1         0.116970                   0.1             1032.0   \n",
       "  2         0.104174                   0.2             1032.0   \n",
       "  3         0.080009                   0.3             1032.0   \n",
       "  4         0.089220                   0.4             1032.0   \n",
       "  5         0.078800                   0.5             1032.0   \n",
       "  6         0.078063                   0.6             1032.0   \n",
       "  7         0.051456                   0.7             1032.0   \n",
       "  8         0.043038                   0.8             1032.0   \n",
       "  9         0.000000                   0.9             1032.0   \n",
       "  10        0.000000                   1.0             1032.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                5653.0                47.0                 181.0   \n",
       "  1                5653.0                47.0                 181.0   \n",
       "  2                5653.0                47.0                 181.0   \n",
       "  3                5653.0                47.0                 181.0   \n",
       "  4                5653.0                47.0                 181.0   \n",
       "  5                5653.0                47.0                 181.0   \n",
       "  6                5653.0                47.0                 181.0   \n",
       "  7                5653.0                47.0                 181.0   \n",
       "  8                5653.0                47.0                 181.0   \n",
       "  9                5653.0                47.0                 181.0   \n",
       "  10               5653.0                47.0                 181.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                89.0                433.0  \n",
       "  1                89.0                433.0  \n",
       "  2                89.0                433.0  \n",
       "  3                89.0                433.0  \n",
       "  4                89.0                433.0  \n",
       "  5                89.0                433.0  \n",
       "  6                89.0                433.0  \n",
       "  7                89.0                433.0  \n",
       "  8                89.0                433.0  \n",
       "  9                89.0                433.0  \n",
       "  10               89.0                433.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9088      0.011649           0.9086   \n",
       "  2                  0.2         0.8188      0.021684           0.8190   \n",
       "  3                  0.3         0.7342      0.020849           0.7346   \n",
       "  4                  0.4         0.6268      0.039771           0.6264   \n",
       "  5                  0.5         0.5072      0.037265           0.5058   \n",
       "  6                  0.6         0.3936      0.043316           0.3918   \n",
       "  7                  0.7         0.3014      0.047805           0.2994   \n",
       "  8                  0.8         0.1878      0.037413           0.1858   \n",
       "  9                  0.9         0.0900      0.019144           0.0896   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.014328             0.90        0.223607           0.0912   \n",
       "  2         0.020062             0.80        0.325960           0.1812   \n",
       "  3         0.016257             0.70        0.447214           0.2658   \n",
       "  4         0.038338             0.65        0.418330           0.3732   \n",
       "  5         0.035570             0.60        0.379144           0.4928   \n",
       "  6         0.045329             0.50        0.353553           0.6064   \n",
       "  7         0.048788             0.45        0.325960           0.6986   \n",
       "  8         0.036176             0.30        0.273861           0.8122   \n",
       "  9         0.019604             0.10        0.136931           0.9100   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.011649             0.0914  ...        0.180835           0.6000   \n",
       "  2         0.021684             0.1810  ...        0.095541           0.7334   \n",
       "  3         0.020849             0.2654  ...        0.067377           0.7000   \n",
       "  4         0.039771             0.3736  ...        0.105720           0.6500   \n",
       "  5         0.037265             0.4942  ...        0.136835           0.6500   \n",
       "  6         0.043316             0.6082  ...        0.172712           0.6666   \n",
       "  7         0.047805             0.7006  ...        0.181994           0.8000   \n",
       "  8         0.037413             0.8142  ...        0.195163           0.8000   \n",
       "  9         0.019144             0.9104  ...        0.141242           0.4000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              295.0   \n",
       "  1         0.547723                   0.1              295.0   \n",
       "  2         0.434601                   0.2              295.0   \n",
       "  3         0.447214                   0.3              295.0   \n",
       "  4         0.418330                   0.4              295.0   \n",
       "  5         0.418330                   0.5              295.0   \n",
       "  6         0.471463                   0.6              295.0   \n",
       "  7         0.447214                   0.7              295.0   \n",
       "  8         0.447214                   0.8              295.0   \n",
       "  9         0.547723                   0.9              295.0   \n",
       "  10        0.000000                   1.0              295.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7742.0                 4.0                 242.0   \n",
       "  1                7742.0                 4.0                 242.0   \n",
       "  2                7742.0                 4.0                 242.0   \n",
       "  3                7742.0                 4.0                 242.0   \n",
       "  4                7742.0                 4.0                 242.0   \n",
       "  5                7742.0                 4.0                 242.0   \n",
       "  6                7742.0                 4.0                 242.0   \n",
       "  7                7742.0                 4.0                 242.0   \n",
       "  8                7742.0                 4.0                 242.0   \n",
       "  9                7742.0                 4.0                 242.0   \n",
       "  10               7742.0                 4.0                 242.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                 8.0                543.0  \n",
       "  1                 8.0                543.0  \n",
       "  2                 8.0                543.0  \n",
       "  3                 8.0                543.0  \n",
       "  4                 8.0                543.0  \n",
       "  5                 8.0                543.0  \n",
       "  6                 8.0                543.0  \n",
       "  7                 8.0                543.0  \n",
       "  8                 8.0                543.0  \n",
       "  9                 8.0                543.0  \n",
       "  10                8.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9060      0.030174           0.9014   \n",
       "  2                  0.2         0.7970      0.032350           0.7968   \n",
       "  3                  0.3         0.6954      0.044652           0.6950   \n",
       "  4                  0.4         0.5986      0.056199           0.5968   \n",
       "  5                  0.5         0.5060      0.058039           0.5106   \n",
       "  6                  0.6         0.4110      0.040100           0.4176   \n",
       "  7                  0.7         0.3010      0.038685           0.3098   \n",
       "  8                  0.8         0.1860      0.017335           0.1936   \n",
       "  9                  0.9         0.0826      0.013795           0.0846   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.030827           0.9388        0.053392           0.0940   \n",
       "  2         0.035394           0.8000        0.123410           0.2030   \n",
       "  3         0.046792           0.7002        0.098971           0.3046   \n",
       "  4         0.058981           0.6110        0.119445           0.4014   \n",
       "  5         0.066305           0.4722        0.168879           0.4940   \n",
       "  6         0.053276           0.3668        0.157600           0.5890   \n",
       "  7         0.056238           0.2390        0.117326           0.6990   \n",
       "  8         0.029467           0.1334        0.084269           0.8140   \n",
       "  9         0.019100           0.0670        0.057628           0.9174   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.030174             0.0986  ...        0.041386           0.9208   \n",
       "  2         0.032350             0.2032  ...        0.035907           0.8632   \n",
       "  3         0.044652             0.3050  ...        0.031864           0.9208   \n",
       "  4         0.056199             0.4032  ...        0.041693           0.9654   \n",
       "  5         0.058039             0.4894  ...        0.047108           0.9666   \n",
       "  6         0.040100             0.5824  ...        0.050587           0.9428   \n",
       "  7         0.038685             0.6902  ...        0.049419           0.9500   \n",
       "  8         0.017335             0.8064  ...        0.043888           0.9334   \n",
       "  9         0.013795             0.9154  ...        0.058304           0.9000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              933.0   \n",
       "  1         0.066172                   0.1              933.0   \n",
       "  2         0.065297                   0.2              933.0   \n",
       "  3         0.058427                   0.3              933.0   \n",
       "  4         0.040863                   0.4              933.0   \n",
       "  5         0.074685                   0.5              933.0   \n",
       "  6         0.127903                   0.6              933.0   \n",
       "  7         0.111803                   0.7              933.0   \n",
       "  8         0.148922                   0.8              933.0   \n",
       "  9         0.223607                   0.9              933.0   \n",
       "  10        0.000000                   1.0              933.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                6687.0                29.0                 236.0   \n",
       "  1                6687.0                29.0                 236.0   \n",
       "  2                6687.0                29.0                 236.0   \n",
       "  3                6687.0                29.0                 236.0   \n",
       "  4                6687.0                29.0                 236.0   \n",
       "  5                6687.0                29.0                 236.0   \n",
       "  6                6687.0                29.0                 236.0   \n",
       "  7                6687.0                29.0                 236.0   \n",
       "  8                6687.0                29.0                 236.0   \n",
       "  9                6687.0                29.0                 236.0   \n",
       "  10               6687.0                29.0                 236.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                71.0                506.0  \n",
       "  1                71.0                506.0  \n",
       "  2                71.0                506.0  \n",
       "  3                71.0                506.0  \n",
       "  4                71.0                506.0  \n",
       "  5                71.0                506.0  \n",
       "  6                71.0                506.0  \n",
       "  7                71.0                506.0  \n",
       "  8                71.0                506.0  \n",
       "  9                71.0                506.0  \n",
       "  10               71.0                506.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9240      0.014000           0.9246   \n",
       "  2                  0.2         0.8366      0.021090           0.8366   \n",
       "  3                  0.3         0.7310      0.047255           0.7336   \n",
       "  4                  0.4         0.6190      0.049076           0.6226   \n",
       "  5                  0.5         0.4902      0.043734           0.4918   \n",
       "  6                  0.6         0.4062      0.041063           0.4066   \n",
       "  7                  0.7         0.2988      0.033425           0.3000   \n",
       "  8                  0.8         0.1924      0.009965           0.1912   \n",
       "  9                  0.9         0.0904      0.009476           0.0878   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.012157             0.90        0.122474           0.0760   \n",
       "  2         0.016562             0.84        0.181659           0.1634   \n",
       "  3         0.043547             0.66        0.207364           0.2690   \n",
       "  4         0.049682             0.52        0.130384           0.3810   \n",
       "  5         0.044347             0.44        0.194936           0.5098   \n",
       "  6         0.045275             0.40        0.187083           0.5938   \n",
       "  7         0.036339             0.26        0.194936           0.7012   \n",
       "  8         0.013480             0.22        0.164317           0.8076   \n",
       "  9         0.013405             0.16        0.151658           0.9096   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.014000             0.0754  ...        0.143243           0.8166   \n",
       "  2         0.021090             0.1634  ...        0.105495           0.7856   \n",
       "  3         0.047255             0.2664  ...        0.086866           0.6264   \n",
       "  4         0.049076             0.3774  ...        0.111509           0.5376   \n",
       "  5         0.043734             0.5082  ...        0.148136           0.5958   \n",
       "  6         0.041063             0.5934  ...        0.115731           0.6628   \n",
       "  7         0.033425             0.7000  ...        0.081220           0.6048   \n",
       "  8         0.009965             0.8088  ...        0.108320           0.9000   \n",
       "  9         0.009476             0.9122  ...        0.125220           0.8000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              419.0   \n",
       "  1         0.207492                   0.1              419.0   \n",
       "  2         0.236988                   0.2              419.0   \n",
       "  3         0.184180                   0.3              419.0   \n",
       "  4         0.110909                   0.4              419.0   \n",
       "  5         0.133840                   0.5              419.0   \n",
       "  6         0.181919                   0.6              419.0   \n",
       "  7         0.197611                   0.7              419.0   \n",
       "  8         0.223607                   0.8              419.0   \n",
       "  9         0.447214                   0.9              419.0   \n",
       "  10        0.000000                   1.0              419.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7763.0                10.0                 270.0   \n",
       "  1                7763.0                10.0                 270.0   \n",
       "  2                7763.0                10.0                 270.0   \n",
       "  3                7763.0                10.0                 270.0   \n",
       "  4                7763.0                10.0                 270.0   \n",
       "  5                7763.0                10.0                 270.0   \n",
       "  6                7763.0                10.0                 270.0   \n",
       "  7                7763.0                10.0                 270.0   \n",
       "  8                7763.0                10.0                 270.0   \n",
       "  9                7763.0                10.0                 270.0   \n",
       "  10               7763.0                10.0                 270.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                20.0                548.0  \n",
       "  1                20.0                548.0  \n",
       "  2                20.0                548.0  \n",
       "  3                20.0                548.0  \n",
       "  4                20.0                548.0  \n",
       "  5                20.0                548.0  \n",
       "  6                20.0                548.0  \n",
       "  7                20.0                548.0  \n",
       "  8                20.0                548.0  \n",
       "  9                20.0                548.0  \n",
       "  10               20.0                548.0  \n",
       "  \n",
       "  [11 rows x 32 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9100      0.006892           0.9094   \n",
       "  2                  0.2         0.7992      0.010035           0.7938   \n",
       "  3                  0.3         0.6856      0.014536           0.6790   \n",
       "  4                  0.4         0.5720      0.017706           0.5662   \n",
       "  5                  0.5         0.4718      0.023679           0.4638   \n",
       "  6                  0.6         0.3590      0.023087           0.3542   \n",
       "  7                  0.7         0.2578      0.012091           0.2510   \n",
       "  8                  0.8         0.1610      0.013038           0.1532   \n",
       "  9                  0.9         0.0782      0.013461           0.0744   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006309           0.9232        0.068328           0.0900   \n",
       "  2         0.009524           0.8980        0.083135           0.2008   \n",
       "  3         0.018775           0.8066        0.098916           0.3144   \n",
       "  4         0.023178           0.6766        0.157890           0.4280   \n",
       "  5         0.023113           0.6126        0.161336           0.5282   \n",
       "  6         0.024874           0.4426        0.209507           0.6410   \n",
       "  7         0.014440           0.3780        0.188445           0.7422   \n",
       "  8         0.019447           0.2990        0.146549           0.8390   \n",
       "  9         0.013759           0.1434        0.176190           0.9218   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0         0.000000             0.0000  ...        0.000000           0.0000   \n",
       "  1         0.006892             0.0906  ...        0.047321           0.8542   \n",
       "  2         0.010035             0.2062  ...        0.029406           0.8458   \n",
       "  3         0.014536             0.3210  ...        0.038888           0.7884   \n",
       "  4         0.017706             0.4338  ...        0.066036           0.7930   \n",
       "  5         0.023679             0.5362  ...        0.076647           0.8228   \n",
       "  6         0.023087             0.6458  ...        0.091993           0.8034   \n",
       "  7         0.012091             0.7490  ...        0.097774           0.8028   \n",
       "  8         0.013038             0.8468  ...        0.147701           0.8600   \n",
       "  9         0.013461             0.9256  ...        0.100029           0.6000   \n",
       "  10        0.000000             1.0000  ...        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives_train  \\\n",
       "  0         0.000000                   0.0              204.0   \n",
       "  1         0.106135                   0.1              204.0   \n",
       "  2         0.118105                   0.2              204.0   \n",
       "  3         0.101569                   0.3              204.0   \n",
       "  4         0.081287                   0.4              204.0   \n",
       "  5         0.084535                   0.5              204.0   \n",
       "  6         0.141537                   0.6              204.0   \n",
       "  7         0.155953                   0.7              204.0   \n",
       "  8         0.142107                   0.8              204.0   \n",
       "  9         0.547723                   0.9              204.0   \n",
       "  10        0.000000                   1.0              204.0   \n",
       "  \n",
       "      num_inactives_train  num_actives_update  num_inactives_update  \\\n",
       "  0                7414.0                15.0                 245.0   \n",
       "  1                7414.0                15.0                 245.0   \n",
       "  2                7414.0                15.0                 245.0   \n",
       "  3                7414.0                15.0                 245.0   \n",
       "  4                7414.0                15.0                 245.0   \n",
       "  5                7414.0                15.0                 245.0   \n",
       "  6                7414.0                15.0                 245.0   \n",
       "  7                7414.0                15.0                 245.0   \n",
       "  8                7414.0                15.0                 245.0   \n",
       "  9                7414.0                15.0                 245.0   \n",
       "  10               7414.0                15.0                 245.0   \n",
       "  \n",
       "      num_actives_score  num_inactives_score  \n",
       "  0                31.0                543.0  \n",
       "  1                31.0                543.0  \n",
       "  2                31.0                543.0  \n",
       "  3                31.0                543.0  \n",
       "  4                31.0                543.0  \n",
       "  5                31.0                543.0  \n",
       "  6                31.0                543.0  \n",
       "  7                31.0                543.0  \n",
       "  8                31.0                543.0  \n",
       "  9                31.0                543.0  \n",
       "  10               31.0                543.0  \n",
       "  \n",
       "  [11 rows x 32 columns]],\n",
       " 'cv_trainupdate': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9192      0.007596           0.9184   \n",
       "  2                  0.2         0.8204      0.008620           0.8184   \n",
       "  3                  0.3         0.7182      0.009203           0.7158   \n",
       "  4                  0.4         0.6080      0.013285           0.6066   \n",
       "  5                  0.5         0.4980      0.009301           0.4962   \n",
       "  6                  0.6         0.3908      0.006907           0.3880   \n",
       "  7                  0.7         0.2848      0.010663           0.2818   \n",
       "  8                  0.8         0.1838      0.005215           0.1824   \n",
       "  9                  0.9         0.0854      0.002608           0.0868   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007162           0.9380        0.016000           0.0808   \n",
       "  2         0.008019           0.8724        0.040998           0.1796   \n",
       "  3         0.008701           0.7796        0.051588           0.2818   \n",
       "  4         0.010139           0.6456        0.108675           0.3920   \n",
       "  5         0.008106           0.5402        0.110119           0.5020   \n",
       "  6         0.005523           0.4688        0.106617           0.6092   \n",
       "  7         0.009149           0.3570        0.106167           0.7152   \n",
       "  8         0.006877           0.2202        0.070517           0.8162   \n",
       "  9         0.003033           0.0528        0.042417           0.9146   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007596             0.0816  ...          0.064098         0.8588   \n",
       "  2         0.008620             0.1816  ...          0.020057         0.8044   \n",
       "  3         0.009203             0.2842  ...          0.040209         0.8686   \n",
       "  4         0.013285             0.3934  ...          0.111541         0.9286   \n",
       "  5         0.009301             0.5038  ...          0.113144         0.9646   \n",
       "  6         0.006907             0.6120  ...          0.112273         0.9762   \n",
       "  7         0.010663             0.7182  ...          0.125221         0.9844   \n",
       "  8         0.005215             0.8176  ...          0.079684         0.9900   \n",
       "  9         0.002608             0.9132  ...          0.069766         0.9892   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.011100           0.8552        0.011692           0.9218   \n",
       "  2       0.004336           0.8022        0.005310           0.8664   \n",
       "  3       0.018515           0.8686        0.019604           0.8704   \n",
       "  4       0.008849           0.9306        0.009127           0.8836   \n",
       "  5       0.007021           0.9686        0.008050           0.8766   \n",
       "  6       0.010085           0.9802        0.009418           0.8966   \n",
       "  7       0.009397           0.9886        0.007570           0.9084   \n",
       "  8       0.010173           0.9932        0.006419           0.9208   \n",
       "  9       0.014061           0.9944        0.005857           0.9334   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.016392                   0.1            0              0  \n",
       "  2         0.040346                   0.2            0              0  \n",
       "  3         0.020157                   0.3            0              0  \n",
       "  4         0.020562                   0.4            0              0  \n",
       "  5         0.024337                   0.5            0              0  \n",
       "  6         0.031262                   0.6            0              0  \n",
       "  7         0.036631                   0.7            0              0  \n",
       "  8         0.109769                   0.8            0              0  \n",
       "  9         0.148922                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9238      0.004147           0.9236   \n",
       "  2                  0.2         0.8296      0.006387           0.8330   \n",
       "  3                  0.3         0.7342      0.013737           0.7414   \n",
       "  4                  0.4         0.5942      0.013330           0.5944   \n",
       "  5                  0.5         0.4928      0.016589           0.4916   \n",
       "  6                  0.6         0.3802      0.013682           0.3744   \n",
       "  7                  0.7         0.2738      0.014237           0.2656   \n",
       "  8                  0.8         0.1648      0.004970           0.1596   \n",
       "  9                  0.9         0.0740      0.003674           0.0710   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004278           0.9256        0.024399           0.0762   \n",
       "  2         0.005050           0.8056        0.039456           0.1704   \n",
       "  3         0.011866           0.6814        0.032106           0.2658   \n",
       "  4         0.010597           0.5928        0.034098           0.4058   \n",
       "  5         0.016772           0.5014        0.024399           0.5072   \n",
       "  6         0.014639           0.4218        0.012398           0.6198   \n",
       "  7         0.015043           0.3308        0.030327           0.7262   \n",
       "  8         0.007266           0.2008        0.047331           0.8352   \n",
       "  9         0.003082           0.0966        0.032308           0.9260   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.004147             0.0764  ...          0.023958         0.7576   \n",
       "  2         0.006387             0.1670  ...          0.036439         0.7412   \n",
       "  3         0.013737             0.2586  ...          0.007403         0.7242   \n",
       "  4         0.013330             0.4056  ...          0.027722         0.7880   \n",
       "  5         0.016589             0.5084  ...          0.037023         0.8600   \n",
       "  6         0.013682             0.6256  ...          0.045698         0.8960   \n",
       "  7         0.014237             0.7344  ...          0.043744         0.9148   \n",
       "  8         0.004970             0.8404  ...          0.054532         0.9350   \n",
       "  9         0.003674             0.9290  ...          0.028815         0.9484   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.010065           0.7202        0.025332           0.8754   \n",
       "  2       0.009338           0.7378        0.010521           0.7598   \n",
       "  3       0.011563           0.7314        0.008820           0.6764   \n",
       "  4       0.010392           0.8030        0.012590           0.6980   \n",
       "  5       0.012845           0.8868        0.012438           0.7128   \n",
       "  6       0.008155           0.9278        0.004550           0.7406   \n",
       "  7       0.009094           0.9482        0.019162           0.7664   \n",
       "  8       0.011958           0.9746        0.021709           0.7586   \n",
       "  9       0.030624           0.9908        0.009935           0.7726   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.038390                   0.1            0              0  \n",
       "  2         0.042092                   0.2            0              0  \n",
       "  3         0.031604                   0.3            0              0  \n",
       "  4         0.034095                   0.4            0              0  \n",
       "  5         0.040567                   0.5            0              0  \n",
       "  6         0.049283                   0.6            0              0  \n",
       "  7         0.056239                   0.7            0              0  \n",
       "  8         0.063189                   0.8            0              0  \n",
       "  9         0.153205                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9288      0.008075           0.9294   \n",
       "  2                  0.2         0.8256      0.007021           0.8264   \n",
       "  3                  0.3         0.7186      0.010237           0.7184   \n",
       "  4                  0.4         0.6048      0.010964           0.6046   \n",
       "  5                  0.5         0.4914      0.016319           0.4890   \n",
       "  6                  0.6         0.3710      0.017073           0.3684   \n",
       "  7                  0.7         0.2588      0.014687           0.2570   \n",
       "  8                  0.8         0.1512      0.013142           0.1496   \n",
       "  9                  0.9         0.0628      0.004494           0.0622   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009017           0.9194        0.027264           0.0712   \n",
       "  2         0.008081           0.8098        0.048448           0.1744   \n",
       "  3         0.011059           0.7236        0.056576           0.2814   \n",
       "  4         0.010738           0.6116        0.067888           0.3952   \n",
       "  5         0.015050           0.5474        0.061133           0.5086   \n",
       "  6         0.014809           0.4322        0.074227           0.6290   \n",
       "  7         0.014405           0.3030        0.042024           0.7412   \n",
       "  8         0.011845           0.1880        0.043342           0.8488   \n",
       "  9         0.004025           0.0832        0.028700           0.9372   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.008075             0.0706  ...          0.037752         0.6978   \n",
       "  2         0.007021             0.1736  ...          0.038351         0.7090   \n",
       "  3         0.010237             0.2816  ...          0.014789         0.7344   \n",
       "  4         0.010964             0.3954  ...          0.042429         0.9270   \n",
       "  5         0.016319             0.5110  ...          0.064817         0.9754   \n",
       "  6         0.017073             0.6316  ...          0.096067         0.9742   \n",
       "  7         0.014687             0.7430  ...          0.062460         0.9788   \n",
       "  8         0.013142             0.8504  ...          0.044859         0.9794   \n",
       "  9         0.004494             0.9378  ...          0.041427         0.9686   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.048241           0.6694        0.060949           0.8862   \n",
       "  2       0.028328           0.7040        0.032764           0.7800   \n",
       "  3       0.043316           0.7350        0.047681           0.7262   \n",
       "  4       0.036966           0.9394        0.042063           0.7182   \n",
       "  5       0.002881           0.9926        0.002074           0.7240   \n",
       "  6       0.003347           0.9940        0.003240           0.7066   \n",
       "  7       0.004658           0.9988        0.001095           0.7118   \n",
       "  8       0.004930           0.9984        0.002191           0.7258   \n",
       "  9       0.012422           0.9982        0.004025           0.6446   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.037798                   0.1            0              0  \n",
       "  2         0.049603                   0.2            0              0  \n",
       "  3         0.049165                   0.3            0              0  \n",
       "  4         0.059655                   0.4            0              0  \n",
       "  5         0.055826                   0.5            0              0  \n",
       "  6         0.047773                   0.6            0              0  \n",
       "  7         0.028438                   0.7            0              0  \n",
       "  8         0.058806                   0.8            0              0  \n",
       "  9         0.079591                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9180      0.007416           0.9192   \n",
       "  2                  0.2         0.8344      0.007127           0.8360   \n",
       "  3                  0.3         0.7144      0.008444           0.7146   \n",
       "  4                  0.4         0.6116      0.009864           0.6128   \n",
       "  5                  0.5         0.4988      0.010545           0.4984   \n",
       "  6                  0.6         0.3904      0.013939           0.3900   \n",
       "  7                  0.7         0.2766      0.013145           0.2732   \n",
       "  8                  0.8         0.1692      0.015675           0.1654   \n",
       "  9                  0.9         0.0746      0.009017           0.0742   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007694           0.8964        0.025764           0.0820   \n",
       "  2         0.007969           0.8028        0.031507           0.1656   \n",
       "  3         0.006841           0.7068        0.068736           0.2856   \n",
       "  4         0.009338           0.5904        0.119450           0.3884   \n",
       "  5         0.011524           0.5048        0.111587           0.5012   \n",
       "  6         0.014765           0.3992        0.071528           0.6096   \n",
       "  7         0.014550           0.3422        0.054417           0.7234   \n",
       "  8         0.015437           0.2332        0.055769           0.8308   \n",
       "  9         0.009011           0.0880        0.033038           0.9254   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007416             0.0808  ...          0.066174         0.8030   \n",
       "  2         0.007127             0.1640  ...          0.033730         0.7882   \n",
       "  3         0.008444             0.2854  ...          0.040488         0.7914   \n",
       "  4         0.009864             0.3872  ...          0.088401         0.8646   \n",
       "  5         0.010545             0.5016  ...          0.087240         0.9104   \n",
       "  6         0.013939             0.6100  ...          0.044162         0.9358   \n",
       "  7         0.013145             0.7268  ...          0.035520         0.9536   \n",
       "  8         0.015675             0.8346  ...          0.051047         0.9642   \n",
       "  9         0.009017             0.9258  ...          0.029038         0.9874   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.018547           0.7984        0.021594           0.8490   \n",
       "  2       0.015482           0.7888        0.017152           0.7776   \n",
       "  3       0.039570           0.7936        0.042647           0.7544   \n",
       "  4       0.024785           0.8708        0.029558           0.7506   \n",
       "  5       0.014082           0.9194        0.018379           0.7586   \n",
       "  6       0.005762           0.9486        0.009127           0.7432   \n",
       "  7       0.013050           0.9652        0.011367           0.8012   \n",
       "  8       0.015304           0.9748        0.015959           0.8344   \n",
       "  9       0.015837           0.9908        0.011862           0.9250   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.042000                   0.1            0              0  \n",
       "  2         0.033805                   0.2            0              0  \n",
       "  3         0.038714                   0.3            0              0  \n",
       "  4         0.079163                   0.4            0              0  \n",
       "  5         0.082367                   0.5            0              0  \n",
       "  6         0.092150                   0.6            0              0  \n",
       "  7         0.079216                   0.7            0              0  \n",
       "  8         0.091517                   0.8            0              0  \n",
       "  9         0.111803                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9150      0.003808           0.9160   \n",
       "  2                  0.2         0.8248      0.011032           0.8274   \n",
       "  3                  0.3         0.7132      0.014550           0.7106   \n",
       "  4                  0.4         0.6040      0.023516           0.6010   \n",
       "  5                  0.5         0.4938      0.026668           0.4908   \n",
       "  6                  0.6         0.3926      0.023618           0.3852   \n",
       "  7                  0.7         0.2868      0.021673           0.2852   \n",
       "  8                  0.8         0.1860      0.017734           0.1820   \n",
       "  9                  0.9         0.0838      0.008289           0.0830   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006442           0.9096        0.018929           0.0850   \n",
       "  2         0.014363           0.8106        0.018008           0.1752   \n",
       "  3         0.017387           0.7266        0.022412           0.2868   \n",
       "  4         0.025466           0.6206        0.031214           0.3960   \n",
       "  5         0.028726           0.5092        0.020105           0.5062   \n",
       "  6         0.026930           0.4324        0.021244           0.6074   \n",
       "  7         0.018267           0.2954        0.055442           0.7132   \n",
       "  8         0.019912           0.2066        0.051257           0.8140   \n",
       "  9         0.012207           0.0878        0.027087           0.9162   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.003808             0.0840  ...          0.014300         0.9040   \n",
       "  2         0.011032             0.1726  ...          0.014738         0.9112   \n",
       "  3         0.014550             0.2894  ...          0.031501         0.9418   \n",
       "  4         0.023516             0.3990  ...          0.029538         0.9608   \n",
       "  5         0.026668             0.5092  ...          0.018955         0.9682   \n",
       "  6         0.023618             0.6148  ...          0.023692         0.9718   \n",
       "  7         0.021673             0.7148  ...          0.058647         0.9782   \n",
       "  8         0.017734             0.8180  ...          0.048026         0.9788   \n",
       "  9         0.008289             0.9170  ...          0.027483         0.9706   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.006042           0.9048        0.010354           0.9012   \n",
       "  2       0.006380           0.9154        0.009607           0.8880   \n",
       "  3       0.006140           0.9472        0.005975           0.9150   \n",
       "  4       0.004712           0.9658        0.006834           0.9364   \n",
       "  5       0.003701           0.9722        0.006261           0.9472   \n",
       "  6       0.003564           0.9750        0.005148           0.9578   \n",
       "  7       0.003421           0.9816        0.006269           0.9618   \n",
       "  8       0.007727           0.9790        0.007714           0.9736   \n",
       "  9       0.019424           0.9698        0.019980           0.9706   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.019804                   0.1            0              0  \n",
       "  2         0.019736                   0.2            0              0  \n",
       "  3         0.014680                   0.3            0              0  \n",
       "  4         0.009659                   0.4            0              0  \n",
       "  5         0.017936                   0.5            0              0  \n",
       "  6         0.015401                   0.6            0              0  \n",
       "  7         0.013609                   0.7            0              0  \n",
       "  8         0.029737                   0.8            0              0  \n",
       "  9         0.048206                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9218      0.000837           0.9202   \n",
       "  2                  0.2         0.8376      0.002966           0.8370   \n",
       "  3                  0.3         0.7138      0.003834           0.7120   \n",
       "  4                  0.4         0.6130      0.006782           0.6104   \n",
       "  5                  0.5         0.5066      0.009503           0.5040   \n",
       "  6                  0.6         0.4010      0.012748           0.3978   \n",
       "  7                  0.7         0.2948      0.007662           0.2904   \n",
       "  8                  0.8         0.1842      0.006686           0.1828   \n",
       "  9                  0.9         0.0812      0.011735           0.0830   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.002588           0.9438        0.030360           0.0782   \n",
       "  2         0.003536           0.8484        0.012896           0.1624   \n",
       "  3         0.002121           0.7398        0.037050           0.2862   \n",
       "  4         0.007503           0.6524        0.042122           0.3870   \n",
       "  5         0.009975           0.5438        0.024712           0.4934   \n",
       "  6         0.014096           0.4522        0.042646           0.5990   \n",
       "  7         0.006107           0.3574        0.050831           0.7052   \n",
       "  8         0.006301           0.2038        0.019627           0.8158   \n",
       "  9         0.013638           0.0542        0.022197           0.9188   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.000837             0.0798  ...          0.033860         0.8754   \n",
       "  2         0.002966             0.1630  ...          0.008012         0.8318   \n",
       "  3         0.003834             0.2880  ...          0.046966         0.8980   \n",
       "  4         0.006782             0.3896  ...          0.042977         0.9382   \n",
       "  5         0.009503             0.4960  ...          0.042924         0.9622   \n",
       "  6         0.012748             0.6022  ...          0.042612         0.9778   \n",
       "  7         0.007662             0.7096  ...          0.058053         0.9878   \n",
       "  8         0.006686             0.8172  ...          0.024058         0.9900   \n",
       "  9         0.011735             0.9170  ...          0.020389         0.9924   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.009343           0.8706        0.012896           0.9310   \n",
       "  2       0.010035           0.8304        0.011261           0.8472   \n",
       "  3       0.009823           0.9000        0.009644           0.8678   \n",
       "  4       0.006535           0.9422        0.008106           0.8940   \n",
       "  5       0.009471           0.9662        0.009066           0.9140   \n",
       "  6       0.007497           0.9808        0.006907           0.9398   \n",
       "  7       0.005762           0.9900        0.005657           0.9600   \n",
       "  8       0.009055           0.9934        0.007403           0.9478   \n",
       "  9       0.008173           0.9952        0.006907           0.9214   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.035143                   0.1            0              0  \n",
       "  2         0.011122                   0.2            0              0  \n",
       "  3         0.014429                   0.3            0              0  \n",
       "  4         0.027313                   0.4            0              0  \n",
       "  5         0.041018                   0.5            0              0  \n",
       "  6         0.044172                   0.6            0              0  \n",
       "  7         0.016643                   0.7            0              0  \n",
       "  8         0.035124                   0.8            0              0  \n",
       "  9         0.114082                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9146      0.010114           0.9146   \n",
       "  2                  0.2         0.8132      0.011100           0.8122   \n",
       "  3                  0.3         0.7092      0.019473           0.7084   \n",
       "  4                  0.4         0.6012      0.021649           0.6000   \n",
       "  5                  0.5         0.4934      0.027218           0.4904   \n",
       "  6                  0.6         0.3944      0.026025           0.3918   \n",
       "  7                  0.7         0.2900      0.027295           0.2864   \n",
       "  8                  0.8         0.1846      0.027273           0.1826   \n",
       "  9                  0.9         0.0856      0.011610           0.0870   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009236           0.9200        0.038736           0.0854   \n",
       "  2         0.010895           0.8340        0.064935           0.1868   \n",
       "  3         0.016802           0.7214        0.081519           0.2908   \n",
       "  4         0.020408           0.6236        0.067803           0.3988   \n",
       "  5         0.025245           0.5500        0.064657           0.5066   \n",
       "  6         0.024284           0.4404        0.062736           0.6056   \n",
       "  7         0.026293           0.3578        0.077374           0.7100   \n",
       "  8         0.026369           0.2216        0.062312           0.8154   \n",
       "  9         0.011747           0.0562        0.030161           0.9144   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.010114             0.0854  ...          0.045371         0.8652   \n",
       "  2         0.011100             0.1878  ...          0.020864         0.7998   \n",
       "  3         0.019473             0.2916  ...          0.048987         0.8526   \n",
       "  4         0.021649             0.4000  ...          0.069576         0.9112   \n",
       "  5         0.027218             0.5096  ...          0.066637         0.9474   \n",
       "  6         0.026025             0.6082  ...          0.045481         0.9692   \n",
       "  7         0.027295             0.7136  ...          0.067013         0.9818   \n",
       "  8         0.027273             0.8174  ...          0.069418         0.9860   \n",
       "  9         0.011610             0.9130  ...          0.031236         0.9922   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.013936           0.8634        0.013240           0.8948   \n",
       "  2       0.010895           0.7984        0.011803           0.8268   \n",
       "  3       0.009864           0.8536        0.013740           0.8342   \n",
       "  4       0.006058           0.9146        0.008385           0.8520   \n",
       "  5       0.010065           0.9514        0.012934           0.8852   \n",
       "  6       0.006760           0.9726        0.004669           0.9166   \n",
       "  7       0.006723           0.9852        0.005070           0.9252   \n",
       "  8       0.005099           0.9870        0.005477           0.9798   \n",
       "  9       0.008672           0.9942        0.005404           0.9600   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.051891                   0.1            0              0  \n",
       "  2         0.066605                   0.2            0              0  \n",
       "  3         0.072727                   0.3            0              0  \n",
       "  4         0.073767                   0.4            0              0  \n",
       "  5         0.045285                   0.5            0              0  \n",
       "  6         0.058115                   0.6            0              0  \n",
       "  7         0.060611                   0.7            0              0  \n",
       "  8         0.027932                   0.8            0              0  \n",
       "  9         0.089443                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9226      0.007127           0.9248   \n",
       "  2                  0.2         0.8272      0.012872           0.8304   \n",
       "  3                  0.3         0.7292      0.008468           0.7318   \n",
       "  4                  0.4         0.6020      0.005050           0.5984   \n",
       "  5                  0.5         0.5044      0.004827           0.5020   \n",
       "  6                  0.6         0.3970      0.007517           0.3928   \n",
       "  7                  0.7         0.2882      0.008167           0.2850   \n",
       "  8                  0.8         0.1818      0.006611           0.1762   \n",
       "  9                  0.9         0.0812      0.005119           0.0804   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010281           0.9100        0.014248           0.0774   \n",
       "  2         0.013297           0.8100        0.018330           0.1728   \n",
       "  3         0.013461           0.7144        0.032746           0.2708   \n",
       "  4         0.009423           0.6202        0.029132           0.3980   \n",
       "  5         0.006205           0.5194        0.028483           0.4956   \n",
       "  6         0.006261           0.4198        0.037185           0.6030   \n",
       "  7         0.012430           0.3052        0.018213           0.7118   \n",
       "  8         0.008167           0.2132        0.028578           0.8182   \n",
       "  9         0.007987           0.0854        0.016041           0.9188   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007127             0.0752  ...          0.017427         0.8702   \n",
       "  2         0.012872             0.1696  ...          0.013953         0.8192   \n",
       "  3         0.008468             0.2682  ...          0.028657         0.8558   \n",
       "  4         0.005050             0.4016  ...          0.032654         0.8890   \n",
       "  5         0.004827             0.4980  ...          0.037246         0.9110   \n",
       "  6         0.007517             0.6072  ...          0.043397         0.9240   \n",
       "  7         0.008167             0.7150  ...          0.016162         0.9400   \n",
       "  8         0.006611             0.8238  ...          0.026195         0.9412   \n",
       "  9         0.005119             0.9196  ...          0.015595         0.9490   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.009284           0.8688        0.014412           0.8768   \n",
       "  2       0.011735           0.8222        0.012716           0.8026   \n",
       "  3       0.012696           0.8628        0.015515           0.8178   \n",
       "  4       0.009110           0.8988        0.012795           0.8408   \n",
       "  5       0.011068           0.9240        0.014053           0.8486   \n",
       "  6       0.007483           0.9376        0.011803           0.8594   \n",
       "  7       0.012629           0.9534        0.010968           0.8772   \n",
       "  8       0.014202           0.9550        0.010000           0.8820   \n",
       "  9       0.023590           0.9614        0.021961           0.8868   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.018254                   0.1            0              0  \n",
       "  2         0.020623                   0.2            0              0  \n",
       "  3         0.016843                   0.3            0              0  \n",
       "  4         0.016177                   0.4            0              0  \n",
       "  5         0.011546                   0.5            0              0  \n",
       "  6         0.022623                   0.6            0              0  \n",
       "  7         0.027041                   0.7            0              0  \n",
       "  8         0.044772                   0.8            0              0  \n",
       "  9         0.044740                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9246      0.006269           0.9248   \n",
       "  2                  0.2         0.8174      0.010431           0.8166   \n",
       "  3                  0.3         0.7122      0.008927           0.7118   \n",
       "  4                  0.4         0.6020      0.011292           0.6012   \n",
       "  5                  0.5         0.4932      0.005404           0.4922   \n",
       "  6                  0.6         0.3840      0.011853           0.3846   \n",
       "  7                  0.7         0.2760      0.006671           0.2762   \n",
       "  8                  0.8         0.1708      0.008044           0.1706   \n",
       "  9                  0.9         0.0802      0.005718           0.0796   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006380           0.9252        0.025782           0.0754   \n",
       "  2         0.009154           0.8340        0.052498           0.1826   \n",
       "  3         0.009783           0.7222        0.030882           0.2878   \n",
       "  4         0.013773           0.6236        0.088661           0.3980   \n",
       "  5         0.006834           0.5084        0.068562           0.5068   \n",
       "  6         0.010090           0.3696        0.081883           0.6160   \n",
       "  7         0.006181           0.2744        0.054294           0.7240   \n",
       "  8         0.007470           0.1762        0.073261           0.8292   \n",
       "  9         0.005683           0.0850        0.041641           0.9198   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.006269             0.0752  ...          0.052529         0.8664   \n",
       "  2         0.010431             0.1834  ...          0.017000         0.8468   \n",
       "  3         0.008927             0.2882  ...          0.057903         0.9828   \n",
       "  4         0.011292             0.3988  ...          0.115396         0.9906   \n",
       "  5         0.005404             0.5078  ...          0.070131         0.9918   \n",
       "  6         0.011853             0.6154  ...          0.080692         0.9932   \n",
       "  7         0.006671             0.7238  ...          0.040587         0.9950   \n",
       "  8         0.008044             0.8294  ...          0.075038         0.9972   \n",
       "  9         0.005718             0.9204  ...          0.040941         0.9970   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.010831           0.8636        0.012239           0.9128   \n",
       "  2       0.033626           0.8472        0.036121           0.8416   \n",
       "  3       0.005805           0.9892        0.005020           0.8468   \n",
       "  4       0.002702           0.9962        0.001643           0.8706   \n",
       "  5       0.001483           0.9970        0.001225           0.8766   \n",
       "  6       0.001643           0.9986        0.001342           0.8608   \n",
       "  7       0.002121           0.9996        0.000894           0.8840   \n",
       "  8       0.002950           1.0000        0.000000           0.9278   \n",
       "  9       0.004123           1.0000        0.000000           0.9084   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.027105                   0.1            0              0  \n",
       "  2         0.043975                   0.2            0              0  \n",
       "  3         0.037164                   0.3            0              0  \n",
       "  4         0.034832                   0.4            0              0  \n",
       "  5         0.033201                   0.5            0              0  \n",
       "  6         0.032942                   0.6            0              0  \n",
       "  7         0.069166                   0.7            0              0  \n",
       "  8         0.091166                   0.8            0              0  \n",
       "  9         0.145397                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9208      0.006496           0.9218   \n",
       "  2                  0.2         0.8358      0.008319           0.8360   \n",
       "  3                  0.3         0.7168      0.013046           0.7146   \n",
       "  4                  0.4         0.6144      0.010359           0.6102   \n",
       "  5                  0.5         0.5090      0.015732           0.5030   \n",
       "  6                  0.6         0.3994      0.017126           0.3912   \n",
       "  7                  0.7         0.2878      0.014202           0.2814   \n",
       "  8                  0.8         0.1746      0.014467           0.1764   \n",
       "  9                  0.9         0.0814      0.006693           0.0798   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007596           0.9110        0.012490           0.0792   \n",
       "  2         0.010173           0.8306        0.017126           0.1642   \n",
       "  3         0.015566           0.7354        0.022678           0.2832   \n",
       "  4         0.011649           0.6460        0.022349           0.3856   \n",
       "  5         0.018055           0.5528        0.026243           0.4910   \n",
       "  6         0.019331           0.4558        0.033056           0.6006   \n",
       "  7         0.018298           0.3300        0.029783           0.7122   \n",
       "  8         0.016667           0.1596        0.006656           0.8254   \n",
       "  9         0.006611           0.0902        0.027133           0.9186   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.006496             0.0782  ...          0.025813         0.8994   \n",
       "  2         0.008319             0.1640  ...          0.019616         0.8884   \n",
       "  3         0.013046             0.2854  ...          0.029064         0.9296   \n",
       "  4         0.010359             0.3898  ...          0.028919         0.9494   \n",
       "  5         0.015732             0.4970  ...          0.026678         0.9620   \n",
       "  6         0.017126             0.6088  ...          0.029853         0.9688   \n",
       "  7         0.014202             0.7186  ...          0.025466         0.9726   \n",
       "  8         0.014467             0.8236  ...          0.008276         0.9772   \n",
       "  9         0.006693             0.9202  ...          0.026848         0.9810   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.009889           0.8992        0.012050           0.8996   \n",
       "  2       0.005857           0.8924        0.006914           0.8622   \n",
       "  3       0.003578           0.9354        0.003847           0.8922   \n",
       "  4       0.005550           0.9558        0.006686           0.9096   \n",
       "  5       0.006964           0.9684        0.006465           0.9232   \n",
       "  6       0.008228           0.9758        0.008228           0.9276   \n",
       "  7       0.004879           0.9810        0.007106           0.9212   \n",
       "  8       0.008075           0.9902        0.009011           0.8872   \n",
       "  9       0.009772           0.9872        0.012194           0.9404   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.012219                   0.1            0              0  \n",
       "  2         0.015865                   0.2            0              0  \n",
       "  3         0.013480                   0.3            0              0  \n",
       "  4         0.007369                   0.4            0              0  \n",
       "  5         0.015123                   0.5            0              0  \n",
       "  6         0.019932                   0.6            0              0  \n",
       "  7         0.020511                   0.7            0              0  \n",
       "  8         0.022742                   0.8            0              0  \n",
       "  9         0.015931                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9244      0.007987           0.9252   \n",
       "  2                  0.2         0.8168      0.007950           0.8160   \n",
       "  3                  0.3         0.7132      0.005718           0.7120   \n",
       "  4                  0.4         0.6040      0.020285           0.6028   \n",
       "  5                  0.5         0.4930      0.019352           0.4912   \n",
       "  6                  0.6         0.3832      0.015515           0.3798   \n",
       "  7                  0.7         0.2742      0.010257           0.2720   \n",
       "  8                  0.8         0.1758      0.009311           0.1754   \n",
       "  9                  0.9         0.0792      0.003194           0.0784   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.009311           0.9070        0.022616           0.0756   \n",
       "  2         0.009644           0.8330        0.034227           0.1832   \n",
       "  3         0.006403           0.7376        0.041884           0.2868   \n",
       "  4         0.019097           0.6232        0.058174           0.3960   \n",
       "  5         0.016932           0.5274        0.078847           0.5070   \n",
       "  6         0.013274           0.4466        0.072728           0.6168   \n",
       "  7         0.008860           0.3152        0.058367           0.7258   \n",
       "  8         0.008849           0.1836        0.028130           0.8242   \n",
       "  9         0.004775           0.0908        0.029643           0.9208   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007987             0.0748  ...          0.045252         0.8164   \n",
       "  2         0.007950             0.1840  ...          0.040698         0.7786   \n",
       "  3         0.005718             0.2880  ...          0.032813         0.8344   \n",
       "  4         0.020285             0.3972  ...          0.065945         0.9552   \n",
       "  5         0.019352             0.5088  ...          0.084875         0.9734   \n",
       "  6         0.015515             0.6202  ...          0.081665         0.9756   \n",
       "  7         0.010257             0.7280  ...          0.064712         0.9784   \n",
       "  8         0.009311             0.8246  ...          0.012369         0.9828   \n",
       "  9         0.003194             0.9216  ...          0.027586         0.9864   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.024795           0.8090        0.030191           0.8818   \n",
       "  2       0.018636           0.7760        0.021691           0.8198   \n",
       "  3       0.028290           0.8362        0.030153           0.7960   \n",
       "  4       0.014481           0.9650        0.015379           0.8106   \n",
       "  5       0.003209           0.9850        0.003000           0.8056   \n",
       "  6       0.004037           0.9874        0.003578           0.8196   \n",
       "  7       0.003435           0.9920        0.003742           0.7984   \n",
       "  8       0.006834           0.9956        0.004722           0.7990   \n",
       "  9       0.009343           1.0000        0.000000           0.8040   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.026790                   0.1            0              0  \n",
       "  2         0.032683                   0.2            0              0  \n",
       "  3         0.022771                   0.3            0              0  \n",
       "  4         0.017053                   0.4            0              0  \n",
       "  5         0.032562                   0.5            0              0  \n",
       "  6         0.027898                   0.6            0              0  \n",
       "  7         0.039310                   0.7            0              0  \n",
       "  8         0.087561                   0.8            0              0  \n",
       "  9         0.142685                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9200      0.008000           0.9204   \n",
       "  2                  0.2         0.8136      0.013353           0.8142   \n",
       "  3                  0.3         0.7152      0.013161           0.7146   \n",
       "  4                  0.4         0.5980      0.016310           0.5974   \n",
       "  5                  0.5         0.4918      0.020290           0.4902   \n",
       "  6                  0.6         0.3850      0.016000           0.3836   \n",
       "  7                  0.7         0.2830      0.013491           0.2826   \n",
       "  8                  0.8         0.1826      0.009017           0.1812   \n",
       "  9                  0.9         0.0802      0.008228           0.0802   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007570           0.9020        0.101777           0.0800   \n",
       "  2         0.012458           0.7992        0.099258           0.1864   \n",
       "  3         0.012973           0.7404        0.097879           0.2848   \n",
       "  4         0.017459           0.6272        0.108916           0.4020   \n",
       "  5         0.021568           0.5436        0.131312           0.5082   \n",
       "  6         0.017141           0.4360        0.079388           0.6150   \n",
       "  7         0.014741           0.3138        0.068736           0.7170   \n",
       "  8         0.009497           0.2408        0.055711           0.8174   \n",
       "  9         0.008927           0.0836        0.045125           0.9198   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.008000             0.0796  ...          0.051868         0.8306   \n",
       "  2         0.013353             0.1858  ...          0.037326         0.7796   \n",
       "  3         0.013161             0.2854  ...          0.036273         0.8014   \n",
       "  4         0.016310             0.4026  ...          0.060756         0.8860   \n",
       "  5         0.020290             0.5098  ...          0.105737         0.9374   \n",
       "  6         0.016000             0.6164  ...          0.100251         0.9696   \n",
       "  7         0.013491             0.7174  ...          0.081534         0.9828   \n",
       "  8         0.009017             0.8188  ...          0.077895         0.9872   \n",
       "  9         0.008228             0.9198  ...          0.049892         0.9954   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.014656           0.8284        0.020489           0.8704   \n",
       "  2       0.017981           0.7790        0.021389           0.7892   \n",
       "  3       0.043821           0.8026        0.047432           0.7734   \n",
       "  4       0.035511           0.8890        0.039793           0.7988   \n",
       "  5       0.017097           0.9416        0.021338           0.8142   \n",
       "  6       0.013031           0.9750        0.015890           0.8330   \n",
       "  7       0.005215           0.9888        0.007596           0.8268   \n",
       "  8       0.005070           0.9918        0.002950           0.8840   \n",
       "  9       0.004219           1.0000        0.000000           0.8600   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.124458                   0.1            0              0  \n",
       "  2         0.098685                   0.2            0              0  \n",
       "  3         0.085248                   0.3            0              0  \n",
       "  4         0.106938                   0.4            0              0  \n",
       "  5         0.116738                   0.5            0              0  \n",
       "  6         0.130052                   0.6            0              0  \n",
       "  7         0.143617                   0.7            0              0  \n",
       "  8         0.073447                   0.8            0              0  \n",
       "  9         0.142107                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns]],\n",
       " 'pred_score_trainupdate': [    significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8320      0.007036           0.8314   \n",
       "  2                  0.2         0.7468      0.008955           0.7506   \n",
       "  3                  0.3         0.6484      0.005983           0.6532   \n",
       "  4                  0.4         0.5268      0.010569           0.5296   \n",
       "  5                  0.5         0.4206      0.005857           0.4282   \n",
       "  6                  0.6         0.3166      0.016637           0.3248   \n",
       "  7                  0.7         0.2158      0.013590           0.2270   \n",
       "  8                  0.8         0.1248      0.010592           0.1328   \n",
       "  9                  0.9         0.0646      0.009711           0.0692   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.008264           0.8390        0.030125           0.1680   \n",
       "  2         0.008050           0.6888        0.049585           0.2532   \n",
       "  3         0.005586           0.5668        0.031444           0.3516   \n",
       "  4         0.012012           0.4888        0.025044           0.4732   \n",
       "  5         0.006058           0.3056        0.027501           0.5794   \n",
       "  6         0.016146           0.1888        0.049585           0.6834   \n",
       "  7         0.010247           0.0390        0.072574           0.7842   \n",
       "  8         0.011234           0.0000        0.000000           0.8752   \n",
       "  9         0.010545           0.0000        0.000000           0.9354   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007036             0.1686  ...          0.065133         0.7128   \n",
       "  2         0.008955             0.2494  ...          0.041161         0.7238   \n",
       "  3         0.005983             0.3468  ...          0.053210         0.7640   \n",
       "  4         0.010569             0.4704  ...          0.055626         0.8258   \n",
       "  5         0.005857             0.5718  ...          0.045675         0.9000   \n",
       "  6         0.016637             0.6752  ...          0.056945         0.9470   \n",
       "  7         0.013590             0.7730  ...          0.057652         0.9608   \n",
       "  8         0.010592             0.8672  ...          0.014789         0.9636   \n",
       "  9         0.009711             0.9308  ...          0.023069         0.9454   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.029508           0.7086        0.032532           0.7698   \n",
       "  2       0.017810           0.7272        0.016664           0.6728   \n",
       "  3       0.026486           0.7710        0.025544           0.6552   \n",
       "  4       0.023037           0.8366        0.022985           0.6790   \n",
       "  5       0.019326           0.9172        0.019123           0.6404   \n",
       "  6       0.009407           0.9682        0.007918           0.6046   \n",
       "  7       0.009859           0.9846        0.011739           0.2000   \n",
       "  8       0.008792           0.9950        0.006856           0.0000   \n",
       "  9       0.033336           0.9892        0.014805           0.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.022709                   0.1            0              0  \n",
       "  2         0.048659                   0.2            0              0  \n",
       "  3         0.042234                   0.3            0              0  \n",
       "  4         0.039198                   0.4            0              0  \n",
       "  5         0.025432                   0.5            0              0  \n",
       "  6         0.088782                   0.6            0              0  \n",
       "  7         0.325960                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8944      0.006841           0.8894   \n",
       "  2                  0.2         0.7792      0.005020           0.7724   \n",
       "  3                  0.3         0.6610      0.011045           0.6552   \n",
       "  4                  0.4         0.5860      0.010000           0.5864   \n",
       "  5                  0.5         0.4854      0.012442           0.4902   \n",
       "  6                  0.6         0.3638      0.017796           0.3752   \n",
       "  7                  0.7         0.2318      0.022129           0.2458   \n",
       "  8                  0.8         0.1256      0.014775           0.1302   \n",
       "  9                  0.9         0.0390      0.003742           0.0372   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.010407           0.9388        0.024904           0.1056   \n",
       "  2         0.007470           0.8366        0.020501           0.2208   \n",
       "  3         0.011777           0.7142        0.032415           0.3390   \n",
       "  4         0.011610           0.5794        0.033946           0.4140   \n",
       "  5         0.015287           0.4410        0.017889           0.5146   \n",
       "  6         0.019980           0.2612        0.033959           0.6362   \n",
       "  7         0.023658           0.1060        0.016733           0.7682   \n",
       "  8         0.015834           0.0860        0.008944           0.8744   \n",
       "  9         0.003834           0.0530        0.010954           0.9610   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.006841             0.1106  ...          0.024906         0.6530   \n",
       "  2         0.005020             0.2276  ...          0.034274         0.6852   \n",
       "  3         0.011045             0.3448  ...          0.017094         0.6558   \n",
       "  4         0.010000             0.4136  ...          0.030475         0.7370   \n",
       "  5         0.012442             0.5098  ...          0.022320         0.8346   \n",
       "  6         0.017796             0.6248  ...          0.050623         0.8978   \n",
       "  7         0.022129             0.7542  ...          0.045840         0.9436   \n",
       "  8         0.014775             0.8698  ...          0.023287         0.9568   \n",
       "  9         0.003742             0.9628  ...          0.017094         0.9914   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.041617           0.6036        0.061419           0.8858   \n",
       "  2       0.009935           0.6718        0.012755           0.7918   \n",
       "  3       0.013809           0.6492        0.013217           0.7140   \n",
       "  4       0.011597           0.7420        0.012000           0.6962   \n",
       "  5       0.010359           0.8508        0.011054           0.7016   \n",
       "  6       0.018913           0.9230        0.010488           0.6718   \n",
       "  7       0.016994           0.9730        0.006042           0.5918   \n",
       "  8       0.016769           0.9894        0.015027           0.6660   \n",
       "  9       0.019230           1.0000        0.000000           0.9500   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.041191                   0.1            0              0  \n",
       "  2         0.023721                   0.2            0              0  \n",
       "  3         0.035518                   0.3            0              0  \n",
       "  4         0.032011                   0.4            0              0  \n",
       "  5         0.029704                   0.5            0              0  \n",
       "  6         0.096347                   0.6            0              0  \n",
       "  7         0.085538                   0.7            0              0  \n",
       "  8         0.084652                   0.8            0              0  \n",
       "  9         0.111803                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.9052      0.005541           0.9042   \n",
       "  2                  0.2         0.8248      0.017441           0.8230   \n",
       "  3                  0.3         0.7124      0.023277           0.7104   \n",
       "  4                  0.4         0.5916      0.016532           0.5952   \n",
       "  5                  0.5         0.4712      0.020462           0.4808   \n",
       "  6                  0.6         0.3518      0.020474           0.3590   \n",
       "  7                  0.7         0.2424      0.020465           0.2474   \n",
       "  8                  0.8         0.1482      0.027105           0.1508   \n",
       "  9                  0.9         0.0628      0.013461           0.0644   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.006535           0.9636        0.049843           0.0948   \n",
       "  2         0.018235           0.9090        0.000000           0.1752   \n",
       "  3         0.024048           0.8180        0.111452           0.2876   \n",
       "  4         0.016932           0.4002        0.151884           0.4084   \n",
       "  5         0.020909           0.0000        0.000000           0.5288   \n",
       "  6         0.020821           0.0000        0.000000           0.6482   \n",
       "  7         0.020465           0.0000        0.000000           0.7576   \n",
       "  8         0.027545           0.0000        0.000000           0.8518   \n",
       "  9         0.013939           0.0000        0.000000           0.9372   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.005541             0.0958  ...          0.128340         0.6082   \n",
       "  2         0.017441             0.1770  ...          0.099686         0.7036   \n",
       "  3         0.023277             0.2896  ...          0.076136         0.7212   \n",
       "  4         0.016532             0.4048  ...          0.143410         0.9294   \n",
       "  5         0.020462             0.5192  ...          0.040696         0.9902   \n",
       "  6         0.020474             0.6410  ...          0.000000         0.9940   \n",
       "  7         0.020465             0.7526  ...          0.040696         0.9942   \n",
       "  8         0.027105             0.8492  ...          0.049843         0.9922   \n",
       "  9         0.013461             0.9356  ...          0.000000         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.052016           0.5896        0.058325           0.9428   \n",
       "  2       0.030055           0.6982        0.031027           0.8848   \n",
       "  3       0.044684           0.7188        0.045991           0.8370   \n",
       "  4       0.045031           0.9328        0.046826           0.7258   \n",
       "  5       0.002168           0.9946        0.001949           0.0000   \n",
       "  6       0.002236           0.9990        0.002236           0.0000   \n",
       "  7       0.003271           1.0000        0.000000           0.0000   \n",
       "  8       0.007430           1.0000        0.000000           0.0000   \n",
       "  9       0.000000           1.0000        0.000000           0.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.078324                   0.1            0              0  \n",
       "  2         0.016254                   0.2            0              0  \n",
       "  3         0.054507                   0.3            0              0  \n",
       "  4         0.136131                   0.4            0              0  \n",
       "  5         0.000000                   0.5            0              0  \n",
       "  6         0.000000                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8560      0.011336           0.8548   \n",
       "  2                  0.2         0.7406      0.014188           0.7376   \n",
       "  3                  0.3         0.6766      0.011082           0.6764   \n",
       "  4                  0.4         0.5730      0.010770           0.5726   \n",
       "  5                  0.5         0.4706      0.019794           0.4706   \n",
       "  6                  0.6         0.3578      0.010521           0.3592   \n",
       "  7                  0.7         0.2366      0.016288           0.2378   \n",
       "  8                  0.8         0.1536      0.010714           0.1556   \n",
       "  9                  0.9         0.0820      0.007969           0.0830   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.012174           0.8948        0.037124           0.1440   \n",
       "  2         0.015405           0.8210        0.060079           0.2594   \n",
       "  3         0.014346           0.6842        0.098352           0.3234   \n",
       "  4         0.011127           0.5894        0.094418           0.4270   \n",
       "  5         0.021314           0.4736        0.052500           0.5294   \n",
       "  6         0.010710           0.3156        0.052500           0.6422   \n",
       "  7         0.016724           0.2110        0.000000           0.7634   \n",
       "  8         0.012095           0.0948        0.043866           0.8464   \n",
       "  9         0.007778           0.0528        0.037124           0.9180   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.011336             0.1452  ...          0.068605         0.6684   \n",
       "  2         0.014188             0.2624  ...          0.043985         0.6924   \n",
       "  3         0.011082             0.3236  ...          0.068605         0.7204   \n",
       "  4         0.010770             0.4274  ...          0.087849         0.7844   \n",
       "  5         0.019794             0.5294  ...          0.060123         0.8456   \n",
       "  6         0.010521             0.6408  ...          0.037477         0.8908   \n",
       "  7         0.016288             0.7622  ...          0.029029         0.9288   \n",
       "  8         0.010714             0.8444  ...          0.044343         0.9610   \n",
       "  9         0.007969             0.9170  ...          0.037124         0.9754   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.015274           0.6598        0.017570           0.8372   \n",
       "  2       0.021501           0.6886        0.023082           0.7968   \n",
       "  3       0.037206           0.7200        0.039268           0.7278   \n",
       "  4       0.035487           0.7848        0.039137           0.7772   \n",
       "  5       0.029788           0.8486        0.033261           0.7770   \n",
       "  6       0.019867           0.8960        0.023484           0.7484   \n",
       "  7       0.017484           0.9372        0.020572           0.7202   \n",
       "  8       0.008124           0.9712        0.008438           0.6168   \n",
       "  9       0.007701           0.9960        0.008944           0.4334   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.051441                   0.1            0              0  \n",
       "  2         0.071451                   0.2            0              0  \n",
       "  3         0.060131                   0.3            0              0  \n",
       "  4         0.073155                   0.4            0              0  \n",
       "  5         0.064277                   0.5            0              0  \n",
       "  6         0.091265                   0.6            0              0  \n",
       "  7         0.072847                   0.7            0              0  \n",
       "  8         0.111878                   0.8            0              0  \n",
       "  9         0.252839                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8746      0.006229           0.8666   \n",
       "  2                  0.2         0.7462      0.004550           0.7450   \n",
       "  3                  0.3         0.6760      0.002828           0.6914   \n",
       "  4                  0.4         0.5844      0.009476           0.6032   \n",
       "  5                  0.5         0.4962      0.003899           0.5186   \n",
       "  6                  0.6         0.3998      0.004817           0.4208   \n",
       "  7                  0.7         0.2926      0.015060           0.3066   \n",
       "  8                  0.8         0.1938      0.005762           0.2018   \n",
       "  9                  0.9         0.0994      0.004506           0.1036   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007301           0.9428        0.022972           0.1254   \n",
       "  2         0.004472           0.7570        0.048208           0.2538   \n",
       "  3         0.005595           0.5536        0.024926           0.3240   \n",
       "  4         0.007981           0.4322        0.034157           0.4156   \n",
       "  5         0.005505           0.3144        0.039004           0.5038   \n",
       "  6         0.006058           0.2284        0.008050           0.6002   \n",
       "  7         0.016134           0.1820        0.023011           0.7074   \n",
       "  8         0.004324           0.1286        0.039023           0.8062   \n",
       "  9         0.006580           0.0642        0.020042           0.9006   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.006229             0.1334  ...          0.058637         0.8554   \n",
       "  2         0.004550             0.2550  ...          0.062400         0.8660   \n",
       "  3         0.002828             0.3086  ...          0.028146         0.9196   \n",
       "  4         0.009476             0.3968  ...          0.031697         0.9504   \n",
       "  5         0.003899             0.4814  ...          0.033276         0.9588   \n",
       "  6         0.004817             0.5792  ...          0.008050         0.9632   \n",
       "  7         0.015060             0.6934  ...          0.023011         0.9606   \n",
       "  8         0.005762             0.7982  ...          0.039023         0.9506   \n",
       "  9         0.004506             0.8964  ...          0.020042         0.9846   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.005459           0.8460        0.007681           0.9336   \n",
       "  2       0.005745           0.8600        0.008155           0.9188   \n",
       "  3       0.007765           0.9176        0.010714           0.9400   \n",
       "  4       0.007127           0.9484        0.006656           0.9760   \n",
       "  5       0.004494           0.9572        0.004324           0.9764   \n",
       "  6       0.005933           0.9610        0.006164           1.0000   \n",
       "  7       0.009154           0.9582        0.009524           1.0000   \n",
       "  8       0.016637           0.9470        0.017692           1.0000   \n",
       "  9       0.015962           0.9838        0.016529           1.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.024368                   0.1            0              0  \n",
       "  2         0.024570                   0.2            0              0  \n",
       "  3         0.029095                   0.3            0              0  \n",
       "  4         0.034993                   0.4            0              0  \n",
       "  5         0.032385                   0.5            0              0  \n",
       "  6         0.000000                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8458      0.003834           0.8460   \n",
       "  2                  0.2         0.7170      0.006782           0.7234   \n",
       "  3                  0.3         0.6346      0.012341           0.6466   \n",
       "  4                  0.4         0.5422      0.009550           0.5580   \n",
       "  5                  0.5         0.4450      0.007714           0.4640   \n",
       "  6                  0.6         0.3464      0.012700           0.3638   \n",
       "  7                  0.7         0.2392      0.003421           0.2534   \n",
       "  8                  0.8         0.1378      0.008843           0.1450   \n",
       "  9                  0.9         0.0570      0.007382           0.0598   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.005099            0.845        0.048088           0.1542   \n",
       "  2         0.005177            0.630        0.051235           0.2830   \n",
       "  3         0.012219            0.470        0.041079           0.3654   \n",
       "  4         0.009925            0.325        0.025000           0.4578   \n",
       "  5         0.009539            0.195        0.037081           0.5550   \n",
       "  6         0.012755            0.115        0.013693           0.6536   \n",
       "  7         0.003847            0.045        0.011180           0.7608   \n",
       "  8         0.009055            0.040        0.013693           0.8622   \n",
       "  9         0.008556            0.015        0.013693           0.9430   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.003834             0.1540  ...          0.039528         0.7610   \n",
       "  2         0.006782             0.2766  ...          0.041833         0.7152   \n",
       "  3         0.012341             0.3534  ...          0.048088         0.8010   \n",
       "  4         0.009550             0.4420  ...          0.022361         0.8698   \n",
       "  5         0.007714             0.5360  ...          0.057009         0.9280   \n",
       "  6         0.012700             0.6362  ...          0.020917         0.9520   \n",
       "  7         0.003421             0.7466  ...          0.041833         0.9764   \n",
       "  8         0.008843             0.8550  ...          0.017678         0.9902   \n",
       "  9         0.007382             0.9402  ...          0.013693         0.9926   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.010075           0.7616        0.015598           0.7544   \n",
       "  2       0.010085           0.7208        0.011389           0.6346   \n",
       "  3       0.012865           0.8134        0.014588           0.6224   \n",
       "  4       0.012438           0.8868        0.012795           0.6018   \n",
       "  5       0.005339           0.9446        0.004561           0.5906   \n",
       "  6       0.005385           0.9660        0.003742           0.5958   \n",
       "  7       0.014206           0.9888        0.010616           0.5666   \n",
       "  8       0.015336           0.9952        0.010733           0.8334   \n",
       "  9       0.016547           0.9924        0.016994           0.6000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.070081                   0.1            0              0  \n",
       "  2         0.038940                   0.2            0              0  \n",
       "  3         0.032122                   0.3            0              0  \n",
       "  4         0.039739                   0.4            0              0  \n",
       "  5         0.053116                   0.5            0              0  \n",
       "  6         0.099165                   0.6            0              0  \n",
       "  7         0.252839                   0.7            0              0  \n",
       "  8         0.235643                   0.8            0              0  \n",
       "  9         0.547723                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8786      0.006229           0.8802   \n",
       "  2                  0.2         0.7614      0.013957           0.7660   \n",
       "  3                  0.3         0.6722      0.013900           0.6812   \n",
       "  4                  0.4         0.5740      0.009274           0.5874   \n",
       "  5                  0.5         0.4628      0.018033           0.4790   \n",
       "  6                  0.6         0.3556      0.015485           0.3702   \n",
       "  7                  0.7         0.2706      0.014311           0.2874   \n",
       "  8                  0.8         0.1758      0.010918           0.1868   \n",
       "  9                  0.9         0.0852      0.005215           0.0902   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004919           0.8610        0.034293           0.1214   \n",
       "  2         0.012349           0.7000        0.036049           0.2386   \n",
       "  3         0.015707           0.5610        0.056846           0.3278   \n",
       "  4         0.006693           0.3998        0.057556           0.4260   \n",
       "  5         0.018344           0.2556        0.030672           0.5372   \n",
       "  6         0.016331           0.1666        0.027501           0.6444   \n",
       "  7         0.014622           0.0504        0.012522           0.7294   \n",
       "  8         0.010616           0.0392        0.025044           0.8242   \n",
       "  9         0.005495           0.0168        0.015336           0.9148   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.006229             0.1198  ...          0.069683         0.8136   \n",
       "  2         0.013957             0.2340  ...          0.046465         0.7474   \n",
       "  3         0.013900             0.3188  ...          0.072517         0.7926   \n",
       "  4         0.009274             0.4126  ...          0.065240         0.8628   \n",
       "  5         0.018033             0.5210  ...          0.052117         0.9146   \n",
       "  6         0.015485             0.6298  ...          0.051983         0.9586   \n",
       "  7         0.014311             0.7126  ...          0.031575         0.9802   \n",
       "  8         0.010918             0.8132  ...          0.033887         0.9866   \n",
       "  9         0.005215             0.9098  ...          0.023426         0.9958   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.009099           0.8162        0.007396           0.7786   \n",
       "  2       0.011261           0.7520        0.010025           0.6882   \n",
       "  3       0.021698           0.8030        0.024423           0.6602   \n",
       "  4       0.013535           0.8748        0.013828           0.6860   \n",
       "  5       0.010644           0.9258        0.013103           0.7120   \n",
       "  6       0.014328           0.9732        0.009365           0.6798   \n",
       "  7       0.011735           0.9926        0.005683           0.5466   \n",
       "  8       0.009476           0.9930        0.006403           0.5668   \n",
       "  9       0.009391           1.0000        0.000000           0.5000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.040494                   0.1            0              0  \n",
       "  2         0.030261                   0.2            0              0  \n",
       "  3         0.034259                   0.3            0              0  \n",
       "  4         0.061356                   0.4            0              0  \n",
       "  5         0.063439                   0.5            0              0  \n",
       "  6         0.131094                   0.6            0              0  \n",
       "  7         0.263169                   0.7            0              0  \n",
       "  8         0.365194                   0.8            0              0  \n",
       "  9         0.500000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8632      0.005404           0.8440   \n",
       "  2                  0.2         0.7118      0.010849           0.6868   \n",
       "  3                  0.3         0.5920      0.013802           0.5716   \n",
       "  4                  0.4         0.4986      0.014433           0.4998   \n",
       "  5                  0.5         0.4238      0.011389           0.4348   \n",
       "  6                  0.6         0.3490      0.010173           0.3616   \n",
       "  7                  0.7         0.2306      0.006841           0.2446   \n",
       "  8                  0.8         0.1272      0.005357           0.1390   \n",
       "  9                  0.9         0.0544      0.006804           0.0540   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.004950           0.9574        0.016622           0.1368   \n",
       "  2         0.012834           0.8336        0.014843           0.2882   \n",
       "  3         0.017544           0.6918        0.041698           0.4080   \n",
       "  4         0.015928           0.4922        0.033327           0.5014   \n",
       "  5         0.012814           0.3710        0.013472           0.5762   \n",
       "  6         0.010854           0.2876        0.009839           0.6510   \n",
       "  7         0.005727           0.1620        0.024648           0.7694   \n",
       "  8         0.008746           0.0696        0.025589           0.8728   \n",
       "  9         0.010173           0.0562        0.024160           0.9456   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.005404             0.1560  ...          0.053163         0.7654   \n",
       "  2         0.010849             0.3132  ...          0.026892         0.6956   \n",
       "  3         0.013802             0.4284  ...          0.054843         0.7370   \n",
       "  4         0.014433             0.5002  ...          0.030517         0.7942   \n",
       "  5         0.011389             0.5652  ...          0.021603         0.8456   \n",
       "  6         0.010173             0.6384  ...          0.009685         0.8906   \n",
       "  7         0.006841             0.7554  ...          0.025846         0.9094   \n",
       "  8         0.005357             0.8610  ...          0.028128         0.9020   \n",
       "  9         0.006804             0.9460  ...          0.024160         0.8698   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.006229           0.7330        0.008456           0.9276   \n",
       "  2       0.009555           0.6688        0.012215           0.8252   \n",
       "  3       0.005701           0.7134        0.007503           0.8514   \n",
       "  4       0.010232           0.7840        0.013342           0.8522   \n",
       "  5       0.011845           0.8372        0.012518           0.8978   \n",
       "  6       0.007635           0.8858        0.007823           0.9212   \n",
       "  7       0.010310           0.9060        0.011113           0.9360   \n",
       "  8       0.017875           0.8980        0.022672           0.9492   \n",
       "  9       0.021183           0.8450        0.026467           1.0000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.023996                   0.1            0              0  \n",
       "  2         0.019537                   0.2            0              0  \n",
       "  3         0.015726                   0.3            0              0  \n",
       "  4         0.033833                   0.4            0              0  \n",
       "  5         0.031956                   0.5            0              0  \n",
       "  6         0.028543                   0.6            0              0  \n",
       "  7         0.051020                   0.7            0              0  \n",
       "  8         0.070475                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8946      0.007232           0.8946   \n",
       "  2                  0.2         0.8116      0.007893           0.8178   \n",
       "  3                  0.3         0.6920      0.009274           0.7024   \n",
       "  4                  0.4         0.5706      0.023586           0.5788   \n",
       "  5                  0.5         0.4552      0.018213           0.4616   \n",
       "  6                  0.6         0.3502      0.006535           0.3554   \n",
       "  7                  0.7         0.2420      0.007778           0.2456   \n",
       "  8                  0.8         0.1488      0.011520           0.1508   \n",
       "  9                  0.9         0.0754      0.005413           0.0764   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000            1.000        0.000000           0.0000   \n",
       "  1         0.007503            0.875        0.088388           0.1054   \n",
       "  2         0.007328            0.400        0.055902           0.1884   \n",
       "  3         0.009813            0.000        0.000000           0.3080   \n",
       "  4         0.023826            0.000        0.000000           0.4294   \n",
       "  5         0.018690            0.000        0.000000           0.5448   \n",
       "  6         0.006877            0.000        0.000000           0.6498   \n",
       "  7         0.007765            0.000        0.000000           0.7580   \n",
       "  8         0.011520            0.000        0.000000           0.8512   \n",
       "  9         0.005413            0.000        0.000000           0.9246   \n",
       "  10        0.000000            0.000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.007232             0.1054  ...          0.227074         0.8062   \n",
       "  2         0.007893             0.1822  ...          0.104583         0.8306   \n",
       "  3         0.009274             0.2976  ...          0.104583         0.9756   \n",
       "  4         0.023586             0.4212  ...          0.104583         0.9880   \n",
       "  5         0.018213             0.5384  ...          0.055902         0.9920   \n",
       "  6         0.006535             0.6446  ...          0.104583         0.9950   \n",
       "  7         0.007778             0.7544  ...          0.111803         0.9970   \n",
       "  8         0.011520             0.8492  ...          0.055902         0.9972   \n",
       "  9         0.005413             0.9236  ...          0.000000         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000            0.000   \n",
       "  1       0.015897           0.8078        0.016664            0.560   \n",
       "  2       0.028103           0.8362        0.027308            0.418   \n",
       "  3       0.006189           0.9826        0.005771            0.000   \n",
       "  4       0.002449           0.9938        0.000447            0.000   \n",
       "  5       0.000000           0.9968        0.001789            0.000   \n",
       "  6       0.003536           0.9990        0.002236            0.000   \n",
       "  7       0.006708           1.0000        0.000000            0.000   \n",
       "  8       0.006261           1.0000        0.000000            0.000   \n",
       "  9       0.000000           1.0000        0.000000            0.000   \n",
       "  10      0.000000           0.0000        0.000000            0.000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.378153                   0.1            0              0  \n",
       "  2         0.090612                   0.2            0              0  \n",
       "  3         0.000000                   0.3            0              0  \n",
       "  4         0.000000                   0.4            0              0  \n",
       "  5         0.000000                   0.5            0              0  \n",
       "  6         0.000000                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.000000                   0.8            0              0  \n",
       "  9         0.000000                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8618      0.008228           0.8480   \n",
       "  2                  0.2         0.7218      0.012194           0.7048   \n",
       "  3                  0.3         0.6402      0.006181           0.6318   \n",
       "  4                  0.4         0.5294      0.005225           0.5272   \n",
       "  5                  0.5         0.4262      0.008843           0.4354   \n",
       "  6                  0.6         0.3312      0.013293           0.3456   \n",
       "  7                  0.7         0.2306      0.015662           0.2438   \n",
       "  8                  0.8         0.1472      0.012029           0.1532   \n",
       "  9                  0.9         0.0680      0.008631           0.0678   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.007348           0.9608        0.015336           0.1382   \n",
       "  2         0.012317           0.8422        0.015336           0.2782   \n",
       "  3         0.005762           0.6984        0.023426           0.3598   \n",
       "  4         0.007694           0.5466        0.052252           0.4706   \n",
       "  5         0.013372           0.3632        0.026930           0.5738   \n",
       "  6         0.015126           0.2310        0.027830           0.6688   \n",
       "  7         0.014601           0.1354        0.032230           0.7694   \n",
       "  8         0.011009           0.1046        0.023426           0.8528   \n",
       "  9         0.009654           0.0672        0.006261           0.9320   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.008228             0.1520  ...          0.028691         0.8218   \n",
       "  2         0.012194             0.2952  ...          0.016447         0.8014   \n",
       "  3         0.006181             0.3682  ...          0.032645         0.8792   \n",
       "  4         0.005225             0.4728  ...          0.049923         0.9118   \n",
       "  5         0.008843             0.5646  ...          0.025436         0.9334   \n",
       "  6         0.013293             0.6544  ...          0.027830         0.9628   \n",
       "  7         0.015662             0.7562  ...          0.032230         0.9564   \n",
       "  8         0.012029             0.8468  ...          0.030351         0.9526   \n",
       "  9         0.008631             0.9322  ...          0.012194         0.9304   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.010616           0.8014        0.010854           0.9536   \n",
       "  2       0.008264           0.7852        0.008319           0.9144   \n",
       "  3       0.013312           0.8700        0.014053           0.9434   \n",
       "  4       0.012398           0.9070        0.013058           0.9462   \n",
       "  5       0.001949           0.9314        0.002881           0.9484   \n",
       "  6       0.005805           0.9648        0.006760           0.9422   \n",
       "  7       0.006465           0.9610        0.006205           0.9020   \n",
       "  8       0.013050           0.9534        0.018609           0.9596   \n",
       "  9       0.021686           0.9304        0.028623           0.9332   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.016979                   0.1            0              0  \n",
       "  2         0.016349                   0.2            0              0  \n",
       "  3         0.025146                   0.3            0              0  \n",
       "  4         0.026253                   0.4            0              0  \n",
       "  5         0.020599                   0.5            0              0  \n",
       "  6         0.005848                   0.6            0              0  \n",
       "  7         0.021119                   0.7            0              0  \n",
       "  8         0.055770                   0.8            0              0  \n",
       "  9         0.091470                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8690      0.010000           0.8678   \n",
       "  2                  0.2         0.7800      0.006782           0.7816   \n",
       "  3                  0.3         0.6706      0.010991           0.6752   \n",
       "  4                  0.4         0.5608      0.005070           0.5690   \n",
       "  5                  0.5         0.4550      0.016171           0.4642   \n",
       "  6                  0.6         0.3482      0.017138           0.3540   \n",
       "  7                  0.7         0.2424      0.013088           0.2460   \n",
       "  8                  0.8         0.1422      0.005541           0.1444   \n",
       "  9                  0.9         0.0576      0.006148           0.0582   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000             1.00        0.000000           0.0000   \n",
       "  1         0.011256             0.90        0.050000           0.1310   \n",
       "  2         0.004980             0.74        0.089443           0.2200   \n",
       "  3         0.010521             0.55        0.035355           0.3294   \n",
       "  4         0.008216             0.33        0.090830           0.4392   \n",
       "  5         0.016438             0.20        0.000000           0.5450   \n",
       "  6         0.018097             0.19        0.022361           0.6518   \n",
       "  7         0.013019             0.14        0.022361           0.7576   \n",
       "  8         0.005505             0.09        0.022361           0.8578   \n",
       "  9         0.006380             0.04        0.022361           0.9424   \n",
       "  10        0.000000             0.00        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.010000             0.1322  ...          0.057009         0.6922   \n",
       "  2         0.006782             0.2184  ...          0.109545         0.7328   \n",
       "  3         0.010991             0.3248  ...          0.041833         0.7810   \n",
       "  4         0.005070             0.4310  ...          0.083666         0.9290   \n",
       "  5         0.016171             0.5358  ...          0.035355         0.9748   \n",
       "  6         0.017138             0.6460  ...          0.027386         0.9782   \n",
       "  7         0.013088             0.7540  ...          0.041833         0.9856   \n",
       "  8         0.005541             0.8556  ...          0.022361         0.9876   \n",
       "  9         0.006148             0.9418  ...          0.035355         0.9934   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.015611           0.6842        0.015222           0.8454   \n",
       "  2       0.011904           0.7346        0.013885           0.6924   \n",
       "  3       0.019774           0.7878        0.020645           0.6048   \n",
       "  4       0.022572           0.9416        0.025274           0.5634   \n",
       "  5       0.007259           0.9858        0.005495           0.5760   \n",
       "  6       0.009066           0.9916        0.008792           0.5760   \n",
       "  7       0.007335           1.0000        0.000000           0.6000   \n",
       "  8       0.000548           1.0000        0.000000           0.6336   \n",
       "  9       0.014758           1.0000        0.000000           0.7000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.068076                   0.1            0              0  \n",
       "  2         0.078732                   0.2            0              0  \n",
       "  3         0.037151                   0.3            0              0  \n",
       "  4         0.108087                   0.4            0              0  \n",
       "  5         0.059439                   0.5            0              0  \n",
       "  6         0.059439                   0.6            0              0  \n",
       "  7         0.154110                   0.7            0              0  \n",
       "  8         0.074685                   0.8            0              0  \n",
       "  9         0.447214                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns],\n",
       "      significance_level  validity mean  validity std  validity_0 mean  \\\n",
       "  0                  0.0         1.0000      0.000000           1.0000   \n",
       "  1                  0.1         0.8678      0.005404           0.8618   \n",
       "  2                  0.2         0.7776      0.006504           0.7714   \n",
       "  3                  0.3         0.6514      0.011459           0.6464   \n",
       "  4                  0.4         0.5484      0.009044           0.5480   \n",
       "  5                  0.5         0.4478      0.014167           0.4516   \n",
       "  6                  0.6         0.3478      0.010663           0.3536   \n",
       "  7                  0.7         0.2424      0.008355           0.2490   \n",
       "  8                  0.8         0.1338      0.008289           0.1400   \n",
       "  9                  0.9         0.0572      0.002049           0.0594   \n",
       "  10                 1.0         0.0000      0.000000           0.0000   \n",
       "  \n",
       "      validity_0 std  validity_1 mean  validity_1 std  error_rate mean  \\\n",
       "  0         0.000000           1.0000        0.000000           0.0000   \n",
       "  1         0.005119           0.9742        0.027133           0.1322   \n",
       "  2         0.006693           0.8838        0.028622           0.2224   \n",
       "  3         0.012033           0.7356        0.014311           0.3486   \n",
       "  4         0.009823           0.5550        0.069882           0.4516   \n",
       "  5         0.016920           0.3742        0.058819           0.5522   \n",
       "  6         0.015143           0.2452        0.080918           0.6522   \n",
       "  7         0.010932           0.1292        0.068236           0.7576   \n",
       "  8         0.009670           0.0256        0.014311           0.8662   \n",
       "  9         0.001673           0.0256        0.014311           0.9428   \n",
       "  10        0.000000           0.0000        0.000000           1.0000   \n",
       "  \n",
       "      error_rate std  error_rate_0 mean  ...  efficiency_1 std  accuracy mean  \\\n",
       "  0         0.000000             0.0000  ...          0.000000         0.0000   \n",
       "  1         0.005404             0.1382  ...          0.041723         0.7336   \n",
       "  2         0.006504             0.2286  ...          0.042145         0.7296   \n",
       "  3         0.011459             0.3536  ...          0.060268         0.7430   \n",
       "  4         0.009044             0.4520  ...          0.083584         0.8288   \n",
       "  5         0.014167             0.5484  ...          0.048959         0.8938   \n",
       "  6         0.010663             0.6464  ...          0.082369         0.9498   \n",
       "  7         0.008355             0.7510  ...          0.068236         0.9858   \n",
       "  8         0.008289             0.8600  ...          0.014311         0.9976   \n",
       "  9         0.002049             0.9406  ...          0.014311         1.0000   \n",
       "  10        0.000000             1.0000  ...          0.000000         0.0000   \n",
       "  \n",
       "      accuracy std  accuracy_0 mean  accuracy_0 std  accuracy_1 mean  \\\n",
       "  0       0.000000           0.0000        0.000000           0.0000   \n",
       "  1       0.023394           0.7168        0.028039           0.9614   \n",
       "  2       0.024429           0.7218        0.026715           0.8632   \n",
       "  3       0.043704           0.7390        0.045100           0.8168   \n",
       "  4       0.044155           0.8272        0.046035           0.8520   \n",
       "  5       0.043677           0.8954        0.047406           0.8634   \n",
       "  6       0.025704           0.9496        0.026736           0.9514   \n",
       "  7       0.010257           0.9852        0.010616           1.0000   \n",
       "  8       0.005367           0.9974        0.005814           0.8000   \n",
       "  9       0.000000           1.0000        0.000000           0.8000   \n",
       "  10      0.000000           0.0000        0.000000           0.0000   \n",
       "  \n",
       "      accuracy_1 std  significance_level.1  num_actives  num_inactives  \n",
       "  0         0.000000                   0.0            0              0  \n",
       "  1         0.039935                   0.1            0              0  \n",
       "  2         0.030532                   0.2            0              0  \n",
       "  3         0.050707                   0.3            0              0  \n",
       "  4         0.027377                   0.4            0              0  \n",
       "  5         0.071416                   0.5            0              0  \n",
       "  6         0.068263                   0.6            0              0  \n",
       "  7         0.000000                   0.7            0              0  \n",
       "  8         0.447214                   0.8            0              0  \n",
       "  9         0.447214                   0.9            0              0  \n",
       "  10        0.000000                   1.0            0              0  \n",
       "  \n",
       "  [11 rows x 28 columns]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rmsd's for all endpoints over all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_original\n",
      "pred_score_original\n",
      "pred_test_original\n",
      "pred_score_calupdate\n",
      "pred_score_calupdate2\n",
      "cv_trainupdate\n",
      "pred_score_trainupdate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv_original': [0.016,\n",
       "  0.021,\n",
       "  0.028,\n",
       "  0.017,\n",
       "  0.01,\n",
       "  0.012,\n",
       "  0.012,\n",
       "  0.014,\n",
       "  0.018,\n",
       "  0.016,\n",
       "  0.018,\n",
       "  0.016],\n",
       " 'pred_score_original': [0.063,\n",
       "  0.047,\n",
       "  0.043,\n",
       "  0.045,\n",
       "  0.034,\n",
       "  0.064,\n",
       "  0.026,\n",
       "  0.076,\n",
       "  0.036,\n",
       "  0.068,\n",
       "  0.054,\n",
       "  0.055],\n",
       " 'pred_test_original': [],\n",
       " 'pred_score_calupdate': [0.019,\n",
       "  0.058,\n",
       "  0.074,\n",
       "  0.055,\n",
       "  0.048,\n",
       "  0.064,\n",
       "  0.042,\n",
       "  0.034,\n",
       "  0.063,\n",
       "  0.065,\n",
       "  0.041,\n",
       "  0.029],\n",
       " 'pred_score_calupdate2': [0.021,\n",
       "  0.025,\n",
       "  0.023,\n",
       "  0.024,\n",
       "  0.021,\n",
       "  0.016,\n",
       "  0.02,\n",
       "  0.021,\n",
       "  0.016,\n",
       "  0.008,\n",
       "  0.018,\n",
       "  0.026],\n",
       " 'cv_trainupdate': [0.013,\n",
       "  0.023,\n",
       "  0.027,\n",
       "  0.019,\n",
       "  0.013,\n",
       "  0.016,\n",
       "  0.01,\n",
       "  0.016,\n",
       "  0.017,\n",
       "  0.018,\n",
       "  0.017,\n",
       "  0.014],\n",
       " 'pred_score_trainupdate': [0.062,\n",
       "  0.04,\n",
       "  0.032,\n",
       "  0.038,\n",
       "  0.02,\n",
       "  0.055,\n",
       "  0.028,\n",
       "  0.069,\n",
       "  0.033,\n",
       "  0.056,\n",
       "  0.039,\n",
       "  0.044]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsds = {}\n",
    "for k, v in evaluation_dfs.items():\n",
    "    print(k)\n",
    "    rmsds[k] = []\n",
    "    for df in v:\n",
    "        \n",
    "        rmsd = calculate_rmsd_from_df(df)\n",
    "        rmsds[k].append(rmsd)\n",
    "rmsds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rmsd_pos's for all endpoints over all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_original\n",
      "pred_score_original\n",
      "pred_test_original\n",
      "pred_score_calupdate\n",
      "pred_score_calupdate2\n",
      "cv_trainupdate\n",
      "pred_score_trainupdate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv_original': [0.014,\n",
       "  0.018,\n",
       "  0.026,\n",
       "  0.013,\n",
       "  0.009,\n",
       "  0.008,\n",
       "  0.011,\n",
       "  0.009,\n",
       "  0.015,\n",
       "  0.011,\n",
       "  0.015,\n",
       "  0.014],\n",
       " 'pred_score_original': [0.063,\n",
       "  0.047,\n",
       "  0.043,\n",
       "  0.045,\n",
       "  0.034,\n",
       "  0.064,\n",
       "  0.026,\n",
       "  0.076,\n",
       "  0.036,\n",
       "  0.068,\n",
       "  0.054,\n",
       "  0.055],\n",
       " 'pred_test_original': [],\n",
       " 'pred_score_calupdate': [0.0,\n",
       "  0.007,\n",
       "  0.004,\n",
       "  0.049,\n",
       "  0.02,\n",
       "  0.0,\n",
       "  0.027,\n",
       "  0.027,\n",
       "  0.0,\n",
       "  0.003,\n",
       "  0.005,\n",
       "  0.007],\n",
       " 'pred_score_calupdate2': [0.021,\n",
       "  0.022,\n",
       "  0.023,\n",
       "  0.024,\n",
       "  0.021,\n",
       "  0.014,\n",
       "  0.02,\n",
       "  0.013,\n",
       "  0.005,\n",
       "  0.007,\n",
       "  0.005,\n",
       "  0.026],\n",
       " 'cv_trainupdate': [0.009,\n",
       "  0.017,\n",
       "  0.024,\n",
       "  0.014,\n",
       "  0.008,\n",
       "  0.008,\n",
       "  0.008,\n",
       "  0.009,\n",
       "  0.014,\n",
       "  0.01,\n",
       "  0.014,\n",
       "  0.011],\n",
       " 'pred_score_trainupdate': [0.062,\n",
       "  0.04,\n",
       "  0.031,\n",
       "  0.038,\n",
       "  0.02,\n",
       "  0.055,\n",
       "  0.028,\n",
       "  0.069,\n",
       "  0.033,\n",
       "  0.056,\n",
       "  0.039,\n",
       "  0.044]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsds_pos = {}\n",
    "for k, v in evaluation_dfs.items():\n",
    "    print(k)\n",
    "    rmsds_pos[k] = []\n",
    "    for df in v:\n",
    "        rmsd_pos = calculate_rmsd_pos_from_df(df)\n",
    "        rmsds_pos[k].append(rmsd_pos)\n",
    "rmsds_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\"cv_original\", \"pred_score_original\",\n",
    "#               \"cv_trainupdate\",\n",
    "              \"pred_score_trainupdate\",\n",
    "              \"pred_score_calupdate\", \"pred_score_calupdate2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot_rmsd(rmsds, \"rmsd\", strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot_rmsd(rmsds_pos, \"rmsd_pos\", strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_rmsd(rmsds, rmsd_title, strategies=None):\n",
    "    if strategies is None:\n",
    "        strategies = [\"cv_original\", \"pred_score_original\", \"pred_score_trainupdate\",\n",
    "              \"pred_score_calupdate\", \"pred_score_calupdate2\"]\n",
    "    \"\"\"\n",
    "    Generate a boxplot with the rmsd values over multiple endpoints.\n",
    "    This function can be used to plot both rmsd or rmsd_pos values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    strategies : strategies or set-ups used when making the predictions (e.g. \"original_cv\")\n",
    "    rmsds : a dictionary with the strategies as keys and a list of rmsd values for all the\n",
    "        endpoints as values\n",
    "    rmsd_title : the naming for 'rmsd' which should be used in the plot title, e.g. \"rmsd\", \"rmsd_pos\"\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    for s in strategies:\n",
    "        plt.scatter([rmsds[k] for k in strategies], s)#, labels=strategies)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.title(f\"{rmsd_title} over all endpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot(rmsds, strategies, colours=None, markers=None):\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(10,20))\n",
    "    if colours is None:\n",
    "        colours = ['navy', 'royalblue', 'blueviolet', 'plum', 'mediumvioletred', 'red', 'coral', 'gold', 'yellowgreen', 'green', 'paleturquoise', 'slategrey']\n",
    "    if markers is None:\n",
    "        markers = ['3', '<', '>', 'x', 's', '+', 'd', 'h', '*', '1', 'o', 'D']\n",
    "    for i, ep in enumerate(endpoints):\n",
    "    \n",
    "        plt.plot(strategies, [rmsds[s][i] for s in strategies], color=colours[i], linewidth=0.5)#, marker='-o')\n",
    "        plt.scatter(strategies, [rmsds[s][i] for s in strategies], label=ep, color=colours[i], marker=markers[i], s=50)\n",
    "        plt.xticks(rotation='vertical')\n",
    "        plt.legend(endpoints, loc='upper right')#, bbox_to_anchor=(1, 0.5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_plot(rmsds, strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_plot(rmsds_pos, strategies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
